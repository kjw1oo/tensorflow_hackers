{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = np.array([[0, 0], \n",
    "                   [1, 0], \n",
    "                   [1, 1],\n",
    "                   [0, 0], \n",
    "                   [0, 0], \n",
    "                   [0, 1]])\n",
    "y_data = np.array([[1, 0, 0],\n",
    "                   [0, 1, 0],\n",
    "                   [0, 0, 1],\n",
    "                   [1, 0, 0],\n",
    "                   [1, 0, 0],\n",
    "                   [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 2), (6, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.38544\n",
      "(0.0, 0.66666669)\n",
      "1 1.18533\n",
      "(0.66666669, 0.66666669)\n",
      "2 0.995165\n",
      "(0.66666669, 0.66666669)\n",
      "3 0.811646\n",
      "(0.66666669, 0.70833331)\n",
      "4 0.666484\n",
      "(0.70833331, 0.73333335)\n",
      "5 0.570506\n",
      "(0.73333335, 0.75)\n",
      "6 0.488543\n",
      "(0.75, 0.76190478)\n",
      "7 0.413468\n",
      "(0.76190478, 0.77083331)\n",
      "8 0.350096\n",
      "(0.77083331, 0.77777779)\n",
      "9 0.3024\n",
      "(0.77777779, 0.80000001)\n",
      "10 0.261952\n",
      "(0.80000001, 0.81818181)\n",
      "11 0.226633\n",
      "(0.81818181, 0.83333331)\n",
      "12 0.197546\n",
      "(0.83333331, 0.84615386)\n",
      "13 0.17391\n",
      "(0.84615386, 0.85714287)\n",
      "14 0.154011\n",
      "(0.85714287, 0.86666667)\n",
      "15 0.137868\n",
      "(0.86666667, 0.875)\n",
      "16 0.124983\n",
      "(0.875, 0.88235295)\n",
      "17 0.113131\n",
      "(0.88235295, 0.8888889)\n",
      "18 0.101623\n",
      "(0.8888889, 0.89473683)\n",
      "19 0.0898138\n",
      "(0.89473683, 0.89999998)\n",
      "20 0.0793247\n",
      "(0.89999998, 0.90476191)\n",
      "21 0.0704903\n",
      "(0.90476191, 0.90909094)\n",
      "22 0.0627403\n",
      "(0.90909094, 0.9130435)\n",
      "23 0.0560203\n",
      "(0.9130435, 0.91666669)\n",
      "24 0.0500523\n",
      "(0.91666669, 0.92000002)\n",
      "25 0.0446398\n",
      "(0.92000002, 0.92307693)\n",
      "26 0.0396989\n",
      "(0.92307693, 0.92592591)\n",
      "27 0.0352116\n",
      "(0.92592591, 0.9285714)\n",
      "28 0.0311857\n",
      "(0.9285714, 0.93103451)\n",
      "29 0.0280087\n",
      "(0.93103451, 0.93333334)\n",
      "30 0.0254473\n",
      "(0.93333334, 0.93548387)\n",
      "31 0.0231018\n",
      "(0.93548387, 0.9375)\n",
      "32 0.0209948\n",
      "(0.9375, 0.93939394)\n",
      "33 0.0191301\n",
      "(0.93939394, 0.94117647)\n",
      "34 0.0174951\n",
      "(0.94117647, 0.94285715)\n",
      "35 0.0160675\n",
      "(0.94285715, 0.94444442)\n",
      "36 0.0148196\n",
      "(0.94444442, 0.94594592)\n",
      "37 0.0137497\n",
      "(0.94594592, 0.94736844)\n",
      "38 0.0128615\n",
      "(0.94736844, 0.94871795)\n",
      "39 0.0120577\n",
      "(0.94871795, 0.94999999)\n",
      "40 0.0113336\n",
      "(0.94999999, 0.9512195)\n",
      "41 0.0106925\n",
      "(0.9512195, 0.95238096)\n",
      "42 0.0100961\n",
      "(0.95238096, 0.95348835)\n",
      "43 0.00954111\n",
      "(0.95348835, 0.95454544)\n",
      "44 0.0090249\n",
      "(0.95454544, 0.95555556)\n",
      "45 0.00854539\n",
      "(0.95555556, 0.95652175)\n",
      "46 0.00810058\n",
      "(0.95652175, 0.95744681)\n",
      "47 0.00768869\n",
      "(0.95744681, 0.95833331)\n",
      "48 0.00730761\n",
      "(0.95833331, 0.95918369)\n",
      "49 0.00695551\n",
      "(0.95918369, 0.95999998)\n",
      "50 0.0066301\n",
      "(0.95999998, 0.96078432)\n",
      "51 0.00633605\n",
      "(0.96078432, 0.96153843)\n",
      "52 0.00607021\n",
      "(0.96153843, 0.96226418)\n",
      "53 0.00582417\n",
      "(0.96226418, 0.96296299)\n",
      "54 0.00560097\n",
      "(0.96296299, 0.96363634)\n",
      "55 0.00539439\n",
      "(0.96363634, 0.96428573)\n",
      "56 0.00519921\n",
      "(0.96428573, 0.9649123)\n",
      "57 0.0050145\n",
      "(0.9649123, 0.96551722)\n",
      "58 0.00483962\n",
      "(0.96551722, 0.96610171)\n",
      "59 0.00467389\n",
      "(0.96610171, 0.96666664)\n",
      "60 0.00451685\n",
      "(0.96666664, 0.96721309)\n",
      "61 0.00436781\n",
      "(0.96721309, 0.96774191)\n",
      "62 0.00422644\n",
      "(0.96774191, 0.96825397)\n",
      "63 0.00409239\n",
      "(0.96825397, 0.96875)\n",
      "64 0.00396511\n",
      "(0.96875, 0.96923077)\n",
      "65 0.00384434\n",
      "(0.96923077, 0.969697)\n",
      "66 0.0037295\n",
      "(0.969697, 0.97014928)\n",
      "67 0.00362043\n",
      "(0.97014928, 0.97058821)\n",
      "68 0.00351839\n",
      "(0.97058821, 0.9710145)\n",
      "69 0.00342602\n",
      "(0.9710145, 0.97142857)\n",
      "70 0.0033377\n",
      "(0.97142857, 0.97183096)\n",
      "71 0.00325311\n",
      "(0.97183096, 0.97222221)\n",
      "72 0.00317768\n",
      "(0.97222221, 0.97260273)\n",
      "73 0.00310787\n",
      "(0.97260273, 0.97297299)\n",
      "74 0.00303944\n",
      "(0.97297299, 0.97333336)\n",
      "75 0.00297242\n",
      "(0.97333336, 0.97368419)\n",
      "76 0.00290699\n",
      "(0.97368419, 0.97402596)\n",
      "77 0.00284317\n",
      "(0.97402596, 0.97435898)\n",
      "78 0.0027809\n",
      "(0.97435898, 0.97468352)\n",
      "79 0.00272038\n",
      "(0.97468352, 0.97500002)\n",
      "80 0.00266343\n",
      "(0.97500002, 0.97530866)\n",
      "81 0.00261141\n",
      "(0.97530866, 0.97560978)\n",
      "82 0.00256061\n",
      "(0.97560978, 0.97590363)\n",
      "83 0.00251093\n",
      "(0.97590363, 0.97619045)\n",
      "84 0.00246231\n",
      "(0.97619045, 0.97647059)\n",
      "85 0.00241494\n",
      "(0.97647059, 0.97674417)\n",
      "86 0.00236858\n",
      "(0.97674417, 0.9770115)\n",
      "87 0.00232344\n",
      "(0.9770115, 0.97727275)\n",
      "88 0.00228603\n",
      "(0.97727275, 0.9775281)\n",
      "89 0.00224879\n",
      "(0.9775281, 0.97777778)\n",
      "90 0.00221201\n",
      "(0.97777778, 0.97802198)\n",
      "91 0.00217687\n",
      "(0.97802198, 0.97826087)\n",
      "92 0.00214147\n",
      "(0.97826087, 0.97849464)\n",
      "93 0.00210623\n",
      "(0.97849464, 0.97872341)\n",
      "94 0.00207247\n",
      "(0.97872341, 0.97894734)\n",
      "95 0.00203929\n",
      "(0.97894734, 0.97916669)\n",
      "96 0.00200653\n",
      "(0.97916669, 0.97938144)\n",
      "97 0.00197474\n",
      "(0.97938144, 0.97959185)\n",
      "98 0.00194373\n",
      "(0.97959185, 0.97979796)\n",
      "99 0.00191299\n",
      "(0.97979796, 0.98000002)\n",
      "100 0.00188469\n",
      "(0.98000002, 0.98019803)\n",
      "101 0.00185775\n",
      "(0.98019803, 0.98039216)\n",
      "102 0.00183079\n",
      "(0.98039216, 0.98058254)\n",
      "103 0.00180391\n",
      "(0.98058254, 0.98076922)\n",
      "104 0.00177757\n",
      "(0.98076922, 0.98095238)\n",
      "105 0.00175229\n",
      "(0.98095238, 0.98113209)\n",
      "106 0.00172772\n",
      "(0.98113209, 0.9813084)\n",
      "107 0.00170363\n",
      "(0.9813084, 0.98148149)\n",
      "108 0.00167975\n",
      "(0.98148149, 0.98165137)\n",
      "109 0.00165599\n",
      "(0.98165137, 0.9818182)\n",
      "110 0.00163278\n",
      "(0.9818182, 0.98198199)\n",
      "111 0.00161096\n",
      "(0.98198199, 0.98214287)\n",
      "112 0.00158998\n",
      "(0.98214287, 0.98230088)\n",
      "113 0.00156877\n",
      "(0.98230088, 0.98245615)\n",
      "114 0.00154843\n",
      "(0.98245615, 0.98260868)\n",
      "115 0.00152846\n",
      "(0.98260868, 0.98275864)\n",
      "116 0.00150837\n",
      "(0.98275864, 0.98290598)\n",
      "117 0.00148821\n",
      "(0.98290598, 0.98305082)\n",
      "118 0.00146944\n",
      "(0.98305082, 0.98319328)\n",
      "119 0.00145119\n",
      "(0.98319328, 0.98333335)\n",
      "120 0.00143286\n",
      "(0.98333335, 0.9834711)\n",
      "121 0.00141458\n",
      "(0.9834711, 0.98360658)\n",
      "122 0.00139732\n",
      "(0.98360658, 0.98373985)\n",
      "123 0.00138044\n",
      "(0.98373985, 0.98387098)\n",
      "124 0.00136355\n",
      "(0.98387098, 0.98400003)\n",
      "125 0.00134711\n",
      "(0.98400003, 0.98412699)\n",
      "126 0.00133114\n",
      "(0.98412699, 0.98425198)\n",
      "127 0.00131542\n",
      "(0.98425198, 0.984375)\n",
      "128 0.00129951\n",
      "(0.984375, 0.98449612)\n",
      "129 0.00128375\n",
      "(0.98449612, 0.98461539)\n",
      "130 0.00126871\n",
      "(0.98461539, 0.98473281)\n",
      "131 0.0012541\n",
      "(0.98473281, 0.9848485)\n",
      "132 0.00123936\n",
      "(0.9848485, 0.9849624)\n",
      "133 0.0012251\n",
      "(0.9849624, 0.98507464)\n",
      "134 0.00121075\n",
      "(0.98507464, 0.98518521)\n",
      "135 0.00119666\n",
      "(0.98518521, 0.9852941)\n",
      "136 0.00118314\n",
      "(0.9852941, 0.98540145)\n",
      "137 0.0011699\n",
      "(0.98540145, 0.98550725)\n",
      "138 0.00115655\n",
      "(0.98550725, 0.9856115)\n",
      "139 0.00114373\n",
      "(0.9856115, 0.98571426)\n",
      "140 0.00113102\n",
      "(0.98571426, 0.98581558)\n",
      "141 0.00111882\n",
      "(0.98581558, 0.98591548)\n",
      "142 0.00110669\n",
      "(0.98591548, 0.98601401)\n",
      "143 0.00109454\n",
      "(0.98601401, 0.9861111)\n",
      "144 0.00108246\n",
      "(0.9861111, 0.98620689)\n",
      "145 0.00107043\n",
      "(0.98620689, 0.98630136)\n",
      "146 0.00105925\n",
      "(0.98630136, 0.98639458)\n",
      "147 0.0010481\n",
      "(0.98639458, 0.98648649)\n",
      "148 0.00103696\n",
      "(0.98648649, 0.98657715)\n",
      "149 0.00102573\n",
      "(0.98657715, 0.98666668)\n",
      "150 0.00101481\n",
      "(0.98666668, 0.98675495)\n",
      "151 0.00100412\n",
      "(0.98675495, 0.9868421)\n",
      "152 0.000993645\n",
      "(0.9868421, 0.98692811)\n",
      "153 0.00098365\n",
      "(0.98692811, 0.98701298)\n",
      "154 0.000973614\n",
      "(0.98701298, 0.98709679)\n",
      "155 0.000963341\n",
      "(0.98709679, 0.98717946)\n",
      "156 0.000953463\n",
      "(0.98717946, 0.98726118)\n",
      "157 0.000943943\n",
      "(0.98726118, 0.98734176)\n",
      "158 0.000934403\n",
      "(0.98734176, 0.98742139)\n",
      "159 0.000924824\n",
      "(0.98742139, 0.98750001)\n",
      "160 0.000915462\n",
      "(0.98750001, 0.98757762)\n",
      "161 0.000906537\n",
      "(0.98757762, 0.98765433)\n",
      "162 0.000897552\n",
      "(0.98765433, 0.98773009)\n",
      "163 0.000888368\n",
      "(0.98773009, 0.98780489)\n",
      "164 0.000879818\n",
      "(0.98780489, 0.9878788)\n",
      "165 0.000871329\n",
      "(0.9878788, 0.98795182)\n",
      "166 0.000862839\n",
      "(0.98795182, 0.98802394)\n",
      "167 0.000854428\n",
      "(0.98802394, 0.98809522)\n",
      "168 0.000846156\n",
      "(0.98809522, 0.98816568)\n",
      "169 0.000837923\n",
      "(0.98816568, 0.98823529)\n",
      "170 0.000829948\n",
      "(0.98823529, 0.98830408)\n",
      "171 0.000821973\n",
      "(0.98830408, 0.98837209)\n",
      "172 0.000814098\n",
      "(0.98837209, 0.98843932)\n",
      "173 0.000806677\n",
      "(0.98843932, 0.98850572)\n",
      "174 0.000799019\n",
      "(0.98850572, 0.98857141)\n",
      "175 0.000791619\n",
      "(0.98857141, 0.98863637)\n",
      "176 0.00078414\n",
      "(0.98863637, 0.98870057)\n",
      "177 0.000776819\n",
      "(0.98870057, 0.98876405)\n",
      "178 0.000769598\n",
      "(0.98876405, 0.98882681)\n",
      "179 0.000762555\n",
      "(0.98882681, 0.98888886)\n",
      "180 0.000755531\n",
      "(0.98888886, 0.98895025)\n",
      "181 0.000748627\n",
      "(0.98895025, 0.98901099)\n",
      "182 0.000741961\n",
      "(0.98901099, 0.98907101)\n",
      "183 0.000735195\n",
      "(0.98907101, 0.98913044)\n",
      "184 0.000728687\n",
      "(0.98913044, 0.98918921)\n",
      "185 0.000722139\n",
      "(0.98918921, 0.98924732)\n",
      "186 0.000715571\n",
      "(0.98924732, 0.98930484)\n",
      "187 0.000709182\n",
      "(0.98930484, 0.9893617)\n",
      "188 0.000702952\n",
      "(0.9893617, 0.98941797)\n",
      "189 0.000696781\n",
      "(0.98941797, 0.9894737)\n",
      "190 0.00069063\n",
      "(0.9894737, 0.98952878)\n",
      "191 0.000684518\n",
      "(0.98952878, 0.98958331)\n",
      "192 0.000678684\n",
      "(0.98958331, 0.98963732)\n",
      "193 0.000672751\n",
      "(0.98963732, 0.98969072)\n",
      "194 0.000666996\n",
      "(0.98969072, 0.98974359)\n",
      "195 0.000661281\n",
      "(0.98974359, 0.98979592)\n",
      "196 0.000655646\n",
      "(0.98979592, 0.98984772)\n",
      "197 0.00065001\n",
      "(0.98984772, 0.98989898)\n",
      "198 0.000644513\n",
      "(0.98989898, 0.98994976)\n",
      "199 0.000639175\n",
      "(0.98994976, 0.99000001)\n",
      "200 0.000633777\n",
      "(0.99000001, 0.99004978)\n",
      "201 0.0006283\n",
      "(0.99004978, 0.99009901)\n",
      "202 0.00062314\n",
      "(0.99009901, 0.99014777)\n",
      "203 0.00061804\n",
      "(0.99014777, 0.99019605)\n",
      "204 0.000613019\n",
      "(0.99019605, 0.99024391)\n",
      "205 0.000607899\n",
      "(0.99024391, 0.99029124)\n",
      "206 0.000602778\n",
      "(0.99029124, 0.99033815)\n",
      "207 0.000597738\n",
      "(0.99033815, 0.99038464)\n",
      "208 0.000593014\n",
      "(0.99038464, 0.99043059)\n",
      "209 0.000588351\n",
      "(0.99043059, 0.99047619)\n",
      "210 0.000583568\n",
      "(0.99047619, 0.99052131)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211 0.000578705\n",
      "(0.99052131, 0.99056602)\n",
      "212 0.000573962\n",
      "(0.99056602, 0.9906103)\n",
      "213 0.000569456\n",
      "(0.9906103, 0.99065423)\n",
      "214 0.000564951\n",
      "(0.99065423, 0.99069768)\n",
      "215 0.000560366\n",
      "(0.99069768, 0.99074072)\n",
      "216 0.00055598\n",
      "(0.99074072, 0.99078339)\n",
      "217 0.000551653\n",
      "(0.99078339, 0.99082571)\n",
      "218 0.000547307\n",
      "(0.99082571, 0.99086756)\n",
      "219 0.00054296\n",
      "(0.99086756, 0.9909091)\n",
      "220 0.000538733\n",
      "(0.9909091, 0.99095023)\n",
      "221 0.000534584\n",
      "(0.99095023, 0.990991)\n",
      "222 0.000530376\n",
      "(0.990991, 0.99103141)\n",
      "223 0.000526367\n",
      "(0.99103141, 0.9910714)\n",
      "224 0.000522218\n",
      "(0.9910714, 0.9911111)\n",
      "225 0.000518268\n",
      "(0.9911111, 0.99115044)\n",
      "226 0.000514239\n",
      "(0.99115044, 0.99118942)\n",
      "227 0.000510388\n",
      "(0.99118942, 0.99122804)\n",
      "228 0.000506418\n",
      "(0.99122804, 0.99126637)\n",
      "229 0.000502627\n",
      "(0.99126637, 0.99130434)\n",
      "230 0.000498776\n",
      "(0.99130434, 0.99134201)\n",
      "231 0.000494945\n",
      "(0.99134201, 0.99137932)\n",
      "232 0.000491293\n",
      "(0.99137932, 0.99141634)\n",
      "233 0.00048766\n",
      "(0.99141634, 0.99145299)\n",
      "234 0.000484008\n",
      "(0.99145299, 0.99148935)\n",
      "235 0.000480514\n",
      "(0.99148935, 0.99152541)\n",
      "236 0.00047704\n",
      "(0.99152541, 0.99156117)\n",
      "237 0.000473507\n",
      "(0.99156117, 0.99159664)\n",
      "238 0.000469934\n",
      "(0.99159664, 0.99163181)\n",
      "239 0.00046648\n",
      "(0.99163181, 0.99166667)\n",
      "240 0.000463125\n",
      "(0.99166667, 0.99170125)\n",
      "241 0.00045979\n",
      "(0.99170125, 0.99173552)\n",
      "242 0.000456495\n",
      "(0.99173552, 0.99176955)\n",
      "243 0.000453279\n",
      "(0.99176955, 0.99180329)\n",
      "244 0.000449984\n",
      "(0.99180329, 0.99183673)\n",
      "245 0.000446768\n",
      "(0.99183673, 0.99186993)\n",
      "246 0.000443532\n",
      "(0.99186993, 0.99190283)\n",
      "247 0.000440395\n",
      "(0.99190283, 0.99193549)\n",
      "248 0.000437298\n",
      "(0.99193549, 0.99196786)\n",
      "249 0.000434162\n",
      "(0.99196786, 0.99199998)\n",
      "250 0.000431204\n",
      "(0.99199998, 0.99203187)\n",
      "251 0.000428206\n",
      "(0.99203187, 0.99206346)\n",
      "252 0.000425248\n",
      "(0.99206346, 0.99209487)\n",
      "253 0.000422191\n",
      "(0.99209487, 0.99212599)\n",
      "254 0.000419352\n",
      "(0.99212599, 0.99215686)\n",
      "255 0.000416433\n",
      "(0.99215686, 0.9921875)\n",
      "256 0.000413575\n",
      "(0.9921875, 0.9922179)\n",
      "257 0.000410696\n",
      "(0.9922179, 0.99224806)\n",
      "258 0.000407877\n",
      "(0.99224806, 0.99227798)\n",
      "259 0.000405098\n",
      "(0.99227798, 0.99230766)\n",
      "260 0.000402417\n",
      "(0.99230766, 0.99233717)\n",
      "261 0.000399658\n",
      "(0.99233717, 0.99236643)\n",
      "262 0.000396918\n",
      "(0.99236643, 0.99239546)\n",
      "263 0.000394297\n",
      "(0.99239546, 0.99242425)\n",
      "264 0.000391558\n",
      "(0.99242425, 0.99245286)\n",
      "265 0.000388977\n",
      "(0.99245286, 0.99248123)\n",
      "266 0.000386336\n",
      "(0.99248123, 0.99250937)\n",
      "267 0.000383775\n",
      "(0.99250937, 0.99253732)\n",
      "268 0.000381313\n",
      "(0.99253732, 0.99256504)\n",
      "269 0.000378772\n",
      "(0.99256504, 0.99259257)\n",
      "270 0.00037629\n",
      "(0.99259257, 0.99261993)\n",
      "271 0.000373748\n",
      "(0.99261993, 0.99264705)\n",
      "272 0.000371247\n",
      "(0.99264705, 0.99267399)\n",
      "273 0.000368884\n",
      "(0.99267399, 0.99270076)\n",
      "274 0.000366442\n",
      "(0.99270076, 0.99272728)\n",
      "275 0.000364099\n",
      "(0.99272728, 0.99275362)\n",
      "276 0.000361816\n",
      "(0.99275362, 0.99277979)\n",
      "277 0.000359414\n",
      "(0.99277979, 0.99280578)\n",
      "278 0.00035711\n",
      "(0.99280578, 0.99283153)\n",
      "279 0.000354887\n",
      "(0.99283153, 0.99285716)\n",
      "280 0.000352643\n",
      "(0.99285716, 0.99288255)\n",
      "281 0.000350439\n",
      "(0.99288255, 0.99290782)\n",
      "282 0.000348176\n",
      "(0.99290782, 0.99293286)\n",
      "283 0.000345932\n",
      "(0.99293286, 0.99295777)\n",
      "284 0.000343688\n",
      "(0.99295777, 0.99298245)\n",
      "285 0.000341584\n",
      "(0.99298245, 0.993007)\n",
      "286 0.000339439\n",
      "(0.993007, 0.99303138)\n",
      "287 0.000337295\n",
      "(0.99303138, 0.99305558)\n",
      "288 0.00033519\n",
      "(0.99305558, 0.9930796)\n",
      "289 0.000333145\n",
      "(0.9930796, 0.99310344)\n",
      "290 0.00033108\n",
      "(0.99310344, 0.99312717)\n",
      "291 0.000329055\n",
      "(0.99312717, 0.99315071)\n",
      "292 0.00032701\n",
      "(0.99315071, 0.99317408)\n",
      "293 0.000325024\n",
      "(0.99317408, 0.99319726)\n",
      "294 0.000323018\n",
      "(0.99319726, 0.99322033)\n",
      "295 0.000321152\n",
      "(0.99322033, 0.99324322)\n",
      "296 0.000319127\n",
      "(0.99324322, 0.99326599)\n",
      "297 0.000317121\n",
      "(0.99326599, 0.99328858)\n",
      "298 0.000315235\n",
      "(0.99328858, 0.99331105)\n",
      "299 0.000313388\n",
      "(0.99331105, 0.99333334)\n",
      "300 0.000311502\n",
      "(0.99333334, 0.99335545)\n",
      "301 0.000309655\n",
      "(0.99335545, 0.99337751)\n",
      "302 0.000307729\n",
      "(0.99337751, 0.99339932)\n",
      "303 0.000305882\n",
      "(0.99339932, 0.99342108)\n",
      "304 0.000304115\n",
      "(0.99342108, 0.9934426)\n",
      "305 0.000302248\n",
      "(0.9934426, 0.99346405)\n",
      "306 0.000300461\n",
      "(0.99346405, 0.99348533)\n",
      "307 0.000298734\n",
      "(0.99348533, 0.99350649)\n",
      "308 0.000296967\n",
      "(0.99350649, 0.99352753)\n",
      "309 0.000295219\n",
      "(0.99352753, 0.99354839)\n",
      "310 0.000293472\n",
      "(0.99354839, 0.99356914)\n",
      "311 0.000291804\n",
      "(0.99356914, 0.99358976)\n",
      "312 0.000290076\n",
      "(0.99358976, 0.9936102)\n",
      "313 0.000288428\n",
      "(0.9936102, 0.99363059)\n",
      "314 0.00028676\n",
      "(0.99363059, 0.99365079)\n",
      "315 0.000285072\n",
      "(0.99365079, 0.99367088)\n",
      "316 0.000283444\n",
      "(0.99367088, 0.99369085)\n",
      "317 0.000281815\n",
      "(0.99369085, 0.9937107)\n",
      "318 0.000280167\n",
      "(0.9937107, 0.99373043)\n",
      "319 0.000278479\n",
      "(0.99373043, 0.99374998)\n",
      "320 0.000276871\n",
      "(0.99374998, 0.99376947)\n",
      "321 0.000275242\n",
      "(0.99376947, 0.99378884)\n",
      "322 0.000273713\n",
      "(0.99378884, 0.99380803)\n",
      "323 0.000272085\n",
      "(0.99380803, 0.99382716)\n",
      "324 0.000270516\n",
      "(0.99382716, 0.99384618)\n",
      "325 0.000269007\n",
      "(0.99384618, 0.99386501)\n",
      "326 0.000267438\n",
      "(0.99386501, 0.99388379)\n",
      "327 0.000265909\n",
      "(0.99388379, 0.99390244)\n",
      "328 0.00026442\n",
      "(0.99390244, 0.99392098)\n",
      "329 0.00026291\n",
      "(0.99392098, 0.9939394)\n",
      "330 0.000261421\n",
      "(0.9939394, 0.9939577)\n",
      "331 0.000259912\n",
      "(0.9939577, 0.99397588)\n",
      "332 0.000258462\n",
      "(0.99397588, 0.993994)\n",
      "333 0.000257052\n",
      "(0.993994, 0.994012)\n",
      "334 0.000255543\n",
      "(0.994012, 0.99402988)\n",
      "335 0.000254113\n",
      "(0.99402988, 0.99404764)\n",
      "336 0.000252703\n",
      "(0.99404764, 0.99406528)\n",
      "337 0.000251372\n",
      "(0.99406528, 0.99408287)\n",
      "338 0.000249943\n",
      "(0.99408287, 0.99410027)\n",
      "339 0.000248533\n",
      "(0.99410027, 0.99411762)\n",
      "340 0.000247103\n",
      "(0.99411762, 0.9941349)\n",
      "341 0.000245812\n",
      "(0.9941349, 0.99415207)\n",
      "342 0.000244442\n",
      "(0.99415207, 0.99416912)\n",
      "343 0.000243111\n",
      "(0.99416912, 0.99418604)\n",
      "344 0.000241781\n",
      "(0.99418604, 0.99420291)\n",
      "345 0.00024051\n",
      "(0.99420291, 0.99421966)\n",
      "346 0.000239159\n",
      "(0.99421966, 0.99423629)\n",
      "347 0.000237888\n",
      "(0.99423629, 0.99425286)\n",
      "348 0.000236637\n",
      "(0.99425286, 0.99426931)\n",
      "349 0.000235326\n",
      "(0.99426931, 0.9942857)\n",
      "350 0.000234095\n",
      "(0.9942857, 0.99430197)\n",
      "351 0.000232804\n",
      "(0.99430197, 0.99431819)\n",
      "352 0.000231573\n",
      "(0.99431819, 0.99433428)\n",
      "353 0.000230361\n",
      "(0.99433428, 0.99435025)\n",
      "354 0.00022911\n",
      "(0.99435025, 0.99436617)\n",
      "355 0.000227859\n",
      "(0.99436617, 0.99438202)\n",
      "356 0.000226628\n",
      "(0.99438202, 0.99439776)\n",
      "357 0.000225436\n",
      "(0.99439776, 0.99441344)\n",
      "358 0.000224304\n",
      "(0.99441344, 0.99442899)\n",
      "359 0.000223132\n",
      "(0.99442899, 0.99444443)\n",
      "360 0.000221981\n",
      "(0.99444443, 0.99445981)\n",
      "361 0.000220769\n",
      "(0.99445981, 0.99447513)\n",
      "362 0.000219677\n",
      "(0.99447513, 0.99449039)\n",
      "363 0.000218565\n",
      "(0.99449039, 0.99450547)\n",
      "364 0.000217433\n",
      "(0.99450547, 0.99452055)\n",
      "365 0.000216281\n",
      "(0.99452055, 0.99453551)\n",
      "366 0.000215208\n",
      "(0.99453551, 0.99455041)\n",
      "367 0.000214116\n",
      "(0.99455041, 0.99456519)\n",
      "368 0.000213044\n",
      "(0.99456519, 0.99457997)\n",
      "369 0.000211931\n",
      "(0.99457997, 0.99459457)\n",
      "370 0.000210839\n",
      "(0.99459457, 0.99460918)\n",
      "371 0.000209767\n",
      "(0.99460918, 0.99462366)\n",
      "372 0.000208694\n",
      "(0.99462366, 0.99463809)\n",
      "373 0.000207661\n",
      "(0.99463809, 0.99465239)\n",
      "374 0.000206629\n",
      "(0.99465239, 0.9946667)\n",
      "375 0.000205576\n",
      "(0.9946667, 0.99468082)\n",
      "376 0.000204563\n",
      "(0.99468082, 0.99469495)\n",
      "377 0.000203511\n",
      "(0.99469495, 0.99470901)\n",
      "378 0.000202498\n",
      "(0.99470901, 0.99472296)\n",
      "379 0.000201544\n",
      "(0.99472296, 0.99473685)\n",
      "380 0.000200591\n",
      "(0.99473685, 0.99475068)\n",
      "381 0.000199538\n",
      "(0.99475068, 0.99476439)\n",
      "382 0.000198545\n",
      "(0.99476439, 0.9947781)\n",
      "383 0.000197572\n",
      "(0.9947781, 0.99479169)\n",
      "384 0.000196619\n",
      "(0.99479169, 0.99480522)\n",
      "385 0.000195666\n",
      "(0.99480522, 0.99481863)\n",
      "386 0.000194752\n",
      "(0.99481863, 0.99483204)\n",
      "387 0.000193779\n",
      "(0.99483204, 0.99484539)\n",
      "388 0.000192786\n",
      "(0.99484539, 0.99485862)\n",
      "389 0.000191892\n",
      "(0.99485862, 0.9948718)\n",
      "390 0.000190978\n",
      "(0.9948718, 0.99488491)\n",
      "391 0.000190025\n",
      "(0.99488491, 0.99489796)\n",
      "392 0.000189131\n",
      "(0.99489796, 0.99491096)\n",
      "393 0.000188158\n",
      "(0.99491096, 0.99492383)\n",
      "394 0.000187264\n",
      "(0.99492383, 0.9949367)\n",
      "395 0.000186391\n",
      "(0.9949367, 0.99494952)\n",
      "396 0.000185536\n",
      "(0.99494952, 0.99496222)\n",
      "397 0.000184623\n",
      "(0.99496222, 0.99497485)\n",
      "398 0.000183769\n",
      "(0.99497485, 0.99498749)\n",
      "399 0.000182935\n",
      "(0.99498749, 0.995)\n",
      "400 0.000182021\n",
      "(0.995, 0.99501246)\n",
      "401 0.000181187\n",
      "(0.99501246, 0.99502486)\n",
      "402 0.000180333\n",
      "(0.99502486, 0.9950372)\n",
      "403 0.000179479\n",
      "(0.9950372, 0.99504948)\n",
      "404 0.000178645\n",
      "(0.99504948, 0.99506176)\n",
      "405 0.00017783\n",
      "(0.99506176, 0.99507391)\n",
      "406 0.000177036\n",
      "(0.99507391, 0.99508601)\n",
      "407 0.000176202\n",
      "(0.99508601, 0.99509805)\n",
      "408 0.000175387\n",
      "(0.99509805, 0.99511003)\n",
      "409 0.000174573\n",
      "(0.99511003, 0.99512196)\n",
      "410 0.000173759\n",
      "(0.99512196, 0.99513382)\n",
      "411 0.000172964\n",
      "(0.99513382, 0.99514562)\n",
      "412 0.000172209\n",
      "(0.99514562, 0.99515736)\n",
      "413 0.000171375\n",
      "(0.99515736, 0.9951691)\n",
      "414 0.000170621\n",
      "(0.9951691, 0.99518073)\n",
      "415 0.000169866\n",
      "(0.99518073, 0.99519229)\n",
      "416 0.000169051\n",
      "(0.99519229, 0.99520385)\n",
      "417 0.000168317\n",
      "(0.99520385, 0.9952153)\n",
      "418 0.000167542\n",
      "(0.9952153, 0.99522674)\n",
      "419 0.000166787\n",
      "(0.99522674, 0.99523807)\n",
      "420 0.000166072\n",
      "(0.99523807, 0.99524939)\n",
      "421 0.000165298\n",
      "(0.99524939, 0.99526066)\n",
      "422 0.000164602\n",
      "(0.99526066, 0.99527186)\n",
      "423 0.000163848\n",
      "(0.99527186, 0.99528301)\n",
      "424 0.000163073\n",
      "(0.99528301, 0.99529409)\n",
      "425 0.000162378\n",
      "(0.99529409, 0.99530518)\n",
      "426 0.000161643\n",
      "(0.99530518, 0.99531615)\n",
      "427 0.000161007\n",
      "(0.99531615, 0.99532712)\n",
      "428 0.000160292\n",
      "(0.99532712, 0.99533802)\n",
      "429 0.000159538\n",
      "(0.99533802, 0.99534881)\n",
      "430 0.000158862\n",
      "(0.99534881, 0.9953596)\n",
      "431 0.000158187\n",
      "(0.9953596, 0.99537039)\n",
      "432 0.000157492\n",
      "(0.99537039, 0.99538106)\n",
      "433 0.000156836\n",
      "(0.99538106, 0.99539173)\n",
      "434 0.000156062\n",
      "(0.99539173, 0.99540228)\n",
      "435 0.000155386\n",
      "(0.99540228, 0.99541283)\n",
      "436 0.000154731\n",
      "(0.99541283, 0.99542332)\n",
      "437 0.000154016\n",
      "(0.99542332, 0.99543381)\n",
      "438 0.00015338\n",
      "(0.99543381, 0.99544418)\n",
      "439 0.000152725\n",
      "(0.99544418, 0.99545455)\n",
      "440 0.000152069\n",
      "(0.99545455, 0.99546486)\n",
      "441 0.000151434\n",
      "(0.99546486, 0.99547511)\n",
      "442 0.000150758\n",
      "(0.99547511, 0.99548531)\n",
      "443 0.000150143\n",
      "(0.99548531, 0.9954955)\n",
      "444 0.000149507\n",
      "(0.9954955, 0.99550563)\n",
      "445 0.000148832\n",
      "(0.99550563, 0.9955157)\n",
      "446 0.000148236\n",
      "(0.9955157, 0.99552572)\n",
      "447 0.0001476\n",
      "(0.99552572, 0.99553573)\n",
      "448 0.000146984\n",
      "(0.99553573, 0.99554569)\n",
      "449 0.000146349\n",
      "(0.99554569, 0.99555558)\n",
      "450 0.000145753\n",
      "(0.99555558, 0.99556541)\n",
      "451 0.000145177\n",
      "(0.99556541, 0.99557525)\n",
      "452 0.000144581\n",
      "(0.99557525, 0.99558496)\n",
      "453 0.000143926\n",
      "(0.99558496, 0.99559474)\n",
      "454 0.00014331\n",
      "(0.99559474, 0.9956044)\n",
      "455 0.000142734\n",
      "(0.9956044, 0.99561405)\n",
      "456 0.000142178\n",
      "(0.99561405, 0.99562365)\n",
      "457 0.000141582\n",
      "(0.99562365, 0.99563318)\n",
      "458 0.000141026\n",
      "(0.99563318, 0.99564272)\n",
      "459 0.00014043\n",
      "(0.99564272, 0.9956522)\n",
      "460 0.000139854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9956522, 0.99566162)\n",
      "461 0.000139258\n",
      "(0.99566162, 0.99567097)\n",
      "462 0.000138722\n",
      "(0.99567097, 0.99568033)\n",
      "463 0.000138165\n",
      "(0.99568033, 0.99568963)\n",
      "464 0.000137589\n",
      "(0.99568963, 0.99569893)\n",
      "465 0.000137033\n",
      "(0.99569893, 0.99570817)\n",
      "466 0.000136477\n",
      "(0.99570817, 0.99571735)\n",
      "467 0.000135921\n",
      "(0.99571735, 0.99572647)\n",
      "468 0.000135365\n",
      "(0.99572647, 0.99573559)\n",
      "469 0.000134848\n",
      "(0.99573559, 0.99574471)\n",
      "470 0.000134292\n",
      "(0.99574471, 0.99575371)\n",
      "471 0.000133716\n",
      "(0.99575371, 0.99576271)\n",
      "472 0.00013318\n",
      "(0.99576271, 0.99577165)\n",
      "473 0.000132703\n",
      "(0.99577165, 0.99578059)\n",
      "474 0.000132127\n",
      "(0.99578059, 0.99578947)\n",
      "475 0.00013165\n",
      "(0.99578947, 0.99579829)\n",
      "476 0.000131114\n",
      "(0.99579829, 0.99580711)\n",
      "477 0.000130558\n",
      "(0.99580711, 0.99581587)\n",
      "478 0.000130081\n",
      "(0.99581587, 0.99582464)\n",
      "479 0.000129505\n",
      "(0.99582464, 0.99583334)\n",
      "480 0.000128949\n",
      "(0.99583334, 0.99584198)\n",
      "481 0.000128452\n",
      "(0.99584198, 0.99585062)\n",
      "482 0.000127936\n",
      "(0.99585062, 0.99585921)\n",
      "483 0.000127479\n",
      "(0.99585921, 0.99586779)\n",
      "484 0.000126963\n",
      "(0.99586779, 0.99587631)\n",
      "485 0.000126486\n",
      "(0.99587631, 0.99588478)\n",
      "486 0.000125989\n",
      "(0.99588478, 0.99589324)\n",
      "487 0.000125532\n",
      "(0.99589324, 0.99590164)\n",
      "488 0.000125056\n",
      "(0.99590164, 0.99591005)\n",
      "489 0.000124539\n",
      "(0.99591005, 0.99591839)\n",
      "490 0.000124062\n",
      "(0.99591839, 0.99592668)\n",
      "491 0.000123566\n",
      "(0.99592668, 0.99593496)\n",
      "492 0.000123129\n",
      "(0.99593496, 0.99594319)\n",
      "493 0.000122632\n",
      "(0.99594319, 0.99595141)\n",
      "494 0.000122156\n",
      "(0.99595141, 0.99595958)\n",
      "495 0.000121699\n",
      "(0.99595958, 0.99596775)\n",
      "496 0.000121262\n",
      "(0.99596775, 0.99597585)\n",
      "497 0.000120825\n",
      "(0.99597585, 0.99598396)\n",
      "498 0.000120328\n",
      "(0.99598396, 0.995992)\n",
      "499 0.000119871\n",
      "(0.995992, 0.99599999)\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([2, 10], -1, 1))\n",
    "b = tf.Variable(tf.random_uniform([10]))\n",
    "L1 = tf.add(tf.matmul(X, W), b)\n",
    "L1 = tf.nn.relu(L1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([10, 20], -1, 1))\n",
    "b2 = tf.Variable(tf.random_uniform([20]))\n",
    "L2 = tf.add(tf.matmul(L1, W2), b2)\n",
    "L2 = tf.nn.relu(L2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_uniform([20, 3], -1, 1))\n",
    "b3 = tf.Variable(tf.random_uniform([3]))\n",
    "L3 = tf.add(tf.matmul(L2, W3), b3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=L3))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "prediction = tf.argmax(tf.nn.softmax(L3), axis = 1)\n",
    "target = tf.argmax(Y, axis = 1)\n",
    "accuracy = tf.metrics.accuracy(target, prediction)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    for step in range(500):\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict = {X: x_data, Y: y_data})\n",
    "        print(step, c)\n",
    "        print(sess.run(accuracy, feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "    \n",
    "\n",
    "#L1 = tf.layers.dense(X, 3, activation = tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\\dnn2.ckpt-1000\n",
      "Step : 1001, cost : 0.00010058088082587346\n",
      "Step : 1002, cost : 0.00010038225445896387\n",
      "Step : 1003, cost : 0.00010022334026871249\n",
      "Step : 1004, cost : 0.00010002470662584528\n",
      "Step : 1005, cost : 9.98459363472648e-05\n",
      "Step : 1006, cost : 9.966716606868431e-05\n",
      "Step : 1007, cost : 9.948838851414621e-05\n",
      "Step : 1008, cost : 9.930962551152334e-05\n",
      "Step : 1009, cost : 9.91109773167409e-05\n",
      "Step : 1010, cost : 9.893220703816041e-05\n",
      "Step : 1011, cost : 9.877330739982426e-05\n",
      "Step : 1012, cost : 9.859452256932855e-05\n",
      "Step : 1013, cost : 9.841574501479045e-05\n",
      "Step : 1014, cost : 9.821711137192324e-05\n",
      "Step : 1015, cost : 9.803834836930037e-05\n",
      "Step : 1016, cost : 9.78992975433357e-05\n",
      "Step : 1017, cost : 9.77006639004685e-05\n",
      "Step : 1018, cost : 9.752189362188801e-05\n",
      "Step : 1019, cost : 9.736298670759425e-05\n",
      "Step : 1020, cost : 9.718420915305614e-05\n",
      "Step : 1021, cost : 9.700543159851804e-05\n",
      "Step : 1022, cost : 9.682666859589517e-05\n",
      "Step : 1023, cost : 9.66081497608684e-05\n",
      "Step : 1024, cost : 9.642937948228791e-05\n",
      "Step : 1025, cost : 9.625060920370743e-05\n",
      "Step : 1026, cost : 9.607183164916933e-05\n",
      "Step : 1027, cost : 9.591292473487556e-05\n",
      "Step : 1028, cost : 9.573414718033746e-05\n",
      "Step : 1029, cost : 9.555536234984174e-05\n",
      "Step : 1030, cost : 9.53964699874632e-05\n",
      "Step : 1031, cost : 9.52176924329251e-05\n",
      "Step : 1032, cost : 9.50190587900579e-05\n",
      "Step : 1033, cost : 9.488000068813562e-05\n",
      "Step : 1034, cost : 9.470122313359752e-05\n",
      "Step : 1035, cost : 9.450258949073032e-05\n",
      "Step : 1036, cost : 9.436354594072327e-05\n",
      "Step : 1037, cost : 9.418477566214278e-05\n",
      "Step : 1038, cost : 9.404573211213574e-05\n",
      "Step : 1039, cost : 9.386695455759764e-05\n",
      "Step : 1040, cost : 9.368817700305954e-05\n",
      "Step : 1041, cost : 9.354913345305249e-05\n",
      "Step : 1042, cost : 9.335049981018528e-05\n",
      "Step : 1043, cost : 9.319159289589152e-05\n",
      "Step : 1044, cost : 9.303267142968252e-05\n",
      "Step : 1045, cost : 9.287375723943114e-05\n",
      "Step : 1046, cost : 9.271485032513738e-05\n",
      "Step : 1047, cost : 9.253607277059928e-05\n",
      "Step : 1048, cost : 9.237716585630551e-05\n",
      "Step : 1049, cost : 9.221825894201174e-05\n",
      "Step : 1050, cost : 9.203947411151603e-05\n",
      "Step : 1051, cost : 9.190043056150898e-05\n",
      "Step : 1052, cost : 9.174152364721522e-05\n",
      "Step : 1053, cost : 9.156274609267712e-05\n",
      "Step : 1054, cost : 9.140383917838335e-05\n",
      "Step : 1055, cost : 9.124492498813197e-05\n",
      "Step : 1056, cost : 9.110587416216731e-05\n",
      "Step : 1057, cost : 9.092709660762921e-05\n",
      "Step : 1058, cost : 9.076818241737783e-05\n",
      "Step : 1059, cost : 9.060928277904168e-05\n",
      "Step : 1060, cost : 9.04503685887903e-05\n",
      "Step : 1061, cost : 9.029145439853892e-05\n",
      "Step : 1062, cost : 9.013254748424515e-05\n",
      "Step : 1063, cost : 8.997362601803616e-05\n",
      "Step : 1064, cost : 8.981471910374239e-05\n",
      "Step : 1065, cost : 8.967567555373535e-05\n",
      "Step : 1066, cost : 8.951675408752635e-05\n",
      "Step : 1067, cost : 8.93777105375193e-05\n",
      "Step : 1068, cost : 8.917906234273687e-05\n",
      "Step : 1069, cost : 8.905988215701655e-05\n",
      "Step : 1070, cost : 8.888111187843606e-05\n",
      "Step : 1071, cost : 8.87420610524714e-05\n",
      "Step : 1072, cost : 8.860301022650674e-05\n",
      "Step : 1073, cost : 8.842423994792625e-05\n",
      "Step : 1074, cost : 8.826531848171726e-05\n",
      "Step : 1075, cost : 8.814613102003932e-05\n",
      "Step : 1076, cost : 8.796736801741645e-05\n",
      "Step : 1077, cost : 8.782831719145179e-05\n",
      "Step : 1078, cost : 8.766940300120041e-05\n",
      "Step : 1079, cost : 8.751048153499141e-05\n",
      "Step : 1080, cost : 8.737143798498437e-05\n",
      "Step : 1081, cost : 8.72125310706906e-05\n",
      "Step : 1082, cost : 8.705360960448161e-05\n",
      "Step : 1083, cost : 8.6954292783048e-05\n",
      "Step : 1084, cost : 8.681524195708334e-05\n",
      "Step : 1085, cost : 8.665632776683196e-05\n",
      "Step : 1086, cost : 8.65172769408673e-05\n",
      "Step : 1087, cost : 8.639808947918937e-05\n",
      "Step : 1088, cost : 8.62590386532247e-05\n",
      "Step : 1089, cost : 8.610012446297333e-05\n",
      "Step : 1090, cost : 8.598092972533777e-05\n",
      "Step : 1091, cost : 8.582202281104401e-05\n",
      "Step : 1092, cost : 8.572269143769518e-05\n",
      "Step : 1093, cost : 8.554392115911469e-05\n",
      "Step : 1094, cost : 8.540487033315003e-05\n",
      "Step : 1095, cost : 8.530554623575881e-05\n",
      "Step : 1096, cost : 8.51267614052631e-05\n",
      "Step : 1097, cost : 8.500757394358516e-05\n",
      "Step : 1098, cost : 8.48685231176205e-05\n",
      "Step : 1099, cost : 8.474934293190017e-05\n",
      "Step : 1100, cost : 8.457055810140446e-05\n",
      "Step : 1101, cost : 8.449110464425758e-05\n",
      "Step : 1102, cost : 8.43321904540062e-05\n",
      "Step : 1103, cost : 8.417326171183959e-05\n",
      "Step : 1104, cost : 8.405408152611926e-05\n",
      "Step : 1105, cost : 8.391502342419699e-05\n",
      "Step : 1106, cost : 8.379584323847666e-05\n",
      "Step : 1107, cost : 8.363692177226767e-05\n",
      "Step : 1108, cost : 8.351772703463212e-05\n",
      "Step : 1109, cost : 8.339854684891179e-05\n",
      "Step : 1110, cost : 8.325950329890475e-05\n",
      "Step : 1111, cost : 8.312045247294009e-05\n",
      "Step : 1112, cost : 8.300126501126215e-05\n",
      "Step : 1113, cost : 8.286221418529749e-05\n",
      "Step : 1114, cost : 8.272315608337522e-05\n",
      "Step : 1115, cost : 8.260396862169728e-05\n",
      "Step : 1116, cost : 8.246492507169023e-05\n",
      "Step : 1117, cost : 8.232586696976796e-05\n",
      "Step : 1118, cost : 8.220667950809002e-05\n",
      "Step : 1119, cost : 8.206762868212536e-05\n",
      "Step : 1120, cost : 8.196831186069176e-05\n",
      "Step : 1121, cost : 8.180939039448276e-05\n",
      "Step : 1122, cost : 8.169020293280482e-05\n",
      "Step : 1123, cost : 8.155114483088255e-05\n",
      "Step : 1124, cost : 8.145183528540656e-05\n",
      "Step : 1125, cost : 8.131277718348429e-05\n",
      "Step : 1126, cost : 8.117371908156201e-05\n",
      "Step : 1127, cost : 8.105453889584169e-05\n",
      "Step : 1128, cost : 8.091548806987703e-05\n",
      "Step : 1129, cost : 8.081616397248581e-05\n",
      "Step : 1130, cost : 8.067710587056354e-05\n",
      "Step : 1131, cost : 8.053806232055649e-05\n",
      "Step : 1132, cost : 8.041886758292094e-05\n",
      "Step : 1133, cost : 8.0299680121243e-05\n",
      "Step : 1134, cost : 8.018049265956506e-05\n",
      "Step : 1135, cost : 8.006130519788712e-05\n",
      "Step : 1136, cost : 7.992225437192246e-05\n",
      "Step : 1137, cost : 7.980306691024452e-05\n",
      "Step : 1138, cost : 7.966401608427987e-05\n",
      "Step : 1139, cost : 7.954482134664431e-05\n",
      "Step : 1140, cost : 7.944550452521071e-05\n",
      "Step : 1141, cost : 7.930645369924605e-05\n",
      "Step : 1142, cost : 7.91872589616105e-05\n",
      "Step : 1143, cost : 7.904820813564584e-05\n",
      "Step : 1144, cost : 7.892902794992551e-05\n",
      "Step : 1145, cost : 7.880983321228996e-05\n",
      "Step : 1146, cost : 7.871050911489874e-05\n",
      "Step : 1147, cost : 7.857145828893408e-05\n",
      "Step : 1148, cost : 7.847213419154286e-05\n",
      "Step : 1149, cost : 7.835294672986493e-05\n",
      "Step : 1150, cost : 7.821388862794265e-05\n",
      "Step : 1151, cost : 7.80748450779356e-05\n",
      "Step : 1152, cost : 7.797551370458677e-05\n",
      "Step : 1153, cost : 7.785633351886645e-05\n",
      "Step : 1154, cost : 7.77371387812309e-05\n",
      "Step : 1155, cost : 7.761795131955296e-05\n",
      "Step : 1156, cost : 7.749876385787502e-05\n",
      "Step : 1157, cost : 7.739944703644142e-05\n",
      "Step : 1158, cost : 7.728025229880586e-05\n",
      "Step : 1159, cost : 7.716106483712792e-05\n",
      "Step : 1160, cost : 7.702200673520565e-05\n",
      "Step : 1161, cost : 7.692268263781443e-05\n",
      "Step : 1162, cost : 7.680350245209411e-05\n",
      "Step : 1163, cost : 7.668431499041617e-05\n",
      "Step : 1164, cost : 7.656512752873823e-05\n",
      "Step : 1165, cost : 7.644593279110268e-05\n",
      "Step : 1166, cost : 7.634660869371146e-05\n",
      "Step : 1167, cost : 7.622742123203352e-05\n",
      "Step : 1168, cost : 7.610823377035558e-05\n",
      "Step : 1169, cost : 7.600890967296436e-05\n",
      "Step : 1170, cost : 7.588972221128643e-05\n",
      "Step : 1171, cost : 7.577053474960849e-05\n",
      "Step : 1172, cost : 7.565134001197293e-05\n",
      "Step : 1173, cost : 7.555202319053933e-05\n",
      "Step : 1174, cost : 7.543282845290378e-05\n",
      "Step : 1175, cost : 7.533350435551256e-05\n",
      "Step : 1176, cost : 7.523418025812134e-05\n",
      "Step : 1177, cost : 7.513485616073012e-05\n",
      "Step : 1178, cost : 7.501566869905218e-05\n",
      "Step : 1179, cost : 7.483686931664124e-05\n",
      "Step : 1180, cost : 7.469781849067658e-05\n",
      "Step : 1181, cost : 7.459849439328536e-05\n",
      "Step : 1182, cost : 7.447929965564981e-05\n",
      "Step : 1183, cost : 7.436011946992949e-05\n",
      "Step : 1184, cost : 7.426079537253827e-05\n",
      "Step : 1185, cost : 7.414160791086033e-05\n",
      "Step : 1186, cost : 7.404228381346911e-05\n",
      "Step : 1187, cost : 7.39429597160779e-05\n",
      "Step : 1188, cost : 7.384363561868668e-05\n",
      "Step : 1189, cost : 7.372444815700874e-05\n",
      "Step : 1190, cost : 7.362512405961752e-05\n",
      "Step : 1191, cost : 7.350593659793958e-05\n",
      "Step : 1192, cost : 7.342646858887747e-05\n",
      "Step : 1193, cost : 7.330728112719953e-05\n",
      "Step : 1194, cost : 7.320795702980831e-05\n",
      "Step : 1195, cost : 7.308876956813037e-05\n",
      "Step : 1196, cost : 7.298944547073916e-05\n",
      "Step : 1197, cost : 7.287025800906122e-05\n",
      "Step : 1198, cost : 7.277092663571239e-05\n",
      "Step : 1199, cost : 7.265173917403445e-05\n",
      "Step : 1200, cost : 7.255241507664323e-05\n",
      "Step : 1201, cost : 7.243322761496529e-05\n",
      "Step : 1202, cost : 7.233390351757407e-05\n",
      "Step : 1203, cost : 7.223457942018285e-05\n",
      "Step : 1204, cost : 7.213524804683402e-05\n",
      "Step : 1205, cost : 7.20160678611137e-05\n",
      "Step : 1206, cost : 7.191673648776487e-05\n",
      "Step : 1207, cost : 7.179754902608693e-05\n",
      "Step : 1208, cost : 7.169822492869571e-05\n",
      "Step : 1209, cost : 7.157903746701777e-05\n",
      "Step : 1210, cost : 7.149957673391327e-05\n",
      "Step : 1211, cost : 7.140025263652205e-05\n",
      "Step : 1212, cost : 7.130092853913084e-05\n",
      "Step : 1213, cost : 7.122146780602634e-05\n",
      "Step : 1214, cost : 7.11022803443484e-05\n",
      "Step : 1215, cost : 7.098308560671285e-05\n",
      "Step : 1216, cost : 7.088376150932163e-05\n",
      "Step : 1217, cost : 7.078443741193041e-05\n",
      "Step : 1218, cost : 7.066524267429486e-05\n",
      "Step : 1219, cost : 7.056592585286126e-05\n",
      "Step : 1220, cost : 7.04467311152257e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 1221, cost : 7.03672703821212e-05\n",
      "Step : 1222, cost : 7.028781692497432e-05\n",
      "Step : 1223, cost : 7.01884928275831e-05\n",
      "Step : 1224, cost : 7.006929808994755e-05\n",
      "Step : 1225, cost : 6.996996671659872e-05\n",
      "Step : 1226, cost : 6.98507865308784e-05\n",
      "Step : 1227, cost : 6.975145515752956e-05\n",
      "Step : 1228, cost : 6.967200170038268e-05\n",
      "Step : 1229, cost : 6.955280696274713e-05\n",
      "Step : 1230, cost : 6.949321686988696e-05\n",
      "Step : 1231, cost : 6.937402213225141e-05\n",
      "Step : 1232, cost : 6.92746980348602e-05\n",
      "Step : 1233, cost : 6.915551057318226e-05\n",
      "Step : 1234, cost : 6.907604984007776e-05\n",
      "Step : 1235, cost : 6.897672574268654e-05\n",
      "Step : 1236, cost : 6.885753100505099e-05\n",
      "Step : 1237, cost : 6.879794091219082e-05\n",
      "Step : 1238, cost : 6.867874617455527e-05\n",
      "Step : 1239, cost : 6.859928544145077e-05\n",
      "Step : 1240, cost : 6.849996134405956e-05\n",
      "Step : 1241, cost : 6.8380766606424e-05\n",
      "Step : 1242, cost : 6.82814497849904e-05\n",
      "Step : 1243, cost : 6.816225504735485e-05\n",
      "Step : 1244, cost : 6.81225283187814e-05\n",
      "Step : 1245, cost : 6.800333358114585e-05\n",
      "Step : 1246, cost : 6.790400948375463e-05\n",
      "Step : 1247, cost : 6.78046781104058e-05\n",
      "Step : 1248, cost : 6.770535401301458e-05\n",
      "Step : 1249, cost : 6.760603719158098e-05\n",
      "Step : 1250, cost : 6.750671309418976e-05\n",
      "Step : 1251, cost : 6.742725236108527e-05\n",
      "Step : 1252, cost : 6.732792098773643e-05\n",
      "Step : 1253, cost : 6.722859689034522e-05\n",
      "Step : 1254, cost : 6.712926551699638e-05\n",
      "Step : 1255, cost : 6.702994141960517e-05\n",
      "Step : 1256, cost : 6.695048796245828e-05\n",
      "Step : 1257, cost : 6.687101995339617e-05\n",
      "Step : 1258, cost : 6.675183976767585e-05\n",
      "Step : 1259, cost : 6.667237175861374e-05\n",
      "Step : 1260, cost : 6.657304766122252e-05\n",
      "Step : 1261, cost : 6.64737235638313e-05\n",
      "Step : 1262, cost : 6.637439946644008e-05\n",
      "Step : 1263, cost : 6.629493873333558e-05\n",
      "Step : 1264, cost : 6.621547800023109e-05\n",
      "Step : 1265, cost : 6.609629053855315e-05\n",
      "Step : 1266, cost : 6.601682252949104e-05\n",
      "Step : 1267, cost : 6.591749843209982e-05\n",
      "Step : 1268, cost : 6.58181743347086e-05\n",
      "Step : 1269, cost : 6.57387136016041e-05\n",
      "Step : 1270, cost : 6.565925286849961e-05\n",
      "Step : 1271, cost : 6.554005813086405e-05\n",
      "Step : 1272, cost : 6.546060467371717e-05\n",
      "Step : 1273, cost : 6.536127330036834e-05\n",
      "Step : 1274, cost : 6.528181256726384e-05\n",
      "Step : 1275, cost : 6.520235183415934e-05\n",
      "Step : 1276, cost : 6.508315709652379e-05\n",
      "Step : 1277, cost : 6.498383299913257e-05\n",
      "Step : 1278, cost : 6.492424290627241e-05\n",
      "Step : 1279, cost : 6.484478217316791e-05\n",
      "Step : 1280, cost : 6.472558743553236e-05\n",
      "Step : 1281, cost : 6.464612670242786e-05\n",
      "Step : 1282, cost : 6.456666596932337e-05\n",
      "Step : 1283, cost : 6.446734187193215e-05\n",
      "Step : 1284, cost : 6.438788113882765e-05\n",
      "Step : 1285, cost : 6.42686864011921e-05\n",
      "Step : 1286, cost : 6.420909630833194e-05\n",
      "Step : 1287, cost : 6.41097649349831e-05\n",
      "Step : 1288, cost : 6.403031147783622e-05\n",
      "Step : 1289, cost : 6.393098010448739e-05\n",
      "Step : 1290, cost : 6.385151209542528e-05\n",
      "Step : 1291, cost : 6.37720586382784e-05\n",
      "Step : 1292, cost : 6.365286390064284e-05\n",
      "Step : 1293, cost : 6.357341044349596e-05\n",
      "Step : 1294, cost : 6.351380579872057e-05\n",
      "Step : 1295, cost : 6.341448170132935e-05\n",
      "Step : 1296, cost : 6.331515760393813e-05\n",
      "Step : 1297, cost : 6.323569687083364e-05\n",
      "Step : 1298, cost : 6.313637277344242e-05\n",
      "Step : 1299, cost : 6.30569047643803e-05\n",
      "Step : 1300, cost : 6.297745130723342e-05\n",
      "Step : 1301, cost : 6.289798329817131e-05\n",
      "Step : 1302, cost : 6.277879583649337e-05\n",
      "Step : 1303, cost : 6.27191984676756e-05\n",
      "Step : 1304, cost : 6.26397377345711e-05\n",
      "Step : 1305, cost : 6.254041363717988e-05\n",
      "Step : 1306, cost : 6.244108226383105e-05\n",
      "Step : 1307, cost : 6.238149217097089e-05\n",
      "Step : 1308, cost : 6.228216807357967e-05\n",
      "Step : 1309, cost : 6.220270006451756e-05\n",
      "Step : 1310, cost : 6.210337596712634e-05\n",
      "Step : 1311, cost : 6.202391523402184e-05\n",
      "Step : 1312, cost : 6.194444722495973e-05\n",
      "Step : 1313, cost : 6.186498649185523e-05\n",
      "Step : 1314, cost : 6.178553303470835e-05\n",
      "Step : 1315, cost : 6.168620166135952e-05\n",
      "Step : 1316, cost : 6.160674092825502e-05\n",
      "Step : 1317, cost : 6.152728019515052e-05\n",
      "Step : 1318, cost : 6.144781946204603e-05\n",
      "Step : 1319, cost : 6.13484880886972e-05\n",
      "Step : 1320, cost : 6.12690273555927e-05\n",
      "Step : 1321, cost : 6.120943726273254e-05\n",
      "Step : 1322, cost : 6.11101058893837e-05\n",
      "Step : 1323, cost : 6.1010781791992486e-05\n",
      "Step : 1324, cost : 6.0951188061153516e-05\n",
      "Step : 1325, cost : 6.087172369007021e-05\n",
      "Step : 1326, cost : 6.075252895243466e-05\n",
      "Step : 1327, cost : 6.06929388595745e-05\n",
      "Step : 1328, cost : 6.0613470850512385e-05\n",
      "Step : 1329, cost : 6.053400647942908e-05\n",
      "Step : 1330, cost : 6.043468602001667e-05\n",
      "Step : 1331, cost : 6.0355221648933366e-05\n",
      "Step : 1332, cost : 6.027576091582887e-05\n",
      "Step : 1333, cost : 6.021616354701109e-05\n",
      "Step : 1334, cost : 6.0116839449619874e-05\n",
      "Step : 1335, cost : 6.001751171424985e-05\n",
      "Step : 1336, cost : 5.997778498567641e-05\n",
      "Step : 1337, cost : 5.9878453612327576e-05\n",
      "Step : 1338, cost : 5.9818859881488606e-05\n",
      "Step : 1339, cost : 5.969966878183186e-05\n",
      "Step : 1340, cost : 5.964006777503528e-05\n",
      "Step : 1341, cost : 5.956061067990959e-05\n",
      "Step : 1342, cost : 5.948114630882628e-05\n",
      "Step : 1343, cost : 5.938181493547745e-05\n",
      "Step : 1344, cost : 5.932222120463848e-05\n",
      "Step : 1345, cost : 5.924275683355518e-05\n",
      "Step : 1346, cost : 5.9143436374142766e-05\n",
      "Step : 1347, cost : 5.90838426433038e-05\n",
      "Step : 1348, cost : 5.900437827222049e-05\n",
      "Step : 1349, cost : 5.892491390113719e-05\n",
      "Step : 1350, cost : 5.884545316803269e-05\n",
      "Step : 1351, cost : 5.8765988796949387e-05\n",
      "Step : 1352, cost : 5.8686531701823696e-05\n",
      "Step : 1353, cost : 5.860706733074039e-05\n",
      "Step : 1354, cost : 5.852760295965709e-05\n",
      "Step : 1355, cost : 5.846800922881812e-05\n",
      "Step : 1356, cost : 5.8368681493448094e-05\n",
      "Step : 1357, cost : 5.8289220760343596e-05\n",
      "Step : 1358, cost : 5.822962339152582e-05\n",
      "Step : 1359, cost : 5.813029201817699e-05\n",
      "Step : 1360, cost : 5.807069828733802e-05\n",
      "Step : 1361, cost : 5.7991233916254714e-05\n",
      "Step : 1362, cost : 5.7891909818863496e-05\n",
      "Step : 1363, cost : 5.777270780527033e-05\n",
      "Step : 1364, cost : 5.767338370787911e-05\n",
      "Step : 1365, cost : 5.7633649703348055e-05\n",
      "Step : 1366, cost : 5.755418897024356e-05\n",
      "Step : 1367, cost : 5.743499787058681e-05\n",
      "Step : 1368, cost : 5.7395267504034564e-05\n",
      "Step : 1369, cost : 5.731580313295126e-05\n",
      "Step : 1370, cost : 5.7236338761867955e-05\n",
      "Step : 1371, cost : 5.7156881666742265e-05\n",
      "Step : 1372, cost : 5.709728065994568e-05\n",
      "Step : 1373, cost : 5.6997956562554464e-05\n",
      "Step : 1374, cost : 5.691849219147116e-05\n",
      "Step : 1375, cost : 5.687876182491891e-05\n",
      "Step : 1376, cost : 5.6779434089548886e-05\n",
      "Step : 1377, cost : 5.669996971846558e-05\n",
      "Step : 1378, cost : 5.666023935191333e-05\n",
      "Step : 1379, cost : 5.654104825225659e-05\n",
      "Step : 1380, cost : 5.648145088343881e-05\n",
      "Step : 1381, cost : 5.6421853514621034e-05\n",
      "Step : 1382, cost : 5.634239278151654e-05\n",
      "Step : 1383, cost : 5.626292841043323e-05\n",
      "Step : 1384, cost : 5.618347131530754e-05\n",
      "Step : 1385, cost : 5.610400694422424e-05\n",
      "Step : 1386, cost : 5.6024542573140934e-05\n",
      "Step : 1387, cost : 5.5964948842301965e-05\n",
      "Step : 1388, cost : 5.588548447121866e-05\n",
      "Step : 1389, cost : 5.580602373811416e-05\n",
      "Step : 1390, cost : 5.574642636929639e-05\n",
      "Step : 1391, cost : 5.568682900047861e-05\n",
      "Step : 1392, cost : 5.560736826737411e-05\n",
      "Step : 1393, cost : 5.550803689402528e-05\n",
      "Step : 1394, cost : 5.546830652747303e-05\n",
      "Step : 1395, cost : 5.538884943234734e-05\n",
      "Step : 1396, cost : 5.530938506126404e-05\n",
      "Step : 1397, cost : 5.5249784054467455e-05\n",
      "Step : 1398, cost : 5.517032332136296e-05\n",
      "Step : 1399, cost : 5.509085895027965e-05\n",
      "Step : 1400, cost : 5.501140185515396e-05\n",
      "Step : 1401, cost : 5.4951804486336187e-05\n",
      "Step : 1402, cost : 5.487234375323169e-05\n",
      "Step : 1403, cost : 5.4812742746435106e-05\n",
      "Step : 1404, cost : 5.47332783753518e-05\n",
      "Step : 1405, cost : 5.467368464451283e-05\n",
      "Step : 1406, cost : 5.461408363771625e-05\n",
      "Step : 1407, cost : 5.451475954032503e-05\n",
      "Step : 1408, cost : 5.4455162171507254e-05\n",
      "Step : 1409, cost : 5.437569416244514e-05\n",
      "Step : 1410, cost : 5.4316100431606174e-05\n",
      "Step : 1411, cost : 5.421677269623615e-05\n",
      "Step : 1412, cost : 5.41770423296839e-05\n",
      "Step : 1413, cost : 5.4097577958600596e-05\n",
      "Step : 1414, cost : 5.4037984227761626e-05\n",
      "Step : 1415, cost : 5.395851985667832e-05\n",
      "Step : 1416, cost : 5.389892612583935e-05\n",
      "Step : 1417, cost : 5.381946175475605e-05\n",
      "Step : 1418, cost : 5.370025246520527e-05\n",
      "Step : 1419, cost : 5.36406587343663e-05\n",
      "Step : 1420, cost : 5.352146763470955e-05\n",
      "Step : 1421, cost : 5.34817372681573e-05\n",
      "Step : 1422, cost : 5.3402272897074e-05\n",
      "Step : 1423, cost : 5.334267916623503e-05\n",
      "Step : 1424, cost : 5.328308543539606e-05\n",
      "Step : 1425, cost : 5.320361742633395e-05\n",
      "Step : 1426, cost : 5.3124153055250645e-05\n",
      "Step : 1427, cost : 5.30844263266772e-05\n",
      "Step : 1428, cost : 5.30049619555939e-05\n",
      "Step : 1429, cost : 5.294536458677612e-05\n",
      "Step : 1430, cost : 5.286590021569282e-05\n",
      "Step : 1431, cost : 5.280630648485385e-05\n",
      "Step : 1432, cost : 5.2726842113770545e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 1433, cost : 5.266724110697396e-05\n",
      "Step : 1434, cost : 5.2587780373869464e-05\n",
      "Step : 1435, cost : 5.252818300505169e-05\n",
      "Step : 1436, cost : 5.244872227194719e-05\n",
      "Step : 1437, cost : 5.2389124903129414e-05\n",
      "Step : 1438, cost : 5.232952753431164e-05\n",
      "Step : 1439, cost : 5.225006316322833e-05\n",
      "Step : 1440, cost : 5.217060606810264e-05\n",
      "Step : 1441, cost : 5.211100506130606e-05\n",
      "Step : 1442, cost : 5.2051404054509476e-05\n",
      "Step : 1443, cost : 5.1991810323670506e-05\n",
      "Step : 1444, cost : 5.193221659283154e-05\n",
      "Step : 1445, cost : 5.1852748583769426e-05\n",
      "Step : 1446, cost : 5.179315121495165e-05\n",
      "Step : 1447, cost : 5.171369048184715e-05\n",
      "Step : 1448, cost : 5.165408947505057e-05\n",
      "Step : 1449, cost : 5.15944957442116e-05\n",
      "Step : 1450, cost : 5.153489837539382e-05\n",
      "Step : 1451, cost : 5.1475301006576046e-05\n",
      "Step : 1452, cost : 5.141570363775827e-05\n",
      "Step : 1453, cost : 5.131637226440944e-05\n",
      "Step : 1454, cost : 5.125677489559166e-05\n",
      "Step : 1455, cost : 5.1177314162487164e-05\n",
      "Step : 1456, cost : 5.111771679366939e-05\n",
      "Step : 1457, cost : 5.105811942485161e-05\n",
      "Step : 1458, cost : 5.0998522056033835e-05\n",
      "Step : 1459, cost : 5.093892468721606e-05\n",
      "Step : 1460, cost : 5.085945667815395e-05\n",
      "Step : 1461, cost : 5.077999958302826e-05\n",
      "Step : 1462, cost : 5.074026921647601e-05\n",
      "Step : 1463, cost : 5.068067184765823e-05\n",
      "Step : 1464, cost : 5.0621074478840455e-05\n",
      "Step : 1465, cost : 5.056147711002268e-05\n",
      "Step : 1466, cost : 5.048200910096057e-05\n",
      "Step : 1467, cost : 5.0442282372387126e-05\n",
      "Step : 1468, cost : 5.036282163928263e-05\n",
      "Step : 1469, cost : 5.0283357268199325e-05\n",
      "Step : 1470, cost : 5.022375626140274e-05\n",
      "Step : 1471, cost : 5.0164158892584965e-05\n",
      "Step : 1472, cost : 5.010456152376719e-05\n",
      "Step : 1473, cost : 5.004496779292822e-05\n",
      "Step : 1474, cost : 4.996549978386611e-05\n",
      "Step : 1475, cost : 4.992576941731386e-05\n",
      "Step : 1476, cost : 4.9905909691005945e-05\n",
      "Step : 1477, cost : 4.9866179324453697e-05\n",
      "Step : 1478, cost : 4.97867185913492e-05\n",
      "Step : 1479, cost : 4.970725058228709e-05\n",
      "Step : 1480, cost : 4.964765685144812e-05\n",
      "Step : 1481, cost : 4.9588055844651535e-05\n",
      "Step : 1482, cost : 4.952845847583376e-05\n",
      "Step : 1483, cost : 4.946886110701598e-05\n",
      "Step : 1484, cost : 4.940926737617701e-05\n",
      "Step : 1485, cost : 4.934966636938043e-05\n",
      "Step : 1486, cost : 4.929006900056265e-05\n",
      "Step : 1487, cost : 4.92503349960316e-05\n",
      "Step : 1488, cost : 4.919074126519263e-05\n",
      "Step : 1489, cost : 4.9111276894109324e-05\n",
      "Step : 1490, cost : 4.9071546527557075e-05\n",
      "Step : 1491, cost : 4.8992078518494964e-05\n",
      "Step : 1492, cost : 4.8932484787655994e-05\n",
      "Step : 1493, cost : 4.885302041657269e-05\n",
      "Step : 1494, cost : 4.881329005002044e-05\n",
      "Step : 1495, cost : 4.8753692681202665e-05\n",
      "Step : 1496, cost : 4.8674224672140554e-05\n",
      "Step : 1497, cost : 4.8634494305588305e-05\n",
      "Step : 1498, cost : 4.8555029934505e-05\n",
      "Step : 1499, cost : 4.851529956795275e-05\n",
      "Step : 1500, cost : 4.843583519686945e-05\n"
     ]
    }
   ],
   "source": [
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    X = tf.placeholder(tf.float32)\n",
    "    Y = tf.placeholder(tf.float32)\n",
    "    with tf.name_scope('Layer1'):\n",
    "        W = tf.Variable(tf.random_uniform([2, 10], -1, 1))\n",
    "        b = tf.Variable(tf.random_uniform([10]))\n",
    "        L1 = tf.add(tf.matmul(X, W), b)\n",
    "        L1 = tf.nn.relu(L1)\n",
    "    with tf.name_scope('Layer2'):\n",
    "        W2 = tf.Variable(tf.random_uniform([10, 20], -1, 1))\n",
    "        b2 = tf.Variable(tf.random_uniform([20]))\n",
    "        L2 = tf.add(tf.matmul(L1, W2), b2)\n",
    "        L2 = tf.nn.relu(L2)\n",
    "    with tf.name_scope('output'):\n",
    "        W3 = tf.Variable(tf.random_uniform([20, 3], -1, 1))\n",
    "        b3 = tf.Variable(tf.random_uniform([3]))\n",
    "        L3 = tf.add(tf.matmul(L2, W3), b3)\n",
    "    with tf.name_scope('optimizer'):\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=L3))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.01).minimize(cost, global_step = global_step)\n",
    "tf.summary.scalar('cost', cost)\n",
    "tf.summary.histogram('weight1', W)\n",
    "tf.summary.histogram('weight2', W2)\n",
    "tf.summary.histogram('weight3', W3)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "prediction = tf.argmax(tf.nn.softmax(L3), axis = 1)\n",
    "target = tf.argmax(Y, axis = 1)\n",
    "accuracy = tf.metrics.accuracy(target, prediction)\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter('./logs', sess.graph)\n",
    "    ckpt = tf.train.get_checkpoint_state('./model')\n",
    "    \n",
    "    if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "    for step in range(500):\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict = {X: x_data, Y: y_data})\n",
    "        summ = sess.run(merged, feed_dict = {X: x_data, Y: y_data})\n",
    "        print('Step : {}, cost : {}'.format(sess.run(global_step), c))\n",
    "        writer.add_summary(summ, global_step= sess.run(global_step))\n",
    "    saver.save(sess, './model/dnn2.ckpt', global_step=global_step)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!tensorboard --logdir=./logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\\dnn.ckpt-2\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Key Variable_3/Adam not found in checkpoint\n\t [[Node: save_1/RestoreV2_10 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_10/tensor_names, save_1/RestoreV2_10/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_10/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_114_save_1/RestoreV2_10\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'save_1/RestoreV2_10', defined at:\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-52-5f07597da086>\", line 38, in <module>\n    saver = tf.train.Saver(tf.global_variables())\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1056, in __init__\n    self.build()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 669, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Key Variable_3/Adam not found in checkpoint\n\t [[Node: save_1/RestoreV2_10 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_10/tensor_names, save_1/RestoreV2_10/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_10/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_114_save_1/RestoreV2_10\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key Variable_3/Adam not found in checkpoint\n\t [[Node: save_1/RestoreV2_10 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_10/tensor_names, save_1/RestoreV2_10/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_10/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_114_save_1/RestoreV2_10\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-5f07597da086>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mckpt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_checkpoint_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mckpt\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Restoring parameters from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1457\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key Variable_3/Adam not found in checkpoint\n\t [[Node: save_1/RestoreV2_10 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_10/tensor_names, save_1/RestoreV2_10/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_10/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_114_save_1/RestoreV2_10\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'save_1/RestoreV2_10', defined at:\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-52-5f07597da086>\", line 38, in <module>\n    saver = tf.train.Saver(tf.global_variables())\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1056, in __init__\n    self.build()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 669, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Key Variable_3/Adam not found in checkpoint\n\t [[Node: save_1/RestoreV2_10 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_10/tensor_names, save_1/RestoreV2_10/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_10/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_114_save_1/RestoreV2_10\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "# 학습에 직접적으로 사용하지 않고 학습 횟수에 따라 단순히 증가시킬 변수를 만듭니다.\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([2, 10], -1., 1.))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([10, 20], -1., 1.))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "\n",
    "W3 = tf.Variable(tf.random_uniform([20, 3], -1., 1.))\n",
    "model = tf.matmul(L2, W3)\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=model))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "# global_step로 넘겨준 변수를, 학습용 변수들을 최적화 할 때 마다 학습 횟수를 하나씩 증가시킵니다.\n",
    "train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "\n",
    "\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "sess = tf.Session()\n",
    "# 모델을 저장하고 불러오는 API를 초기화합니다.\n",
    "# global_variables 함수를 통해 앞서 정의하였던 변수들을 저장하거나 불러올 변수들로 설정합니다.\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state('./model')\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 최적화 진행\n",
    "for step in range(2):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    print('Step: %d, ' % sess.run(global_step),\n",
    "          'Cost: %.3f' % sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "# 최적화가 끝난 뒤, 변수를 저장합니다.\n",
    "saver.save(sess, './model/dnn.ckpt', global_step=global_step)\n",
    "\n",
    "#########\n",
    "# 결과 확인\n",
    "# 0: 기타 1: 포유류, 2: 조류\n",
    "######\n",
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "print('예측값:', sess.run(prediction, feed_dict={X: x_data}))\n",
    "print('실제값:', sess.run(target, feed_dict={Y: y_data}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1,  Cost: 0.952\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_8' with dtype float\n\t [[Node: Placeholder_8 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: optimizer_3/Mean/_63 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_254_optimizer_3/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Placeholder_8', defined at:\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-61-bcd5bf177eb5>\", line 2, in <module>\n    X = tf.placeholder(tf.float32)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1507, in placeholder\n    name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 1997, in _placeholder\n    name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_8' with dtype float\n\t [[Node: Placeholder_8 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: optimizer_3/Mean/_63 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_254_optimizer_3/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_8' with dtype float\n\t [[Node: Placeholder_8 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: optimizer_3/Mean/_63 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_254_optimizer_3/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-b022236bfe19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[1;31m# 적절한 시점에 저장할 값들을 수집하고 저장합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0msummary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_8' with dtype float\n\t [[Node: Placeholder_8 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: optimizer_3/Mean/_63 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_254_optimizer_3/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Placeholder_8', defined at:\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-61-bcd5bf177eb5>\", line 2, in <module>\n    X = tf.placeholder(tf.float32)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1507, in placeholder\n    name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 1997, in _placeholder\n    name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_8' with dtype float\n\t [[Node: Placeholder_8 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: optimizer_3/Mean/_63 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_254_optimizer_3/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# with tf.name_scope 으로 묶은 블럭은 텐서보드에서 한 레이어안에 표현해줍니다\n",
    "with tf.name_scope('layer1'):\n",
    "    W1 = tf.Variable(tf.random_uniform([2, 10], -1., 1.), name='W1')\n",
    "    L1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "\n",
    "with tf.name_scope('layer2'):\n",
    "    W2 = tf.Variable(tf.random_uniform([10, 20], -1., 1.), name='W2')\n",
    "    L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "\n",
    "with tf.name_scope('output'):\n",
    "    W3 = tf.Variable(tf.random_uniform([20, 3], -1., 1.), name='W3')\n",
    "    model = tf.matmul(L2, W3)\n",
    "\n",
    "with tf.name_scope('optimizer'):\n",
    "    cost = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=model))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "\n",
    "    # tf.summary.scalar 를 이용해 수집하고 싶은 값들을 지정할 수 있습니다.\n",
    "    tf.summary.scalar('cost', cost)\n",
    "\n",
    "\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state('./model')\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 텐서보드에서 표시해주기 위한 텐서들을 수집합니다.\n",
    "merged = tf.summary.merge_all()\n",
    "# 저장할 그래프와 텐서값들을 저장할 디렉토리를 설정합니다.\n",
    "writer = tf.summary.FileWriter('./logs', sess.graph)\n",
    "# 이렇게 저장한 로그는, 학습 후 다음의 명령어를 이용해 웹서버를 실행시킨 뒤\n",
    "# tensorboard --logdir=./logs\n",
    "# 다음 주소와 웹브라우저를 이용해 텐서보드에서 확인할 수 있습니다.\n",
    "# http://localhost:6006\n",
    "\n",
    "# 최적화 진행\n",
    "for step in range(100):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    print('Step: %d, ' % sess.run(global_step),\n",
    "          'Cost: %.3f' % sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "    # 적절한 시점에 저장할 값들을 수집하고 저장합니다.\n",
    "    summary = sess.run(merged, feed_dict={X: x_data, Y: y_data})\n",
    "    writer.add_summary(summary, global_step=sess.run(global_step))\n",
    "\n",
    "saver.save(sess, './model/dnn.ckpt', global_step=global_step)\n",
    "\n",
    "#########\n",
    "# 결과 확인\n",
    "# 0: 기타 1: 포유류, 2: 조류\n",
    "######\n",
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "print('예측값:', sess.run(prediction, feed_dict={X: x_data}))\n",
    "print('실제값:', sess.run(target, feed_dict={Y: y_data}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
