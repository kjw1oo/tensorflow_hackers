{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('./mnist/data/', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, cost: 0.565647977753119, accuracy: [0.9327001]\n",
      "epoch: 1, cost: 0.18339841230349108, accuracy: [0.95580018]\n",
      "epoch: 2, cost: 0.1215089893645861, accuracy: [0.96630013]\n",
      "epoch: 3, cost: 0.0889964967864481, accuracy: [0.97290015]\n",
      "epoch: 4, cost: 0.06859741344370625, accuracy: [0.97370011]\n",
      "epoch: 5, cost: 0.05450161150402644, accuracy: [0.9703002]\n",
      "epoch: 6, cost: 0.04262884056788276, accuracy: [0.97540021]\n",
      "epoch: 7, cost: 0.03474905598823997, accuracy: [0.97510016]\n",
      "epoch: 8, cost: 0.028327038006179712, accuracy: [0.97630012]\n",
      "epoch: 9, cost: 0.023062253095400095, accuracy: [0.97700012]\n",
      "epoch: 10, cost: 0.018911648366960104, accuracy: [0.97820008]\n",
      "epoch: 11, cost: 0.01572975490443324, accuracy: [0.97710013]\n",
      "epoch: 12, cost: 0.013795616331732494, accuracy: [0.97510016]\n",
      "epoch: 13, cost: 0.011182634777452965, accuracy: [0.97640014]\n",
      "epoch: 14, cost: 0.013350546640285756, accuracy: [0.97580016]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "with tf.device('/cpu:0'):\n",
    "    W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "    b1 = tf.Variable(tf.random_normal([256]))\n",
    "    L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "    W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "    b2 = tf.Variable(tf.random_normal([256]))\n",
    "    L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "    W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "    b3 = tf.Variable(tf.random_normal([10]))\n",
    "    L3 = tf.matmul(L2, W3) + b3\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = Y, logits = L3))\n",
    "    train = tf.train.AdamOptimizer(1e-3).minimize(cost)\n",
    "\n",
    "prediction = tf.argmax(tf.nn.softmax(L3), 1)\n",
    "labels = tf.argmax(Y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, labels), tf.float32))\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for epoch in range(15):\n",
    "        total_cost = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            _, c = sess.run([train, cost], feed_dict = {X: batch_xs, Y: batch_ys})\n",
    "            total_cost += c\n",
    "        acc = sess.run([accuracy], feed_dict = {X: mnist.test.images, Y: mnist.test.labels})\n",
    "        print('epoch: {}, cost: {}, accuracy: {}'.format(epoch, total_cost/total_batch, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "def build_net_batch_norm(x, activation, is_training, reuse = None):\n",
    "   # L1 = tf.layers.batch_normalization(x, training = is_training, reuse = reuse)\n",
    "    L1 = tf.layers.dense(x, 256, reuse = reuse, name = 'L1_batch')\n",
    "    L1 = tf.layers.batch_normalization(L1, training = is_training)\n",
    "    L1 = activation(L1)\n",
    "    L1 = tf.layers.dropout(L1, 0.3, training=is_training)\n",
    "    \n",
    "    L2 = tf.layers.dense(L1, 256,  reuse = reuse, name = 'L2_batch')\n",
    "    L2 = tf.layers.batch_normalization(L2, training = is_training)\n",
    "    L2 = activation(L2)\n",
    "    L2 = tf.layers.dropout(L2, 0.3, training=is_training)\n",
    "    \n",
    "    output = tf.layers.dense(L2, 10, reuse = reuse, name = 'L3_batch')\n",
    "    return output   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_net(x, activation, is_training, reuse = None):\n",
    "   # L1 = tf.layers.batch_normalization(x, training = is_training, reuse = reuse)\n",
    "    L1 = tf.layers.dense(x, 256, reuse = reuse, name = 'L1')\n",
    "    L1 = activation(L1)\n",
    "    \n",
    "    L2 = tf.layers.dense(L1, 256,  reuse = reuse, name = 'L2')\n",
    "    L2 = activation(L2)\n",
    "    \n",
    "    output = tf.layers.dense(L2, 10, reuse = reuse, name = 'L3')\n",
    "    return output   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    logits_batch = build_net_batch_norm(X, tf.nn.relu, True)\n",
    "    output_batch = build_net_batch_norm(X, tf.nn.relu, False, reuse = True)\n",
    "    cost_batch = tf.reduce_mean(tf.losses.softmax_cross_entropy(Y, logits_batch))\n",
    "\n",
    "#with tf.control_dependencies(extra_update_ops):\n",
    "train_batch = tf.train.AdamOptimizer(0.01).minimize(cost_batch)\n",
    "\n",
    "\n",
    "\n",
    "accuracy_batch = tf.metrics.accuracy(tf.argmax(Y, 1), tf.argmax(tf.nn.softmax(output_batch), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4b789c850f84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mextra_update_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUPDATE_OPS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'build_net' is not defined"
     ]
    }
   ],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "logits = build_net(X, tf.nn.relu, True)\n",
    "output = build_net(X, tf.nn.relu, False, reuse = True)\n",
    "cost = tf.reduce_mean(tf.losses.softmax_cross_entropy(Y, logits))\n",
    "\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train = tf.train.AdamOptimizer(0.01).minimize(cost)\n",
    "\n",
    "\n",
    "\n",
    "accuracy = tf.metrics.accuracy(tf.argmax(Y, 1), tf.argmax(tf.nn.softmax(output), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, cost: 0.24070071481845595, accuracy: [(0.0, 0.94919997)]\n",
      "epoch: 1, cost: 0.1387631998041814, accuracy: [(0.94919997, 0.95270002)]\n",
      "epoch: 2, cost: 0.12201243366792121, accuracy: [(0.95270002, 0.95499998)]\n",
      "epoch: 3, cost: 0.10665283208374272, accuracy: [(0.95499998, 0.95740002)]\n",
      "epoch: 4, cost: 0.09982649514155294, accuracy: [(0.95740002, 0.95986003)]\n",
      "epoch: 5, cost: 0.09065829710484567, accuracy: [(0.95986003, 0.96108335)]\n",
      "epoch: 6, cost: 0.08295000379672274, accuracy: [(0.96108335, 0.96192855)]\n",
      "epoch: 7, cost: 0.07838856377003883, accuracy: [(0.96192855, 0.96249998)]\n",
      "epoch: 8, cost: 0.0746744273330974, accuracy: [(0.96249998, 0.96338886)]\n",
      "epoch: 9, cost: 0.0840728684372946, accuracy: [(0.96338886, 0.96379)]\n",
      "epoch: 10, cost: 0.06972372749418189, accuracy: [(0.96379, 0.9647091)]\n",
      "epoch: 11, cost: 0.06685490308117799, accuracy: [(0.9647091, 0.96524167)]\n",
      "epoch: 12, cost: 0.0613623296494056, accuracy: [(0.96524167, 0.96523845)]\n",
      "epoch: 13, cost: 0.05700320681752187, accuracy: [(0.96523845, 0.9655)]\n",
      "epoch: 14, cost: 0.060530585278240984, accuracy: [(0.9655, 0.96580666)]\n",
      "epoch: 15, cost: 0.0634854063915819, accuracy: [(0.96580666, 0.96612501)]\n",
      "epoch: 16, cost: 0.05531074007225636, accuracy: [(0.96612501, 0.96644706)]\n",
      "epoch: 17, cost: 0.04992197636725905, accuracy: [(0.96644706, 0.96662778)]\n",
      "epoch: 18, cost: 0.04619003809696799, accuracy: [(0.96662778, 0.96678424)]\n",
      "epoch: 19, cost: 0.0596697740550272, accuracy: [(0.96678424, 0.966905)]\n",
      "epoch: 20, cost: 0.05200985637406947, accuracy: [(0.966905, 0.96689045)]\n",
      "epoch: 21, cost: 0.050846961158280135, accuracy: [(0.96689045, 0.96698636)]\n",
      "epoch: 22, cost: 0.05164896874360486, accuracy: [(0.96698636, 0.9673)]\n",
      "epoch: 23, cost: 0.041090992870739765, accuracy: [(0.9673, 0.96753752)]\n",
      "epoch: 24, cost: 0.04166349462264076, accuracy: [(0.96753752, 0.96767199)]\n",
      "epoch: 25, cost: 0.04271038724314332, accuracy: [(0.96767199, 0.96793461)]\n",
      "epoch: 26, cost: 0.041841311033538, accuracy: [(0.96793461, 0.96818149)]\n",
      "epoch: 27, cost: 0.03912623114755496, accuracy: [(0.96818149, 0.96820712)]\n",
      "epoch: 28, cost: 0.047345014461299635, accuracy: [(0.96820712, 0.96830344)]\n",
      "epoch: 29, cost: 0.049572618196970404, accuracy: [(0.96830344, 0.96840668)]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for epoch in range(30):\n",
    "        total_cost = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            _, c = sess.run([train, cost], feed_dict = {X: batch_xs, Y: batch_ys})\n",
    "            total_cost += c\n",
    "        acc = sess.run([accuracy], feed_dict = {X: mnist.test.images, Y: mnist.test.labels})\n",
    "        print('epoch: {}, cost: {}, accuracy: {}'.format(epoch, total_cost/total_batch, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(100, 10), b.shape=(256, 10), m=100, n=256, k=10\n\t [[Node: gradients/L3_batch/MatMul_grad/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/L3_batch/BiasAdd_grad/tuple/control_dependency, L3_batch/kernel/read/_89)]]\n\t [[Node: gradients/batch_normalization/Reshape_1_grad/Reshape/_145 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1055_gradients/batch_normalization/Reshape_1_grad/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'gradients/L3_batch/MatMul_grad/MatMul', defined at:\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-7365c551f11e>\", line 8, in <module>\n    train_batch = tf.train.AdamOptimizer(0.01).minimize(cost_batch)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 315, in minimize\n    grad_loss=grad_loss)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 386, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 560, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 368, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 560, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\", line 783, in _MatMulGrad\n    grad_a = math_ops.matmul(grad, b, transpose_b=True)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1801, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1263, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'L3_batch/MatMul', defined at:\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 18 identical lines from previous traceback]\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-7365c551f11e>\", line 3, in <module>\n    logits_batch = build_net_batch_norm(X, tf.nn.relu, True)\n  File \"<ipython-input-12-f9e3e2a1f4aa>\", line 16, in build_net_batch_norm\n    output = tf.layers.dense(L2, 10, reuse = reuse, name = 'L3_batch')\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\", line 218, in dense\n    return layer.apply(inputs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 320, in apply\n    return self.__call__(inputs, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 290, in __call__\n    outputs = self.call(inputs, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\", line 144, in call\n    outputs = standard_ops.matmul(inputs, self.kernel)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1801, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1263, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(100, 10), b.shape=(256, 10), m=100, n=256, k=10\n\t [[Node: gradients/L3_batch/MatMul_grad/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/L3_batch/BiasAdd_grad/tuple/control_dependency, L3_batch/kernel/read/_89)]]\n\t [[Node: gradients/batch_normalization/Reshape_1_grad/Reshape/_145 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1055_gradients/batch_normalization/Reshape_1_grad/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(100, 10), b.shape=(256, 10), m=100, n=256, k=10\n\t [[Node: gradients/L3_batch/MatMul_grad/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/L3_batch/BiasAdd_grad/tuple/control_dependency, L3_batch/kernel/read/_89)]]\n\t [[Node: gradients/batch_normalization/Reshape_1_grad/Reshape/_145 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1055_gradients/batch_normalization/Reshape_1_grad/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-bbd60075e04a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost_batch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mtotal_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maccuracy_batch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(100, 10), b.shape=(256, 10), m=100, n=256, k=10\n\t [[Node: gradients/L3_batch/MatMul_grad/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/L3_batch/BiasAdd_grad/tuple/control_dependency, L3_batch/kernel/read/_89)]]\n\t [[Node: gradients/batch_normalization/Reshape_1_grad/Reshape/_145 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1055_gradients/batch_normalization/Reshape_1_grad/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'gradients/L3_batch/MatMul_grad/MatMul', defined at:\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-7365c551f11e>\", line 8, in <module>\n    train_batch = tf.train.AdamOptimizer(0.01).minimize(cost_batch)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 315, in minimize\n    grad_loss=grad_loss)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 386, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 560, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 368, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 560, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\", line 783, in _MatMulGrad\n    grad_a = math_ops.matmul(grad, b, transpose_b=True)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1801, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1263, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'L3_batch/MatMul', defined at:\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 18 identical lines from previous traceback]\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-7365c551f11e>\", line 3, in <module>\n    logits_batch = build_net_batch_norm(X, tf.nn.relu, True)\n  File \"<ipython-input-12-f9e3e2a1f4aa>\", line 16, in build_net_batch_norm\n    output = tf.layers.dense(L2, 10, reuse = reuse, name = 'L3_batch')\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\", line 218, in dense\n    return layer.apply(inputs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 320, in apply\n    return self.__call__(inputs, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 290, in __call__\n    outputs = self.call(inputs, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\", line 144, in call\n    outputs = standard_ops.matmul(inputs, self.kernel)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1801, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1263, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(100, 10), b.shape=(256, 10), m=100, n=256, k=10\n\t [[Node: gradients/L3_batch/MatMul_grad/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/L3_batch/BiasAdd_grad/tuple/control_dependency, L3_batch/kernel/read/_89)]]\n\t [[Node: gradients/batch_normalization/Reshape_1_grad/Reshape/_145 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1055_gradients/batch_normalization/Reshape_1_grad/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for epoch in range(30):\n",
    "        total_cost = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            _, c = sess.run([train_batch, cost_batch], feed_dict = {X: batch_xs, Y: batch_ys})\n",
    "            total_cost += c\n",
    "        acc = sess.run([accuracy_batch], feed_dict = {X: mnist.test.images, Y: mnist.test.labels})\n",
    "        print('epoch: {}, cost: {}, accuracy: {}'.format(epoch, total_cost/total_batch, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
