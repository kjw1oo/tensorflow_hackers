{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./mnist/data/', one_hot = True)\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#residual learning\n",
    "# f(x) + x\n",
    "# original resnet : 본래 분기되기전에 활성화 함수 적용 \n",
    "# this resnet : 분기된 이후 shortcut은 그냥 냅두고 weight path의 weight layer 앞에 활성화함수를 두는 pre_activation 설정\n",
    "# regularization 효과\n",
    "\n",
    "def residual_unit(inputs, n_filter,  strides, name, short_cut = True, is_training = True, reuse = False):\n",
    "    # 쇼트컷 (residual) 설정\n",
    "    shortcut = inputs\n",
    "    if short_cut:\n",
    "        shortcut = tf.layers.conv2d(inputs = shortcut,\n",
    "                                    filters = n_filter,\n",
    "                                    kernel_size= 1,\n",
    "                                    strides = strides,\n",
    "                                    padding = 'SAME',\n",
    "                                    name = name + 'shortcut',\n",
    "                                    reuse =reuse)\n",
    "        \n",
    "    #pre_activation\n",
    "    L = tf.layers.batch_normalization(inputs, training = is_training, name = name + 'BN1', reuse = reuse)\n",
    "    L = tf.nn.relu(L)\n",
    "    # convolution (weight layer)\n",
    "    L = tf.layers.conv2d(inputs = L,\n",
    "                         filters = n_filter,\n",
    "                         kernel_size = 3,\n",
    "                         strides = strides,\n",
    "                         padding = 'SAME',\n",
    "                         name = name + 'conv1',\n",
    "                         reuse = reuse)\n",
    "    L = tf.layers.batch_normalization(L, training = is_training, name = name + 'BN2', reuse = reuse)\n",
    "    L = tf.nn.relu(L)\n",
    "    # 블럭의 마지막 layer는 언제나 strides = 1로 하여야한다.\n",
    "    L = tf.layers.conv2d(inputs = L,\n",
    "                         filters = n_filter,\n",
    "                         kernel_size = 3,\n",
    "                         strides = 1,\n",
    "                         padding = 'SAME',\n",
    "                         name = name + 'conv2',\n",
    "                         reuse = reuse)\n",
    "    \n",
    "    return L + shortcut\n",
    "    \n",
    " # 학습에 걸리는 시간을 고려해서 50 layer 이상에서는 bottle_neck 구조를 사용한다.\n",
    "# bottle_neck구조는 output filter의 갯수가 4배로 증가되어 병부리처럼 보여서 bottle_neck이라고 한다.\n",
    "def bottle_neck_unit(inputs, n_filter, strides, name, short_cut = True, is_training = True, reuse = False):\n",
    "    shortcut = inputs\n",
    "    # bottle_neck 레이어에서는 output filter의 갯수가 input filter 갯수의 4배\n",
    "    n_filter_out = n_filter\n",
    "    if short_cut:\n",
    "        shortcut = tf.layers.conv2d(inputs = shortcut,\n",
    "                                    filters = n_filter_out,\n",
    "                                    kernel_size= 1,\n",
    "                                    strides = strides,\n",
    "                                    padding = 'SAME',\n",
    "                                    name = name + 'shortcut',\n",
    "                                    reuse =reuse)\n",
    "        \n",
    "    # pre_activation\n",
    "    L =  tf.layers.batch_normalization(inputs, training = is_training, name = name + 'BN1', reuse = reuse)\n",
    "    L = tf.nn.relu(L)\n",
    "    # 첫번째 레이어 conv 1x1\n",
    "    L = tf.layers.conv2d(inputs = L,\n",
    "                         filters = n_filter,\n",
    "                         kernel_size = 1,\n",
    "                         strides = 1,\n",
    "                         padding = 'SAME',\n",
    "                         name = name + 'conv1',\n",
    "                         reuse=reuse)\n",
    "    \n",
    "    L =  tf.layers.batch_normalization(inputs, training = is_training, name = name + 'BN2', reuse = reuse)\n",
    "    L = tf.nn.relu(L)\n",
    "    # 두번쨰 레이어 conv 3x3, strides = strides\n",
    "    L = tf.layers.conv2d(inputs = L,\n",
    "                         filters = n_filter,\n",
    "                         kernel_size = 3,\n",
    "                         strides = strides,\n",
    "                         padding = 'SAME',\n",
    "                         name = name + 'conv2',\n",
    "                         reuse=reuse)\n",
    "    L =  tf.layers.batch_normalization(inputs, training = is_training, name = name + 'BN3', reuse = reuse)\n",
    "    L = tf.nn.relu(L)\n",
    "    # 세번째 레이어 conv 1x1, n_filter x 4\n",
    "    L = tf.layers.conv2d(inputs = L,\n",
    "                         filters = n_filter_out,\n",
    "                         kernel_size = 1,\n",
    "                         strides = 1,\n",
    "                         padding = 'SAME',\n",
    "                         name = name + 'conv3',\n",
    "                         reuse=reuse)\n",
    "    \n",
    "    return L + shortcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. params 에서 각 블럭레이어에서 어떤 블럭을 몇개 쌓을 것인지 결정한다.( 34 layer기준 3, 4, 6, 3 residual_net)\n",
    "# 2. 첫번째 블럭은 strides를 2로 설정하여 이미지 크기를 줄인다.\n",
    "# 3. 나머지 블럭은 strides를 1로 설정.\n",
    "def block_layer(inputs, n_filter, strides, name, n_block, is_bottleneck = False, is_training = True, reuse = False):\n",
    "    # bottleneck_layer를 사용한다면\n",
    "    if is_bottleneck:\n",
    "        # 첫번째 블럭은 strides 파라미터 받은데로 설정(이미지 크기 1/2)\n",
    "        L = bottle_neck_unit(inputs, n_filter, strides, name+'_bottle_neck_1_', is_training = is_training, reuse = reuse)\n",
    "        # 나머지 블럭은 strides를 1로 설정(이미지 크기 보존)\n",
    "        for i in range(2, n_block + 1):\n",
    "            L = bottle_neck_unit(inputs, n_filter, 1, name+'_bottle_neck_'+ str(i) + '_', is_training = is_training, reuse = reuse)\n",
    "    else:\n",
    "        # 첫번째 블럭은 strides 파라미터 받은데로 설정(이미지 크기 1/2)\n",
    "        L = residual_unit(inputs, n_filter, strides, name+'_residual_unit_1_', is_training = is_training, reuse = reuse)\n",
    "        # 나머지 블럭은 strides를 1로 설정(이미지 크기 보존)\n",
    "        for i in range(2, n_block + 1):\n",
    "            L = residual_unit(inputs, n_filter, 1, name+'_residual_unit_'+ str(i) + '_', is_training = is_training, reuse = reuse)\n",
    "    return L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits(inputs, resnet_params, is_training = True, reuse = False):\n",
    "    \n",
    "    start_n_filters = resnet_params['start_n_filters']\n",
    "    start_strides = resnet_params['start_strides']\n",
    "    n_filters = resnet_params['n_filters']\n",
    "    n_blocks = resnet_params['n_blocks']\n",
    "    is_bottlenecks = resnet_params['is_bottlenecks']\n",
    "    layers_strides = resnet_params['layers_strides']\n",
    "    layer_number = range(1, len(n_blocks) + 1)\n",
    "    \n",
    "    \n",
    "    # 첫번째는 먼저 conv 3x3 시행 128x32 -> 64 x 16 \n",
    "    L = tf.layers.conv2d(inputs = inputs,\n",
    "                         filters = start_n_filters,\n",
    "                         kernel_size = 3,\n",
    "                         strides = start_strides,\n",
    "                         padding = 'SAME',\n",
    "                         name = 'begin_conv',\n",
    "                         reuse = reuse)\n",
    "    # 크기가 큰경우는 max_pooling을 거치나 여기는 그렇게 크지않으므로 제외\n",
    "    # strides = [1, 2, 2] 기준\n",
    "    # 첫번째 layer image size : 64 x16 -> 64 x 16\n",
    "    # 두번째 layer image size : 64 x 16 -> 32 x 8\n",
    "    # 세번째 layer image size : 32 x 8 -> 16 x 4\n",
    "    for i, n_filter, strides, n_block, is_bottleneck in zip(layer_number, n_filters, layers_strides, n_blocks, is_bottlenecks):\n",
    "        L = block_layer(inputs = L,\n",
    "                        n_filter = n_filter,\n",
    "                        strides = strides,\n",
    "                        name = 'block'+str(i),\n",
    "                        n_block = n_block,\n",
    "                        is_bottleneck = is_bottleneck,\n",
    "                        reuse = reuse)\n",
    "        \n",
    "    #마지막 batch_norm and activation function\n",
    "    outputs =  tf.layers.batch_normalization(L, training = is_training, name='final_BN', reuse = reuse)\n",
    "    outputs = tf.nn.relu(L)\n",
    "    # global average_pooling\n",
    "    # shape : (batch_size, height, width, n_feature_map)\n",
    "    shape = outputs.get_shape().as_list()\n",
    "    # 글로벌 풀링 사이즈 (height, width)\n",
    "    pool_size = (shape[1], shape[2])\n",
    "    outputs= tf.layers.average_pooling2d(outputs, pool_size = pool_size, strides = 1, padding = 'VALID')\n",
    "    # 마지막 dense layer\n",
    "    outputs = tf.layers.flatten(outputs)\n",
    "    outputs = tf.layers.dense(outputs, 10, name = 'final_dense', reuse=reuse)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_params = {\n",
    "    'num'\n",
    "    'start_n_filters': 16, # 첫 시작 convolution layer의 n_filter\n",
    "    'start_strides': 1,  # 첫 시작 convolution layer의 strides\n",
    "    'n_filters': [16, 32, 64], # 각 레이어에 할당된 filter의 수\n",
    "    'layers_strides': [1, 2, 2],\n",
    "    'n_blocks': [2, 2, 2], # 각 레이어에 할당된블럭의 수 \n",
    "    'is_bottlenecks': [False, False, False], # bottle_neck을 사용하면 True, 일반 residual_net사용한다면 False\n",
    "       \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number : 0 )) <tf.Variable 'model/begin_conv/kernel:0' shape=(3, 3, 1, 16) dtype=float32_ref>\n",
      "number : 1 )) <tf.Variable 'model/begin_conv/bias:0' shape=(16,) dtype=float32_ref>\n",
      "number : 2 )) <tf.Variable 'model/block1_residual_unit_1_shortcut/kernel:0' shape=(1, 1, 16, 16) dtype=float32_ref>\n",
      "number : 3 )) <tf.Variable 'model/block1_residual_unit_1_shortcut/bias:0' shape=(16,) dtype=float32_ref>\n",
      "number : 4 )) <tf.Variable 'model/block1_residual_unit_1_BN1/gamma:0' shape=(16,) dtype=float32_ref>\n",
      "number : 5 )) <tf.Variable 'model/block1_residual_unit_1_BN1/beta:0' shape=(16,) dtype=float32_ref>\n",
      "number : 6 )) <tf.Variable 'model/block1_residual_unit_1_conv1/kernel:0' shape=(3, 3, 16, 16) dtype=float32_ref>\n",
      "number : 7 )) <tf.Variable 'model/block1_residual_unit_1_conv1/bias:0' shape=(16,) dtype=float32_ref>\n",
      "number : 8 )) <tf.Variable 'model/block1_residual_unit_1_BN2/gamma:0' shape=(16,) dtype=float32_ref>\n",
      "number : 9 )) <tf.Variable 'model/block1_residual_unit_1_BN2/beta:0' shape=(16,) dtype=float32_ref>\n",
      "number : 10 )) <tf.Variable 'model/block1_residual_unit_1_conv2/kernel:0' shape=(3, 3, 16, 16) dtype=float32_ref>\n",
      "number : 11 )) <tf.Variable 'model/block1_residual_unit_1_conv2/bias:0' shape=(16,) dtype=float32_ref>\n",
      "number : 12 )) <tf.Variable 'model/block1_residual_unit_2_shortcut/kernel:0' shape=(1, 1, 16, 16) dtype=float32_ref>\n",
      "number : 13 )) <tf.Variable 'model/block1_residual_unit_2_shortcut/bias:0' shape=(16,) dtype=float32_ref>\n",
      "number : 14 )) <tf.Variable 'model/block1_residual_unit_2_BN1/gamma:0' shape=(16,) dtype=float32_ref>\n",
      "number : 15 )) <tf.Variable 'model/block1_residual_unit_2_BN1/beta:0' shape=(16,) dtype=float32_ref>\n",
      "number : 16 )) <tf.Variable 'model/block1_residual_unit_2_conv1/kernel:0' shape=(3, 3, 16, 16) dtype=float32_ref>\n",
      "number : 17 )) <tf.Variable 'model/block1_residual_unit_2_conv1/bias:0' shape=(16,) dtype=float32_ref>\n",
      "number : 18 )) <tf.Variable 'model/block1_residual_unit_2_BN2/gamma:0' shape=(16,) dtype=float32_ref>\n",
      "number : 19 )) <tf.Variable 'model/block1_residual_unit_2_BN2/beta:0' shape=(16,) dtype=float32_ref>\n",
      "number : 20 )) <tf.Variable 'model/block1_residual_unit_2_conv2/kernel:0' shape=(3, 3, 16, 16) dtype=float32_ref>\n",
      "number : 21 )) <tf.Variable 'model/block1_residual_unit_2_conv2/bias:0' shape=(16,) dtype=float32_ref>\n",
      "number : 22 )) <tf.Variable 'model/block2_residual_unit_1_shortcut/kernel:0' shape=(1, 1, 16, 32) dtype=float32_ref>\n",
      "number : 23 )) <tf.Variable 'model/block2_residual_unit_1_shortcut/bias:0' shape=(32,) dtype=float32_ref>\n",
      "number : 24 )) <tf.Variable 'model/block2_residual_unit_1_BN1/gamma:0' shape=(16,) dtype=float32_ref>\n",
      "number : 25 )) <tf.Variable 'model/block2_residual_unit_1_BN1/beta:0' shape=(16,) dtype=float32_ref>\n",
      "number : 26 )) <tf.Variable 'model/block2_residual_unit_1_conv1/kernel:0' shape=(3, 3, 16, 32) dtype=float32_ref>\n",
      "number : 27 )) <tf.Variable 'model/block2_residual_unit_1_conv1/bias:0' shape=(32,) dtype=float32_ref>\n",
      "number : 28 )) <tf.Variable 'model/block2_residual_unit_1_BN2/gamma:0' shape=(32,) dtype=float32_ref>\n",
      "number : 29 )) <tf.Variable 'model/block2_residual_unit_1_BN2/beta:0' shape=(32,) dtype=float32_ref>\n",
      "number : 30 )) <tf.Variable 'model/block2_residual_unit_1_conv2/kernel:0' shape=(3, 3, 32, 32) dtype=float32_ref>\n",
      "number : 31 )) <tf.Variable 'model/block2_residual_unit_1_conv2/bias:0' shape=(32,) dtype=float32_ref>\n",
      "number : 32 )) <tf.Variable 'model/block2_residual_unit_2_shortcut/kernel:0' shape=(1, 1, 16, 32) dtype=float32_ref>\n",
      "number : 33 )) <tf.Variable 'model/block2_residual_unit_2_shortcut/bias:0' shape=(32,) dtype=float32_ref>\n",
      "number : 34 )) <tf.Variable 'model/block2_residual_unit_2_BN1/gamma:0' shape=(16,) dtype=float32_ref>\n",
      "number : 35 )) <tf.Variable 'model/block2_residual_unit_2_BN1/beta:0' shape=(16,) dtype=float32_ref>\n",
      "number : 36 )) <tf.Variable 'model/block2_residual_unit_2_conv1/kernel:0' shape=(3, 3, 16, 32) dtype=float32_ref>\n",
      "number : 37 )) <tf.Variable 'model/block2_residual_unit_2_conv1/bias:0' shape=(32,) dtype=float32_ref>\n",
      "number : 38 )) <tf.Variable 'model/block2_residual_unit_2_BN2/gamma:0' shape=(32,) dtype=float32_ref>\n",
      "number : 39 )) <tf.Variable 'model/block2_residual_unit_2_BN2/beta:0' shape=(32,) dtype=float32_ref>\n",
      "number : 40 )) <tf.Variable 'model/block2_residual_unit_2_conv2/kernel:0' shape=(3, 3, 32, 32) dtype=float32_ref>\n",
      "number : 41 )) <tf.Variable 'model/block2_residual_unit_2_conv2/bias:0' shape=(32,) dtype=float32_ref>\n",
      "number : 42 )) <tf.Variable 'model/block3_residual_unit_1_shortcut/kernel:0' shape=(1, 1, 32, 64) dtype=float32_ref>\n",
      "number : 43 )) <tf.Variable 'model/block3_residual_unit_1_shortcut/bias:0' shape=(64,) dtype=float32_ref>\n",
      "number : 44 )) <tf.Variable 'model/block3_residual_unit_1_BN1/gamma:0' shape=(32,) dtype=float32_ref>\n",
      "number : 45 )) <tf.Variable 'model/block3_residual_unit_1_BN1/beta:0' shape=(32,) dtype=float32_ref>\n",
      "number : 46 )) <tf.Variable 'model/block3_residual_unit_1_conv1/kernel:0' shape=(3, 3, 32, 64) dtype=float32_ref>\n",
      "number : 47 )) <tf.Variable 'model/block3_residual_unit_1_conv1/bias:0' shape=(64,) dtype=float32_ref>\n",
      "number : 48 )) <tf.Variable 'model/block3_residual_unit_1_BN2/gamma:0' shape=(64,) dtype=float32_ref>\n",
      "number : 49 )) <tf.Variable 'model/block3_residual_unit_1_BN2/beta:0' shape=(64,) dtype=float32_ref>\n",
      "number : 50 )) <tf.Variable 'model/block3_residual_unit_1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
      "number : 51 )) <tf.Variable 'model/block3_residual_unit_1_conv2/bias:0' shape=(64,) dtype=float32_ref>\n",
      "number : 52 )) <tf.Variable 'model/block3_residual_unit_2_shortcut/kernel:0' shape=(1, 1, 32, 64) dtype=float32_ref>\n",
      "number : 53 )) <tf.Variable 'model/block3_residual_unit_2_shortcut/bias:0' shape=(64,) dtype=float32_ref>\n",
      "number : 54 )) <tf.Variable 'model/block3_residual_unit_2_BN1/gamma:0' shape=(32,) dtype=float32_ref>\n",
      "number : 55 )) <tf.Variable 'model/block3_residual_unit_2_BN1/beta:0' shape=(32,) dtype=float32_ref>\n",
      "number : 56 )) <tf.Variable 'model/block3_residual_unit_2_conv1/kernel:0' shape=(3, 3, 32, 64) dtype=float32_ref>\n",
      "number : 57 )) <tf.Variable 'model/block3_residual_unit_2_conv1/bias:0' shape=(64,) dtype=float32_ref>\n",
      "number : 58 )) <tf.Variable 'model/block3_residual_unit_2_BN2/gamma:0' shape=(64,) dtype=float32_ref>\n",
      "number : 59 )) <tf.Variable 'model/block3_residual_unit_2_BN2/beta:0' shape=(64,) dtype=float32_ref>\n",
      "number : 60 )) <tf.Variable 'model/block3_residual_unit_2_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
      "number : 61 )) <tf.Variable 'model/block3_residual_unit_2_conv2/bias:0' shape=(64,) dtype=float32_ref>\n",
      "number : 62 )) <tf.Variable 'model/final_BN/gamma:0' shape=(64,) dtype=float32_ref>\n",
      "number : 63 )) <tf.Variable 'model/final_BN/beta:0' shape=(64,) dtype=float32_ref>\n",
      "number : 64 )) <tf.Variable 'model/final_dense/kernel:0' shape=(64, 10) dtype=float32_ref>\n",
      "number : 65 )) <tf.Variable 'model/final_dense/bias:0' shape=(10,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "with tf.variable_scope('model'):\n",
    "    logits_train = get_logits(X, resnet_params)                              \n",
    "    loss = tf.losses.softmax_cross_entropy(Y, logits_train)   \n",
    "\n",
    "    logits_eval = get_logits(X,resnet_params, is_training = False, reuse = True)\n",
    "    predict_proba_ = tf.nn.softmax(logits_eval)\n",
    "    prediction = tf.argmax(predict_proba_, 1)\n",
    "    global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "    \n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope='model')            \n",
    "with tf.control_dependencies(update_ops):    \n",
    "    optimizer = tf.train.AdamOptimizer(0.03).minimize(loss, global_step=global_step)\n",
    "\n",
    "\n",
    "#accuracy = tf.metrics.accuracy(tf.argmax(Y, 1), prediction)\n",
    "# 변수들 프린트/ 텐서보드 summary 생성\n",
    "for i, v in enumerate(tf.trainable_variables()):\n",
    "    print('number : {} )) {}'.format(i, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_params = {\n",
    "    'start_n_filters': 16, # 첫 시작 convolution layer의 n_filter\n",
    "    'start_strides': 1,  # 첫 시작 convolution layer의 strides\n",
    "    'n_filters': [16, 32, 64], # 각 레이어에 할당된 filter의 수\n",
    "    'layers_strides': [1, 2, 2],\n",
    "    'n_blocks': [2, 2, 2], # 각 레이어에 할당된블럭의 수 \n",
    "    'is_bottlenecks': [False, False, False], # bottle_neck을 사용하면 True, 일반 residual_net사용한다면 False\n",
    "    \n",
    "    'learning_rate': 0.01,\n",
    "    'batch_size': 50,\n",
    "    'epochs': 10,\n",
    "    'height': 28,\n",
    "    'width': 28,\n",
    "    'model_path': './model/tegksjgk/'        \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-2b6b8347eb12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch : {}, cost : {}, acc: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    total_batch = int(mnist.train.num_examples/ batch_size)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    for epoch in range(10):\n",
    "        total_cost = 0    \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, c, = sess.run([optimizer, loss], feed_dict = {X:batch_xs.reshape(-1, 28, 28, 1), Y: batch_ys})\n",
    "        acc = sess.run(accuracy, feed_dict = {X: mnist.test.images.reshape(-1, 28, 28, 1), Y: mnist.test.labels})\n",
    "        \n",
    "        print('epoch : {}, cost : {}, acc: {}'.format(epoch, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.082891062)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_params = {\n",
    "    'num_classes': 10,\n",
    "    'start_n_filters': 16, # 첫 시작 convolution layer의 n_filter\n",
    "    'start_strides': 1,  # 첫 시작 convolution layer의 strides\n",
    "    'n_filters': [16, 32, 64], # 각 레이어에 할당된 filter의 수\n",
    "    'layers_strides': [1, 2, 2],\n",
    "    'n_blocks': [2, 2, 2], # 각 레이어에 할당된블럭의 수 \n",
    "    'is_bottlenecks': [False, False, False], # bottle_neck을 사용하면 True, 일반 residual_net사용한다면 False\n",
    "    \n",
    "    'learning_rate': 0.01,\n",
    "    'batch_size': 50,\n",
    "    'epochs': 10,\n",
    "    'height': 28,\n",
    "    'width': 28,\n",
    "    'model_path': './model/tegksjgk/'        \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resnet:\n",
    "    def __init__(self, resnet_params, sess, name):\n",
    "        self.num_classes = resnet_params['num_classes']\n",
    "        self.start_n_filters = resnet_params['start_n_filters']\n",
    "        self.start_strides = resnet_params['start_strides']\n",
    "        self.n_filters = resnet_params['n_filters']\n",
    "        self.n_blocks = resnet_params['n_blocks']\n",
    "        self.is_bottlenecks = resnet_params['is_bottlenecks']\n",
    "        self.layers_strides = resnet_params['layers_strides']\n",
    "        self.layer_number = range(1, len(self.n_blocks) + 1)\n",
    "        \n",
    "        self.height = resnet_params['height']\n",
    "        self.width = resnet_params['width']\n",
    "        \n",
    "        self.learning_rate = resnet_params['learning_rate']\n",
    "        self.batch_size = resnet_params['batch_size']   \n",
    "        self.name = name\n",
    "        self.sess = sess\n",
    "        \n",
    "        self.X = tf.placeholder(tf.float32, [None, self.height, self.width, 1], name=\"input_x\")\n",
    "        self.Y = tf.placeholder(tf.float32, [None, self.num_classes], name=\"input_y\")\n",
    "           \n",
    "\n",
    "        self._build_net()\n",
    "        \n",
    "    #residual learning\n",
    "    # f(x) + x\n",
    "    # original resnet : 본래 분기되기전에 활성화 함수 적용 \n",
    "    # this resnet : 분기된 이후 shortcut은 그냥 냅두고 weight path의 weight layer 앞에 활성화함수를 두는 pre_activation 설정\n",
    "    # regularization 효과\n",
    "\n",
    "    def residual_unit(self, inputs, n_filter,  strides, name, short_cut = True, is_training = True, reuse = False):\n",
    "        # 쇼트컷 (residual) 설정\n",
    "        shortcut = inputs\n",
    "        if short_cut:\n",
    "            shortcut = tf.layers.conv2d(inputs = shortcut,\n",
    "                                        filters = n_filter,\n",
    "                                        kernel_size= 1,\n",
    "                                        strides = strides,\n",
    "                                        padding = 'SAME',\n",
    "                                        name = name + 'shortcut',\n",
    "                                        reuse =reuse)\n",
    "\n",
    "        #pre_activation\n",
    "        L = tf.layers.batch_normalization(inputs, training = is_training, name = name + 'BN1', reuse = reuse)\n",
    "        L = tf.nn.relu(L)\n",
    "        # convolution (weight layer)\n",
    "        L = tf.layers.conv2d(inputs = L,\n",
    "                             filters = n_filter,\n",
    "                             kernel_size = 3,\n",
    "                             strides = strides,\n",
    "                             padding = 'SAME',\n",
    "                             name = name + 'conv1',\n",
    "                             reuse = reuse)\n",
    "        L = tf.layers.batch_normalization(L, training = is_training, name = name + 'BN2', reuse = reuse)\n",
    "        L = tf.nn.relu(L)\n",
    "        # 블럭의 마지막 layer는 언제나 strides = 1로 하여야한다.\n",
    "        L = tf.layers.conv2d(inputs = L,\n",
    "                             filters = n_filter,\n",
    "                             kernel_size = 3,\n",
    "                             strides = 1,\n",
    "                             padding = 'SAME',\n",
    "                             name = name + 'conv2',\n",
    "                             reuse = reuse)\n",
    "\n",
    "        return L + shortcut\n",
    "\n",
    "     # 학습에 걸리는 시간을 고려해서 50 layer 이상에서는 bottle_neck 구조를 사용한다.\n",
    "    # bottle_neck구조는 output filter의 갯수가 4배로 증가되어 병부리처럼 보여서 bottle_neck이라고 한다.\n",
    "    def bottle_neck_unit(self, inputs, n_filter, strides, name, short_cut = True, is_training = True, reuse = False):\n",
    "        shortcut = inputs\n",
    "        # bottle_neck 레이어에서는 output filter의 갯수가 input filter 갯수의 4배\n",
    "        n_filter_out = n_filter\n",
    "        if short_cut:\n",
    "            shortcut = tf.layers.conv2d(inputs = shortcut,\n",
    "                                        filters = n_filter_out,\n",
    "                                        kernel_size= 1,\n",
    "                                        strides = strides,\n",
    "                                        padding = 'SAME',\n",
    "                                        name = name + 'shortcut',\n",
    "                                        reuse =reuse)\n",
    "\n",
    "        # pre_activation\n",
    "        L =  tf.layers.batch_normalization(inputs, training = is_training, name = name + 'BN1', reuse = reuse)\n",
    "        L = tf.nn.relu(L)\n",
    "        # 첫번째 레이어 conv 1x1\n",
    "        L = tf.layers.conv2d(inputs = L,\n",
    "                             filters = n_filter,\n",
    "                             kernel_size = 1,\n",
    "                             strides = 1,\n",
    "                             padding = 'SAME',\n",
    "                             name = name + 'conv1',\n",
    "                             reuse=reuse)\n",
    "\n",
    "        L =  tf.layers.batch_normalization(inputs, training = is_training, name = name + 'BN2', reuse = reuse)\n",
    "        L = tf.nn.relu(L)\n",
    "        # 두번쨰 레이어 conv 3x3, strides = strides\n",
    "        L = tf.layers.conv2d(inputs = L,\n",
    "                             filters = n_filter,\n",
    "                             kernel_size = 3,\n",
    "                             strides = strides,\n",
    "                             padding = 'SAME',\n",
    "                             name = name + 'conv2',\n",
    "                             reuse=reuse)\n",
    "        L =  tf.layers.batch_normalization(inputs, training = is_training, name = name + 'BN3', reuse = reuse)\n",
    "        L = tf.nn.relu(L)\n",
    "        # 세번째 레이어 conv 1x1, n_filter x 4\n",
    "        L = tf.layers.conv2d(inputs = L,\n",
    "                             filters = n_filter_out,\n",
    "                             kernel_size = 1,\n",
    "                             strides = 1,\n",
    "                             padding = 'SAME',\n",
    "                             name = name + 'conv3',\n",
    "                             reuse=reuse)\n",
    "\n",
    "        return L + shortcut\n",
    "    \n",
    "\n",
    "    # 1. params 에서 각 블럭레이어에서 어떤 블럭을 몇개 쌓을 것인지 결정한다.( 34 layer기준 3, 4, 6, 3 residual_net)\n",
    "    # 2. 첫번째 블럭은 strides를 2로 설정하여 이미지 크기를 줄인다.\n",
    "    # 3. 나머지 블럭은 strides를 1로 설정.\n",
    "    def block_layer(self, inputs, n_filter, strides, name, n_block, is_bottleneck = False, is_training = True, reuse = False):\n",
    "        # bottleneck_layer를 사용한다면\n",
    "        if is_bottleneck:\n",
    "            # 첫번째 블럭은 strides 파라미터 받은데로 설정(이미지 크기 1/2)\n",
    "            L = self.bottle_neck_unit(inputs, n_filter, strides, name+'_bottle_neck_1_', is_training = is_training, reuse = reuse)\n",
    "            # 나머지 블럭은 strides를 1로 설정(이미지 크기 보존)\n",
    "            for i in range(2, n_block + 1):\n",
    "                L = self.bottle_neck_unit(inputs, n_filter, 1, name+'_bottle_neck_'+ str(i) + '_', is_training = is_training, reuse = reuse)\n",
    "        else:\n",
    "            # 첫번째 블럭은 strides 파라미터 받은데로 설정(이미지 크기 1/2)\n",
    "            L = self.residual_unit(inputs, n_filter, strides, name+'_residual_unit_1_', is_training = is_training, reuse = reuse)\n",
    "            # 나머지 블럭은 strides를 1로 설정(이미지 크기 보존)\n",
    "            for i in range(2, n_block + 1):\n",
    "                L = self.residual_unit(inputs, n_filter, 1, name+'_residual_unit_'+ str(i) + '_', is_training = is_training, reuse = reuse)\n",
    "        return L\n",
    "    \n",
    "    \n",
    "    def get_logits(self, inputs, is_training = True, reuse = False):\n",
    "\n",
    "        layer_number = range(1, len(self.n_blocks) + 1)\n",
    "\n",
    "\n",
    "        # 첫번째는 먼저 conv 3x3 시행 128x32 -> 64 x 16 \n",
    "        conv = tf.layers.conv2d(inputs = inputs,\n",
    "                             filters = self.start_n_filters,\n",
    "                             kernel_size = 3,\n",
    "                             strides = self.start_strides,\n",
    "                             padding = 'SAME',\n",
    "                             name = 'begin_conv',\n",
    "                             reuse = reuse)\n",
    "        # 크기가 큰경우는 max_pooling을 거치나 여기는 그렇게 크지않으므로 제외\n",
    "        # strides = [1, 2, 2] 기준\n",
    "        # 첫번째 layer image size : 64 x16 -> 64 x 16\n",
    "        # 두번째 layer image size : 64 x 16 -> 32 x 8\n",
    "        # 세번째 layer image size : 32 x 8 -> 16 x 4\n",
    "        block = conv\n",
    "        for i, n_filter, strides, n_block, is_bottleneck in zip(layer_number,\n",
    "                                                                self.n_filters,\n",
    "                                                                self.layers_strides,\n",
    "                                                                self.n_blocks,\n",
    "                                                                self.is_bottlenecks):\n",
    "            L = self.block_layer(inputs = block,\n",
    "                                n_filter = n_filter,\n",
    "                                strides = strides,\n",
    "                                name = 'block'+str(i),\n",
    "                                n_block = n_block,\n",
    "                                is_bottleneck = is_bottleneck,\n",
    "                                is_training = is_training,\n",
    "                                reuse = reuse)\n",
    "            block = L\n",
    "     \n",
    "        #마지막 batch_norm and activation function\n",
    "        outputs =  tf.layers.batch_normalization(block, training = is_training, name='final_BN', reuse = reuse)\n",
    "        outputs = tf.nn.relu(L)\n",
    "        # global average_pooling\n",
    "        # shape : (batch_size, height, width, n_feature_map)\n",
    "        shape = outputs.get_shape().as_list()\n",
    "        # 글로벌 풀링 사이즈 (height, width)\n",
    "        pool_size = (shape[1], shape[2])\n",
    "        outputs= tf.layers.average_pooling2d(outputs, pool_size = pool_size, strides = 1, padding = 'VALID')\n",
    "        # 마지막 dense layer\n",
    "        outputs = tf.layers.flatten(outputs)\n",
    "        outputs = tf.layers.dense(outputs, self.num_classes, name = 'final_dense', reuse=reuse)\n",
    "        return outputs\n",
    "    \n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            self.logits_train = self.get_logits(self.X, resnet_params)                              \n",
    "            self.loss = tf.losses.softmax_cross_entropy(self.Y, self.logits_train)   \n",
    "\n",
    "            self.logits_eval = self.get_logits(self.X, is_training = False, reuse = True)\n",
    "            self.predict_proba_ = tf.nn.softmax(self.logits_eval)\n",
    "            self.prediction = tf.argmax(self.predict_proba_, 1)\n",
    "            self.accuracy = tf.metrics.accuracy(tf.argmax(self.Y, 1), self.prediction)\n",
    "            \n",
    "            self.global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope=self.name)            \n",
    "        with tf.control_dependencies(update_ops):    \n",
    "            self.optimizer = tf.train.AdamOptimizer(0.03).minimize(loss, global_step=global_step)\n",
    "        \n",
    "        for i, v in enumerate(tf.trainable_variables()):\n",
    "            print('number : {} )) {}'.format(i, v))\n",
    "    \n",
    "    def fit(self):\n",
    "        total_batch = int(mnist.train.num_examples/ self.batch_size)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.sess.run(tf.local_variables_initializer())\n",
    "        for epoch in range(10):\n",
    "            total_cost = 0\n",
    "        \n",
    "            for i in range(total_batch):\n",
    "                batch_xs, batch_ys = mnist.train.next_batch(self.batch_size)\n",
    "                _, c = sess.run([self.optimizer, self.loss], feed_dict = {self.X:batch_xs.reshape(-1, 28, 28, 1), self.Y: batch_ys})\n",
    "            acc = sess.run(self.accuracy, feed_dict = {self.X: mnist.test.images.reshape(-1, 28, 28, 1), self.Y: mnist.test.labels})\n",
    "            \n",
    "            print('epoch : {}, cost : {}, acc: {}'.format(epoch, c, acc))\n",
    "        return self\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "`pred` must be a Tensor, a Variable, or a Python bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b7d13a5b910f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresnet_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-61b4d35f49e4>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, resnet_params, sess, name)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[1;31m#residual learning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-61b4d35f49e4>\u001b[0m in \u001b[0;36m_build_net\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_build_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresnet_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-61b4d35f49e4>\u001b[0m in \u001b[0;36mget_logits\u001b[0;34m(self, inputs, is_training, reuse)\u001b[0m\n\u001b[1;32m    168\u001b[0m                                 \u001b[0mis_bottleneck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_bottleneck\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                                 \u001b[0mis_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                                 reuse = reuse)\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-61b4d35f49e4>\u001b[0m in \u001b[0;36mblock_layer\u001b[0;34m(self, inputs, n_filter, strides, name, n_block, is_bottleneck, is_training, reuse)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[1;31m# 첫번째 블럭은 strides 파라미터 받은데로 설정(이미지 크기 1/2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresidual_unit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_filter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_residual_unit_1_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreuse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[1;31m# 나머지 블럭은 strides를 1로 설정(이미지 크기 보존)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_block\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-61b4d35f49e4>\u001b[0m in \u001b[0;36mresidual_unit\u001b[0;34m(self, inputs, n_filter, strides, name, short_cut, is_training, reuse)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[1;31m#pre_activation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_normalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'BN1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreuse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[1;31m# convolution (weight layer)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\normalization.py\u001b[0m in \u001b[0;36mbatch_normalization\u001b[0;34m(inputs, axis, momentum, epsilon, center, scale, beta_initializer, gamma_initializer, moving_mean_initializer, moving_variance_initializer, beta_regularizer, gamma_regularizer, beta_constraint, gamma_constraint, training, trainable, name, reuse, renorm, renorm_clipping, renorm_momentum, fused)\u001b[0m\n\u001b[1;32m    584\u001b[0m       \u001b[0m_reuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m       _scope=name)\n\u001b[0;32m--> 586\u001b[0;31m   \u001b[1;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    669\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \"\"\"\n\u001b[0;32m--> 671\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m   def _add_inbound_node(self,\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0min_graph_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    393\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfused\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fused_batch_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[1;31m# First, compute the axes along which to reduce the mean / variance,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     output, mean, variance = utils.smart_cond(\n\u001b[0;32m--> 302\u001b[0;31m         training, _fused_batch_norm_training, _fused_batch_norm_inference)\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bessels_correction_test_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m       \u001b[1;31m# Remove Bessel's correction to be consistent with non-fused batch norm.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\utils.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, fn1, fn2, name)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`fn2` must be callable.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m   \u001b[0mpred_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\utils.py\u001b[0m in \u001b[0;36mconstant_value\u001b[0;34m(pred)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0mpred_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`pred` must be a Tensor, a Variable, or a Python bool.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: `pred` must be a Tensor, a Variable, or a Python bool."
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "model = resnet(resnet_params, sess, name = 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [3, 4, 5]\n",
    "b = [7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 7\n",
      "2 4 8\n",
      "3 5 9\n"
     ]
    }
   ],
   "source": [
    "for i, j, k in zip(range(1, len(a) +1 ),a, b):\n",
    "    print(i, j, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "128,32\n",
    "64, 16\n",
    "32, 8\n",
    "16, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hyperparameter\n",
    "params = {\n",
    "    'num_classes': 10,\n",
    "    \n",
    "    'num_filters': [8, 16, 32],\n",
    "    'filter_size': [2, 2, 2],\n",
    "    'cnn_batch_norm' : [False, False, False],\n",
    "    \n",
    "    'fc_hidden_units': [256, 128],\n",
    "    'fc_batch_norm': [False, False],\n",
    "    'fc_dropout_keep_prob': [0.2, 0.3],\n",
    "    \n",
    "    'rnn_n_step': 28, #width, time\n",
    "    'rnn_n_hiddens': [128, 128],\n",
    "    'rnn_dropout_keep_prob': [0.5, 0.6],\n",
    "    \n",
    "    'learning_rate': 0.01,\n",
    "    'activation' : tf.nn.relu,\n",
    "    'batch_size': 100\n",
    "}\n",
    "tf.reset_default_graph()\n",
    "\n",
    "class Model(object):\n",
    "\n",
    "    def __init__(self, params, sess, name):\n",
    "        # 하이퍼파라미터\n",
    "        self.num_classes = params['num_classes']\n",
    "        self.num_filters = params['num_filters']\n",
    "        self.filter_sizes = params['filter_size']\n",
    "        self.cnn_batch_norm  = params['cnn_batch_norm']\n",
    "        \n",
    "        self.fc_hidden_units = params['fc_hidden_units']\n",
    "        self.fc_batch_norm = params['fc_batch_norm']\n",
    "        self.fc_dropout_keep_prob = params['fc_dropout_keep_prob']\n",
    "        \n",
    "        self.rnn_n_hiddens = params['rnn_n_hiddens']\n",
    "        self.rnn_dropout_keep_prob = params['rnn_dropout_keep_prob']\n",
    "        \n",
    "        self.learning_rate = params['learning_rate']\n",
    "        self.activation = params['activation']\n",
    "        self.batch_size = params['batch_size']        \n",
    "        \n",
    "        self.idx_convolutional_layers = range(1, len(self.filter_sizes) + 1)\n",
    "        self.idx_fc_layers = range(1, len(self.fc_hidden_units) + 1)\n",
    "        self.idx_rnn_layers = range(1, len(self.rnn_n_hiddens) + 1)\n",
    "\n",
    "        self.name = name\n",
    "        self.sess = sess\n",
    "        # 플레이스홀더\n",
    "        with tf.device('/gpu:0'):\n",
    "            self.X = tf.placeholder(tf.float32, [None, 28, 28, 1], name=\"input_x\")\n",
    "            self.Y = tf.placeholder(tf.float32, [None, self.num_classes], name=\"input_y\")\n",
    "            \n",
    "\n",
    "            self._build_net()\n",
    "\n",
    "        \n",
    "        \n",
    "    #  컨볼루션 레이어를 params에서 받은 파라미터를 따라 구축\n",
    "    def convolutional_layers(self, X, is_training = True, reuse = False):\n",
    "        inputs = X\n",
    "        for i, num_filter, filter_size, use_bn in zip(self.idx_convolutional_layers, self.num_filters, self.filter_sizes, self.cnn_batch_norm):            \n",
    "            L = tf.layers.conv2d(inputs,\n",
    "                                 filters=num_filter,\n",
    "                                 kernel_size=filter_size,\n",
    "                                 strides=1,\n",
    "                                 padding='SAME',\n",
    "                                 name = 'CONV'+str(i),\n",
    "                                 reuse= reuse)\n",
    "            if use_bn:\n",
    "                L= tf.layers.batch_normalization(L, training= is_training, name='BN' + str(i), reuse= reuse)\n",
    "            L = self.activation(L)\n",
    "            L = tf.layers.max_pooling2d(L, pool_size = 2, strides = 2, padding = 'SAME')\n",
    "            inputs = L\n",
    "        return inputs\n",
    "    \n",
    "    \n",
    "    #  dense 레이어를 params에서 받은 파라미터를 따라 구축\n",
    "    def fc_layers(self, X, is_training = True, reuse = False):\n",
    "        inputs = X\n",
    "        for i, units, use_bn, keep_prob in zip(self.idx_fc_layers, self.fc_hidden_units, self.fc_batch_norm, self.fc_dropout_keep_prob):\n",
    "            fc = tf.layers.dense(inputs,\n",
    "                                 units=units,\n",
    "                                 reuse=reuse,\n",
    "                                 name = 'FC' + str(i))\n",
    "            if use_bn:\n",
    "                fc = tf.layers.batch_normalization(fc, training= is_training, name='fc_BN' + str(i), reuse= reuse)\n",
    "            fc = self.activation(fc)\n",
    "            if keep_prob:\n",
    "                fc = tf.layers.dropout(fc, rate = keep_prob, training= is_training, name = 'fc_dropout' + str(i))\n",
    "            inputs = fc \n",
    "        return inputs\n",
    "  \n",
    "\n",
    "     # LSTM 레이어 \n",
    "    def rnn_layers(self, inputs, is_training = True, reuse = False):\n",
    "        if is_training:\n",
    "            keep_probs = self.rnn_dropout_keep_prob\n",
    "            \n",
    "        else:\n",
    "            keep_probs = np.ones_like(self.rnn_dropout_keep_prob)\n",
    "        # single layer\n",
    "        if len(self.idx_rnn_layers) == 1:\n",
    "            cell = tf.nn.rnn_cell.BasicLSTMCell(self.rnn_n_hiddens[0], reuse = reuse)\n",
    "            cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=keep_probs[0])\n",
    "        # multi layer \n",
    "        else:\n",
    "            cell_list = []\n",
    "            for i, n_hidden, keep_prob in zip(self.idx_rnn_layers, self.rnn_n_hiddens, keep_probs):\n",
    "                cell_ = tf.nn.rnn_cell.BasicLSTMCell(n_hidden, reuse = reuse)\n",
    "                cell_ = tf.nn.rnn_cell.DropoutWrapper(cell_, output_keep_prob=keep_prob)\n",
    "                cell_list.append(cell_)\n",
    "            cell = tf.nn.rnn_cell.MultiRNNCell(cell_list)\n",
    "        # output_shape [batch_size, width(n_step), n_classes]\n",
    "        outputs, states = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32)\n",
    "        print(outputs.get_shape().as_list())\n",
    "        outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "        outputs = outputs[-1]\n",
    "        return outputs\n",
    " \n",
    "\n",
    "    def get_reshaped_cnn_to_rnn(self, inputs):\n",
    "        # [batch, height, width, n_feature map]\n",
    "        shape = inputs.get_shape().as_list() \n",
    "        # 우리가 얻어야하는 사이즈 [batch, height, width x n_feature map]\n",
    "        reshaped_inputs = tf.reshape(inputs, [-1, shape[1], shape[2] * shape[3]])\n",
    "        return reshaped_inputs\n",
    "  \n",
    "\n",
    "\n",
    "    # 모델 구축/ logit \n",
    "    def get_logits(self, X, is_training = True, reuse = False):        \n",
    "        conv = self.convolutional_layers(self.X, is_training, reuse)                           \n",
    "        #flat = tf.layers.flatten(conv)\n",
    "        reshaped_fp = self.get_reshaped_cnn_to_rnn(conv)\n",
    "        rnn = self.rnn_layers(reshaped_fp, is_training, reuse)\n",
    "        #fc = self.fc_layers(flat, is_training, reuse)\n",
    "        output = tf.layers.dense(rnn, units= self.num_classes, reuse=reuse, name = 'out')\n",
    "        \n",
    "        return output\n",
    " \n",
    "\n",
    "\n",
    "    # 모델 구축\n",
    "    def _build_net(self):\n",
    "        \n",
    "        with tf.variable_scope(self.name):\n",
    "            self.logits_train = self.get_logits(self.X)                              \n",
    "            self.loss = tf.losses.softmax_cross_entropy(self.Y, self.logits_train)   \n",
    "                # batch_normalization 적용을 위해 모든 변수들을 불러와서 moving\n",
    "                #학습 단계에서는 데이터가 배치 단위로 들어오기 때문에 배치의 평균, 분산을 구하는 것이 가능하지만,\n",
    "                # 테스트 단계에서는 배치 단위로 평균/분산을 구하기가 어렵기때문에\n",
    "                # 학습 단계에서 배치 단위의 평균/분산을 저장해 놓고 테스트 시에는 평균/분산을 사용합니다.\n",
    "                # 저장한 값을 get_collection을 통해서 불러온다.\n",
    "            self.global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope=self.name)            \n",
    "            with tf.control_dependencies(update_ops):    \n",
    "                self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss, global_step=self.global_step)\n",
    "\n",
    "            self.logits_eval = self.get_logits(self.X, is_training = False, reuse = True)\n",
    "            self.predict_proba_ = tf.nn.softmax(self.logits_eval)\n",
    "            self.prediction = tf.argmax(self.predict_proba_, 1)\n",
    "            self.accuracy = tf.metrics.accuracy(tf.argmax(self.Y, 1), self.prediction)\n",
    "            # 변수들 프린트/ 텐서보드 summary 생성\n",
    "        tf.summary.scalar('loss', self.loss)\n",
    "        # tf.summary.scalar('accuracy', self.accuracy[1])\n",
    "        for v in tf.trainable_variables():\n",
    "            tf.summary.histogram('Var_{}'.format(v.name), v)\n",
    "            print(v)            \n",
    "        self.merged = tf.summary.merge_all()\n",
    "        # 모델저장\n",
    "        saver = tf.train.Saver()\n",
    "            \n",
    "        \n",
    "    def fit(self):\n",
    "        total_batch = int(mnist.train.num_examples/ self.batch_size)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.sess.run(tf.local_variables_initializer())\n",
    "        writer = tf.summary.FileWriter('./logs/', sess.graph)\n",
    "        for epoch in range(10):\n",
    "            total_cost = 0\n",
    "        \n",
    "            for i in range(total_batch):\n",
    "                batch_xs, batch_ys = mnist.train.next_batch(self.batch_size)\n",
    "                _, c, _summ = sess.run([self.optimizer, self.loss, self.merged], feed_dict = {self.X:batch_xs.reshape(-1, 28, 28, 1), self.Y: batch_ys})\n",
    "                writer.add_summary(_summ, i)\n",
    "            #acc = sess.run(self.accuracy, feed_dict = {self.X: mnist.test.images.reshape(-1, 28, 28, 1), self.Y: mnist.test.labels})\n",
    "            \n",
    "            print('epoch : {}, cost : {}, acc: {}'.format(epoch, c))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 4, 128]\n",
      "[None, 4, 128]\n",
      "INFO:tensorflow:Summary name Var_model/CONV1/kernel:0 is illegal; using Var_model/CONV1/kernel_0 instead.\n",
      "<tf.Variable 'model/CONV1/kernel:0' shape=(2, 2, 1, 8) dtype=float32_ref>\n",
      "INFO:tensorflow:Summary name Var_model/CONV1/bias:0 is illegal; using Var_model/CONV1/bias_0 instead.\n",
      "<tf.Variable 'model/CONV1/bias:0' shape=(8,) dtype=float32_ref>\n",
      "INFO:tensorflow:Summary name Var_model/CONV2/kernel:0 is illegal; using Var_model/CONV2/kernel_0 instead.\n",
      "<tf.Variable 'model/CONV2/kernel:0' shape=(2, 2, 8, 16) dtype=float32_ref>\n",
      "INFO:tensorflow:Summary name Var_model/CONV2/bias:0 is illegal; using Var_model/CONV2/bias_0 instead.\n",
      "<tf.Variable 'model/CONV2/bias:0' shape=(16,) dtype=float32_ref>\n",
      "INFO:tensorflow:Summary name Var_model/CONV3/kernel:0 is illegal; using Var_model/CONV3/kernel_0 instead.\n",
      "<tf.Variable 'model/CONV3/kernel:0' shape=(2, 2, 16, 32) dtype=float32_ref>\n",
      "INFO:tensorflow:Summary name Var_model/CONV3/bias:0 is illegal; using Var_model/CONV3/bias_0 instead.\n",
      "<tf.Variable 'model/CONV3/bias:0' shape=(32,) dtype=float32_ref>\n",
      "INFO:tensorflow:Summary name Var_model/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0 is illegal; using Var_model/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel_0 instead.\n",
      "<tf.Variable 'model/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(256, 512) dtype=float32_ref>\n",
      "INFO:tensorflow:Summary name Var_model/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0 is illegal; using Var_model/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias_0 instead.\n",
      "<tf.Variable 'model/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(512,) dtype=float32_ref>\n",
      "INFO:tensorflow:Summary name Var_model/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0 is illegal; using Var_model/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel_0 instead.\n",
      "<tf.Variable 'model/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0' shape=(256, 512) dtype=float32_ref>\n",
      "INFO:tensorflow:Summary name Var_model/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0 is illegal; using Var_model/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias_0 instead.\n",
      "<tf.Variable 'model/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0' shape=(512,) dtype=float32_ref>\n",
      "INFO:tensorflow:Summary name Var_model/out/kernel:0 is illegal; using Var_model/out/kernel_0 instead.\n",
      "<tf.Variable 'model/out/kernel:0' shape=(128, 10) dtype=float32_ref>\n",
      "INFO:tensorflow:Summary name Var_model/out/bias:0 is illegal; using Var_model/out/bias_0 instead.\n",
      "<tf.Variable 'model/out/bias:0' shape=(10,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Model(params, sess, name = 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation 'model/rnn_1/range': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: model/rnn_1/range = Range[Tidx=DT_INT32, _device=\"/device:GPU:0\"](model/rnn_1/range/start, model/rnn_1/Rank, model/rnn_1/range/delta)]]\n\nCaused by op 'model/rnn_1/range', defined at:\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-8becbd984eae>\", line 2, in <module>\n    model = Model(params, sess, name = 'model')\n  File \"<ipython-input-11-f9b1783ff22b>\", line 52, in __init__\n    self._build_net()\n  File \"<ipython-input-11-f9b1783ff22b>\", line 157, in _build_net\n    self.logits_eval = self.get_logits(self.X, is_training = False, reuse = True)\n  File \"<ipython-input-11-f9b1783ff22b>\", line 133, in get_logits\n    rnn = self.rnn_layers(reshaped_fp, is_training, reuse)\n  File \"<ipython-input-11-f9b1783ff22b>\", line 112, in rnn_layers\n    outputs, states = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 621, in dynamic_rnn\n    outputs = nest.map_structure(_transpose_batch_time, outputs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\", line 413, in map_structure\n    structure[0], [func(*x) for x in entries])\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\", line 413, in <listcomp>\n    structure[0], [func(*x) for x in entries])\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 71, in _transpose_batch_time\n    ([1, 0], math_ops.range(2, x_rank)), axis=0))\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1234, in range\n    return gen_math_ops._range(start, limit, delta, name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 3258, in _range\n    \"Range\", start=start, limit=limit, delta=delta, name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'model/rnn_1/range': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: model/rnn_1/range = Range[Tidx=DT_INT32, _device=\"/device:GPU:0\"](model/rnn_1/range/start, model/rnn_1/Rank, model/rnn_1/range/delta)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1292\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1353\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m-> 1354\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'model/rnn_1/range': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: model/rnn_1/range = Range[Tidx=DT_INT32, _device=\"/device:GPU:0\"](model/rnn_1/range/start, model/rnn_1/Rank, model/rnn_1/range/delta)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fed1f18ffa7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-f9b1783ff22b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mtotal_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./logs/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'model/rnn_1/range': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: model/rnn_1/range = Range[Tidx=DT_INT32, _device=\"/device:GPU:0\"](model/rnn_1/range/start, model/rnn_1/Rank, model/rnn_1/range/delta)]]\n\nCaused by op 'model/rnn_1/range', defined at:\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-8becbd984eae>\", line 2, in <module>\n    model = Model(params, sess, name = 'model')\n  File \"<ipython-input-11-f9b1783ff22b>\", line 52, in __init__\n    self._build_net()\n  File \"<ipython-input-11-f9b1783ff22b>\", line 157, in _build_net\n    self.logits_eval = self.get_logits(self.X, is_training = False, reuse = True)\n  File \"<ipython-input-11-f9b1783ff22b>\", line 133, in get_logits\n    rnn = self.rnn_layers(reshaped_fp, is_training, reuse)\n  File \"<ipython-input-11-f9b1783ff22b>\", line 112, in rnn_layers\n    outputs, states = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 621, in dynamic_rnn\n    outputs = nest.map_structure(_transpose_batch_time, outputs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\", line 413, in map_structure\n    structure[0], [func(*x) for x in entries])\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\", line 413, in <listcomp>\n    structure[0], [func(*x) for x in entries])\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 71, in _transpose_batch_time\n    ([1, 0], math_ops.range(2, x_rank)), axis=0))\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1234, in range\n    return gen_math_ops._range(start, limit, delta, name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 3258, in _range\n    \"Range\", start=start, limit=limit, delta=delta, name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'model/rnn_1/range': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: model/rnn_1/range = Range[Tidx=DT_INT32, _device=\"/device:GPU:0\"](model/rnn_1/range/start, model/rnn_1/Rank, model/rnn_1/range/delta)]]\n"
     ]
    }
   ],
   "source": [
    "model.fit()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.  28.]\n",
      " [ 49.  64.]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, cost : 0.053370747715234756, acc: [(0.0, 0.96810001)]\n",
      "epoch : 1, cost : 0.06267564743757248, acc: [(0.96810001, 0.97430003)]\n",
      "epoch : 2, cost : 0.0855538621544838, acc: [(0.97430003, 0.97680002)]\n",
      "epoch : 3, cost : 0.19877442717552185, acc: [(0.97680002, 0.97907501)]\n",
      "epoch : 4, cost : 0.05799204856157303, acc: [(0.97907501, 0.98093998)]\n",
      "epoch : 5, cost : 0.11063935607671738, acc: [(0.98093998, 0.98213333)]\n",
      "epoch : 6, cost : 0.03810318559408188, acc: [(0.98213333, 0.98282856)]\n",
      "epoch : 7, cost : 0.0006602299981750548, acc: [(0.98282856, 0.98348749)]\n",
      "epoch : 8, cost : 0.033298783004283905, acc: [(0.98348749, 0.98413336)]\n",
      "epoch : 9, cost : 0.008241044357419014, acc: [(0.98413336, 0.98462999)]\n",
      "epoch : 10, cost : 0.02387131005525589, acc: [(0.98462999, 0.98500907)]\n",
      "epoch : 11, cost : 0.0030551606323570013, acc: [(0.98500907, 0.98540002)]\n",
      "epoch : 12, cost : 0.06204137206077576, acc: [(0.98540002, 0.98581541)]\n",
      "epoch : 13, cost : 0.0004125334962736815, acc: [(0.98581541, 0.98612142)]\n",
      "epoch : 14, cost : 0.023427624255418777, acc: [(0.98612142, 0.98637998)]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev = 0.01))\n",
    "L1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev = 0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "L2_flatten = tf.contrib.layers.flatten(L2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([7 * 7 * 64, 256], stddev = 0.01))\n",
    "b3 = tf.Variable(tf.random_normal([256]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2_flatten, W3) + b3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob)\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([256, 10], stddev =0.01))\n",
    "b4 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L3, W4) + b4\n",
    "\n",
    "cost = tf.losses.softmax_cross_entropy(Y, logits = logits)\n",
    "train = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "\n",
    "predictions = tf.argmax(tf.nn.softmax(logits), 1)\n",
    "accuracy = tf.metrics.accuracy(tf.argmax(Y, 1), predictions)\n",
    "\n",
    "batch_size = 100\n",
    "with tf.Session() as sess:\n",
    "    total_batch = int(mnist.train.num_examples/ batch_size)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    for epoch in range(15):\n",
    "        total_cost = 0\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, c, = sess.run([train, cost], feed_dict = {X:batch_xs.reshape(-1, 28, 28, 1), Y: batch_ys, keep_prob: 0.8})\n",
    "        acc = sess.run([accuracy], feed_dict = {X: mnist.test.images.reshape(-1, 28, 28, 1), Y: mnist.test.labels, keep_prob: 1.0})\n",
    "        print('epoch : {}, cost : {}, acc: {}'.format(epoch, c, acc))\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "def model_net(x, activation, is_training, reuse = False):\n",
    "    L1 = tf.layers.conv2d(x, 32, 3, padding='SAME', activation = activation, reuse= reuse, name = 'L1')\n",
    "    L1 = tf.layers.max_pooling2d(L1, 2, 2)\n",
    "    L2 = tf.layers.conv2d(L1, 64, 3, padding='SAME', activation = activation, reuse=reuse, name = 'L2')\n",
    "    L2 = tf.layers.max_pooling2d(L2, 2, 2)\n",
    "    \n",
    "    L2_flatten = tf.contrib.layers.flatten(L2)\n",
    "    \n",
    "    fc1 = tf.layers.dense(L2_flatten, 256, activation = activation, reuse=reuse, name = 'FC1')\n",
    "    fc1 = tf.layers.dropout(fc1, 0.2, training = is_training)\n",
    "    \n",
    "    fc2 = tf.layers.dense(fc1, 10, reuse=reuse, name = 'output')\n",
    "    return fc2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = model_net(X, tf.nn.relu, True)\n",
    "test_logits = model_net(X, tf.nn.relu, False, True)\n",
    "cost = tf.losses.softmax_cross_entropy(Y, logits = logits)\n",
    "train = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "\n",
    "predictions = tf.argmax(tf.nn.softmax(test_logits), 1)\n",
    "accuracy = tf.metrics.accuracy(tf.argmax(Y, 1), predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, cost : 0.020873257890343666, acc: [(0.0, 0.98430002)]\n",
      "epoch : 1, cost : 0.012488684616982937, acc: [(0.98430002, 0.98689997)]\n",
      "epoch : 2, cost : 0.058932267129421234, acc: [(0.98689997, 0.9878)]\n",
      "epoch : 3, cost : 0.050051361322402954, acc: [(0.9878, 0.98860002)]\n",
      "epoch : 4, cost : 0.047780223190784454, acc: [(0.98860002, 0.98923999)]\n",
      "epoch : 5, cost : 0.03912124037742615, acc: [(0.98923999, 0.98943335)]\n",
      "epoch : 6, cost : 0.02453668788075447, acc: [(0.98943335, 0.98968571)]\n",
      "epoch : 7, cost : 0.0036200848408043385, acc: [(0.98968571, 0.98982501)]\n",
      "epoch : 8, cost : 0.0011123416479676962, acc: [(0.98982501, 0.99014443)]\n",
      "epoch : 9, cost : 0.004260535817593336, acc: [(0.99014443, 0.98979002)]\n",
      "epoch : 10, cost : 0.007146528456360102, acc: [(0.98979002, 0.98985457)]\n",
      "epoch : 11, cost : 0.04281054064631462, acc: [(0.98985457, 0.99010831)]\n",
      "epoch : 12, cost : 0.0008145206375047565, acc: [(0.99010831, 0.99017692)]\n",
      "epoch : 13, cost : 0.02385837584733963, acc: [(0.99017692, 0.99017859)]\n",
      "epoch : 14, cost : 0.00028013234259560704, acc: [(0.99017859, 0.99027997)]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "with tf.Session() as sess:\n",
    "    total_batch = int(mnist.train.num_examples/ batch_size)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    for epoch in range(15):\n",
    "        total_cost = 0\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, c, = sess.run([train, cost], feed_dict = {X:batch_xs.reshape(-1, 28, 28, 1), Y: batch_ys})\n",
    "        acc = sess.run([accuracy], feed_dict = {X: mnist.test.images.reshape(-1, 28, 28, 1), Y: mnist.test.labels})\n",
    "        print('epoch : {}, cost : {}, acc: {}'.format(epoch, c, acc))\n",
    "            \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "def model_net(x, activation, is_training, reuse = False):\n",
    "    L1 = tf.layers.conv2d(x, 32, 3, padding='SAME', reuse= reuse, name = 'L1')\n",
    "    L1 = tf.layers.batch_normalization(L1, training=is_training)\n",
    "    L1 = activation(L1)\n",
    "    L1 = tf.layers.max_pooling2d(L1, 2, 2)\n",
    "    \n",
    "    L2 = tf.layers.conv2d(L1, 64, 3, padding='SAME', activation = activation, reuse=reuse, name = 'L2')\n",
    "    L2 = tf.layers.batch_normalization(L2, training=is_training)\n",
    "    L2 = activation(L2)\n",
    "    L2 = tf.layers.max_pooling2d(L2, 2, 2)\n",
    "    \n",
    "    L2_flatten = tf.contrib.layers.flatten(L2)\n",
    "    \n",
    "    fc1 = tf.layers.dense(L2_flatten, 256, activation = activation, reuse=reuse, name = 'FC1')\n",
    "    fc1 = tf.layers.dropout(fc1, 0.2, training = is_training)\n",
    "    \n",
    "    fc2 = tf.layers.dense(fc1, 10, reuse=reuse, name = 'output')\n",
    "    return fc2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = model_net(X, tf.nn.relu, True)\n",
    "test_logits = model_net(X, tf.nn.relu, False, True)\n",
    "cost = tf.losses.softmax_cross_entropy(Y, logits = logits)\n",
    "train = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "\n",
    "predictions = tf.argmax(tf.nn.softmax(test_logits), 1)\n",
    "accuracy = tf.metrics.accuracy(tf.argmax(Y, 1), predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "with tf.Session() as sess:\n",
    "    total_batch = int(mnist.train.num_examples/ batch_size)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    for epoch in range(15):\n",
    "        total_cost = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, c, = sess.run([train, cost], feed_dict = {X:batch_xs.reshape(-1, 28, 28, 1), Y: batch_ys})\n",
    "        acc = sess.run([accuracy], feed_dict = {X: mnist.test.images.reshape(-1, 28, 28, 1), Y: mnist.test.labels})\n",
    "        print('epoch : {}, cost : {}, acc: {}'.format(epoch, c, acc))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
