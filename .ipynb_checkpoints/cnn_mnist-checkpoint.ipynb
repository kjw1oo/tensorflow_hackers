{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./mnist/data/', one_hot = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, cost : 0.053370747715234756, acc: [(0.0, 0.96810001)]\n",
      "epoch : 1, cost : 0.06267564743757248, acc: [(0.96810001, 0.97430003)]\n",
      "epoch : 2, cost : 0.0855538621544838, acc: [(0.97430003, 0.97680002)]\n",
      "epoch : 3, cost : 0.19877442717552185, acc: [(0.97680002, 0.97907501)]\n",
      "epoch : 4, cost : 0.05799204856157303, acc: [(0.97907501, 0.98093998)]\n",
      "epoch : 5, cost : 0.11063935607671738, acc: [(0.98093998, 0.98213333)]\n",
      "epoch : 6, cost : 0.03810318559408188, acc: [(0.98213333, 0.98282856)]\n",
      "epoch : 7, cost : 0.0006602299981750548, acc: [(0.98282856, 0.98348749)]\n",
      "epoch : 8, cost : 0.033298783004283905, acc: [(0.98348749, 0.98413336)]\n",
      "epoch : 9, cost : 0.008241044357419014, acc: [(0.98413336, 0.98462999)]\n",
      "epoch : 10, cost : 0.02387131005525589, acc: [(0.98462999, 0.98500907)]\n",
      "epoch : 11, cost : 0.0030551606323570013, acc: [(0.98500907, 0.98540002)]\n",
      "epoch : 12, cost : 0.06204137206077576, acc: [(0.98540002, 0.98581541)]\n",
      "epoch : 13, cost : 0.0004125334962736815, acc: [(0.98581541, 0.98612142)]\n",
      "epoch : 14, cost : 0.023427624255418777, acc: [(0.98612142, 0.98637998)]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev = 0.01))\n",
    "L1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev = 0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "L2_flatten = tf.contrib.layers.flatten(L2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([7 * 7 * 64, 256], stddev = 0.01))\n",
    "b3 = tf.Variable(tf.random_normal([256]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2_flatten, W3) + b3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob)\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([256, 10], stddev =0.01))\n",
    "b4 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L3, W4) + b4\n",
    "\n",
    "cost = tf.losses.softmax_cross_entropy(Y, logits = logits)\n",
    "train = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "\n",
    "predictions = tf.argmax(tf.nn.softmax(logits), 1)\n",
    "accuracy = tf.metrics.accuracy(tf.argmax(Y, 1), predictions)\n",
    "\n",
    "batch_size = 100\n",
    "with tf.Session() as sess:\n",
    "    total_batch = int(mnist.train.num_examples/ batch_size)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    for epoch in range(15):\n",
    "        total_cost = 0\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, c, = sess.run([train, cost], feed_dict = {X:batch_xs.reshape(-1, 28, 28, 1), Y: batch_ys, keep_prob: 0.8})\n",
    "        acc = sess.run([accuracy], feed_dict = {X: mnist.test.images.reshape(-1, 28, 28, 1), Y: mnist.test.labels, keep_prob: 1.0})\n",
    "        print('epoch : {}, cost : {}, acc: {}'.format(epoch, c, acc))\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "def model_net(x, activation, is_training, reuse = False):\n",
    "    L1 = tf.layers.conv2d(x, 32, 3, padding='SAME', activation = activation, reuse= reuse, name = 'L1')\n",
    "    L1 = tf.layers.max_pooling2d(L1, 2, 2)\n",
    "    L2 = tf.layers.conv2d(L1, 64, 3, padding='SAME', activation = activation, reuse=reuse, name = 'L2')\n",
    "    L2 = tf.layers.max_pooling2d(L2, 2, 2)\n",
    "    \n",
    "    L2_flatten = tf.contrib.layers.flatten(L2)\n",
    "    \n",
    "    fc1 = tf.layers.dense(L2_flatten, 256, activation = activation, reuse=reuse, name = 'FC1')\n",
    "    fc1 = tf.layers.dropout(fc1, 0.2, training = is_training)\n",
    "    \n",
    "    fc2 = tf.layers.dense(fc1, 10, reuse=reuse, name = 'output')\n",
    "    return fc2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = model_net(X, tf.nn.relu, True)\n",
    "test_logits = model_net(X, tf.nn.relu, False, True)\n",
    "cost = tf.losses.softmax_cross_entropy(Y, logits = logits)\n",
    "train = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "\n",
    "predictions = tf.argmax(tf.nn.softmax(test_logits), 1)\n",
    "accuracy = tf.metrics.accuracy(tf.argmax(Y, 1), predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, cost : 0.020873257890343666, acc: [(0.0, 0.98430002)]\n",
      "epoch : 1, cost : 0.012488684616982937, acc: [(0.98430002, 0.98689997)]\n",
      "epoch : 2, cost : 0.058932267129421234, acc: [(0.98689997, 0.9878)]\n",
      "epoch : 3, cost : 0.050051361322402954, acc: [(0.9878, 0.98860002)]\n",
      "epoch : 4, cost : 0.047780223190784454, acc: [(0.98860002, 0.98923999)]\n",
      "epoch : 5, cost : 0.03912124037742615, acc: [(0.98923999, 0.98943335)]\n",
      "epoch : 6, cost : 0.02453668788075447, acc: [(0.98943335, 0.98968571)]\n",
      "epoch : 7, cost : 0.0036200848408043385, acc: [(0.98968571, 0.98982501)]\n",
      "epoch : 8, cost : 0.0011123416479676962, acc: [(0.98982501, 0.99014443)]\n",
      "epoch : 9, cost : 0.004260535817593336, acc: [(0.99014443, 0.98979002)]\n",
      "epoch : 10, cost : 0.007146528456360102, acc: [(0.98979002, 0.98985457)]\n",
      "epoch : 11, cost : 0.04281054064631462, acc: [(0.98985457, 0.99010831)]\n",
      "epoch : 12, cost : 0.0008145206375047565, acc: [(0.99010831, 0.99017692)]\n",
      "epoch : 13, cost : 0.02385837584733963, acc: [(0.99017692, 0.99017859)]\n",
      "epoch : 14, cost : 0.00028013234259560704, acc: [(0.99017859, 0.99027997)]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "with tf.Session() as sess:\n",
    "    total_batch = int(mnist.train.num_examples/ batch_size)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    for epoch in range(15):\n",
    "        total_cost = 0\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, c, = sess.run([train, cost], feed_dict = {X:batch_xs.reshape(-1, 28, 28, 1), Y: batch_ys})\n",
    "        acc = sess.run([accuracy], feed_dict = {X: mnist.test.images.reshape(-1, 28, 28, 1), Y: mnist.test.labels})\n",
    "        print('epoch : {}, cost : {}, acc: {}'.format(epoch, c, acc))\n",
    "            \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
