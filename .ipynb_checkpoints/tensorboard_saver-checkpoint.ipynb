{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = np.array([[0, 0], \n",
    "                   [1, 0], \n",
    "                   [1, 1],\n",
    "                   [0, 0], \n",
    "                   [0, 0], \n",
    "                   [0, 1]])\n",
    "y_data = np.array([[1, 0, 0],\n",
    "                   [0, 1, 0],\n",
    "                   [0, 0, 1],\n",
    "                   [1, 0, 0],\n",
    "                   [1, 0, 0],\n",
    "                   [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 2), (6, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.38544\n",
      "(0.0, 0.66666669)\n",
      "1 1.18533\n",
      "(0.66666669, 0.66666669)\n",
      "2 0.995165\n",
      "(0.66666669, 0.66666669)\n",
      "3 0.811646\n",
      "(0.66666669, 0.70833331)\n",
      "4 0.666484\n",
      "(0.70833331, 0.73333335)\n",
      "5 0.570506\n",
      "(0.73333335, 0.75)\n",
      "6 0.488543\n",
      "(0.75, 0.76190478)\n",
      "7 0.413468\n",
      "(0.76190478, 0.77083331)\n",
      "8 0.350096\n",
      "(0.77083331, 0.77777779)\n",
      "9 0.3024\n",
      "(0.77777779, 0.80000001)\n",
      "10 0.261952\n",
      "(0.80000001, 0.81818181)\n",
      "11 0.226633\n",
      "(0.81818181, 0.83333331)\n",
      "12 0.197546\n",
      "(0.83333331, 0.84615386)\n",
      "13 0.17391\n",
      "(0.84615386, 0.85714287)\n",
      "14 0.154011\n",
      "(0.85714287, 0.86666667)\n",
      "15 0.137868\n",
      "(0.86666667, 0.875)\n",
      "16 0.124983\n",
      "(0.875, 0.88235295)\n",
      "17 0.113131\n",
      "(0.88235295, 0.8888889)\n",
      "18 0.101623\n",
      "(0.8888889, 0.89473683)\n",
      "19 0.0898138\n",
      "(0.89473683, 0.89999998)\n",
      "20 0.0793247\n",
      "(0.89999998, 0.90476191)\n",
      "21 0.0704903\n",
      "(0.90476191, 0.90909094)\n",
      "22 0.0627403\n",
      "(0.90909094, 0.9130435)\n",
      "23 0.0560203\n",
      "(0.9130435, 0.91666669)\n",
      "24 0.0500523\n",
      "(0.91666669, 0.92000002)\n",
      "25 0.0446398\n",
      "(0.92000002, 0.92307693)\n",
      "26 0.0396989\n",
      "(0.92307693, 0.92592591)\n",
      "27 0.0352116\n",
      "(0.92592591, 0.9285714)\n",
      "28 0.0311857\n",
      "(0.9285714, 0.93103451)\n",
      "29 0.0280087\n",
      "(0.93103451, 0.93333334)\n",
      "30 0.0254473\n",
      "(0.93333334, 0.93548387)\n",
      "31 0.0231018\n",
      "(0.93548387, 0.9375)\n",
      "32 0.0209948\n",
      "(0.9375, 0.93939394)\n",
      "33 0.0191301\n",
      "(0.93939394, 0.94117647)\n",
      "34 0.0174951\n",
      "(0.94117647, 0.94285715)\n",
      "35 0.0160675\n",
      "(0.94285715, 0.94444442)\n",
      "36 0.0148196\n",
      "(0.94444442, 0.94594592)\n",
      "37 0.0137497\n",
      "(0.94594592, 0.94736844)\n",
      "38 0.0128615\n",
      "(0.94736844, 0.94871795)\n",
      "39 0.0120577\n",
      "(0.94871795, 0.94999999)\n",
      "40 0.0113336\n",
      "(0.94999999, 0.9512195)\n",
      "41 0.0106925\n",
      "(0.9512195, 0.95238096)\n",
      "42 0.0100961\n",
      "(0.95238096, 0.95348835)\n",
      "43 0.00954111\n",
      "(0.95348835, 0.95454544)\n",
      "44 0.0090249\n",
      "(0.95454544, 0.95555556)\n",
      "45 0.00854539\n",
      "(0.95555556, 0.95652175)\n",
      "46 0.00810058\n",
      "(0.95652175, 0.95744681)\n",
      "47 0.00768869\n",
      "(0.95744681, 0.95833331)\n",
      "48 0.00730761\n",
      "(0.95833331, 0.95918369)\n",
      "49 0.00695551\n",
      "(0.95918369, 0.95999998)\n",
      "50 0.0066301\n",
      "(0.95999998, 0.96078432)\n",
      "51 0.00633605\n",
      "(0.96078432, 0.96153843)\n",
      "52 0.00607021\n",
      "(0.96153843, 0.96226418)\n",
      "53 0.00582417\n",
      "(0.96226418, 0.96296299)\n",
      "54 0.00560097\n",
      "(0.96296299, 0.96363634)\n",
      "55 0.00539439\n",
      "(0.96363634, 0.96428573)\n",
      "56 0.00519921\n",
      "(0.96428573, 0.9649123)\n",
      "57 0.0050145\n",
      "(0.9649123, 0.96551722)\n",
      "58 0.00483962\n",
      "(0.96551722, 0.96610171)\n",
      "59 0.00467389\n",
      "(0.96610171, 0.96666664)\n",
      "60 0.00451685\n",
      "(0.96666664, 0.96721309)\n",
      "61 0.00436781\n",
      "(0.96721309, 0.96774191)\n",
      "62 0.00422644\n",
      "(0.96774191, 0.96825397)\n",
      "63 0.00409239\n",
      "(0.96825397, 0.96875)\n",
      "64 0.00396511\n",
      "(0.96875, 0.96923077)\n",
      "65 0.00384434\n",
      "(0.96923077, 0.969697)\n",
      "66 0.0037295\n",
      "(0.969697, 0.97014928)\n",
      "67 0.00362043\n",
      "(0.97014928, 0.97058821)\n",
      "68 0.00351839\n",
      "(0.97058821, 0.9710145)\n",
      "69 0.00342602\n",
      "(0.9710145, 0.97142857)\n",
      "70 0.0033377\n",
      "(0.97142857, 0.97183096)\n",
      "71 0.00325311\n",
      "(0.97183096, 0.97222221)\n",
      "72 0.00317768\n",
      "(0.97222221, 0.97260273)\n",
      "73 0.00310787\n",
      "(0.97260273, 0.97297299)\n",
      "74 0.00303944\n",
      "(0.97297299, 0.97333336)\n",
      "75 0.00297242\n",
      "(0.97333336, 0.97368419)\n",
      "76 0.00290699\n",
      "(0.97368419, 0.97402596)\n",
      "77 0.00284317\n",
      "(0.97402596, 0.97435898)\n",
      "78 0.0027809\n",
      "(0.97435898, 0.97468352)\n",
      "79 0.00272038\n",
      "(0.97468352, 0.97500002)\n",
      "80 0.00266343\n",
      "(0.97500002, 0.97530866)\n",
      "81 0.00261141\n",
      "(0.97530866, 0.97560978)\n",
      "82 0.00256061\n",
      "(0.97560978, 0.97590363)\n",
      "83 0.00251093\n",
      "(0.97590363, 0.97619045)\n",
      "84 0.00246231\n",
      "(0.97619045, 0.97647059)\n",
      "85 0.00241494\n",
      "(0.97647059, 0.97674417)\n",
      "86 0.00236858\n",
      "(0.97674417, 0.9770115)\n",
      "87 0.00232344\n",
      "(0.9770115, 0.97727275)\n",
      "88 0.00228603\n",
      "(0.97727275, 0.9775281)\n",
      "89 0.00224879\n",
      "(0.9775281, 0.97777778)\n",
      "90 0.00221201\n",
      "(0.97777778, 0.97802198)\n",
      "91 0.00217687\n",
      "(0.97802198, 0.97826087)\n",
      "92 0.00214147\n",
      "(0.97826087, 0.97849464)\n",
      "93 0.00210623\n",
      "(0.97849464, 0.97872341)\n",
      "94 0.00207247\n",
      "(0.97872341, 0.97894734)\n",
      "95 0.00203929\n",
      "(0.97894734, 0.97916669)\n",
      "96 0.00200653\n",
      "(0.97916669, 0.97938144)\n",
      "97 0.00197474\n",
      "(0.97938144, 0.97959185)\n",
      "98 0.00194373\n",
      "(0.97959185, 0.97979796)\n",
      "99 0.00191299\n",
      "(0.97979796, 0.98000002)\n",
      "100 0.00188469\n",
      "(0.98000002, 0.98019803)\n",
      "101 0.00185775\n",
      "(0.98019803, 0.98039216)\n",
      "102 0.00183079\n",
      "(0.98039216, 0.98058254)\n",
      "103 0.00180391\n",
      "(0.98058254, 0.98076922)\n",
      "104 0.00177757\n",
      "(0.98076922, 0.98095238)\n",
      "105 0.00175229\n",
      "(0.98095238, 0.98113209)\n",
      "106 0.00172772\n",
      "(0.98113209, 0.9813084)\n",
      "107 0.00170363\n",
      "(0.9813084, 0.98148149)\n",
      "108 0.00167975\n",
      "(0.98148149, 0.98165137)\n",
      "109 0.00165599\n",
      "(0.98165137, 0.9818182)\n",
      "110 0.00163278\n",
      "(0.9818182, 0.98198199)\n",
      "111 0.00161096\n",
      "(0.98198199, 0.98214287)\n",
      "112 0.00158998\n",
      "(0.98214287, 0.98230088)\n",
      "113 0.00156877\n",
      "(0.98230088, 0.98245615)\n",
      "114 0.00154843\n",
      "(0.98245615, 0.98260868)\n",
      "115 0.00152846\n",
      "(0.98260868, 0.98275864)\n",
      "116 0.00150837\n",
      "(0.98275864, 0.98290598)\n",
      "117 0.00148821\n",
      "(0.98290598, 0.98305082)\n",
      "118 0.00146944\n",
      "(0.98305082, 0.98319328)\n",
      "119 0.00145119\n",
      "(0.98319328, 0.98333335)\n",
      "120 0.00143286\n",
      "(0.98333335, 0.9834711)\n",
      "121 0.00141458\n",
      "(0.9834711, 0.98360658)\n",
      "122 0.00139732\n",
      "(0.98360658, 0.98373985)\n",
      "123 0.00138044\n",
      "(0.98373985, 0.98387098)\n",
      "124 0.00136355\n",
      "(0.98387098, 0.98400003)\n",
      "125 0.00134711\n",
      "(0.98400003, 0.98412699)\n",
      "126 0.00133114\n",
      "(0.98412699, 0.98425198)\n",
      "127 0.00131542\n",
      "(0.98425198, 0.984375)\n",
      "128 0.00129951\n",
      "(0.984375, 0.98449612)\n",
      "129 0.00128375\n",
      "(0.98449612, 0.98461539)\n",
      "130 0.00126871\n",
      "(0.98461539, 0.98473281)\n",
      "131 0.0012541\n",
      "(0.98473281, 0.9848485)\n",
      "132 0.00123936\n",
      "(0.9848485, 0.9849624)\n",
      "133 0.0012251\n",
      "(0.9849624, 0.98507464)\n",
      "134 0.00121075\n",
      "(0.98507464, 0.98518521)\n",
      "135 0.00119666\n",
      "(0.98518521, 0.9852941)\n",
      "136 0.00118314\n",
      "(0.9852941, 0.98540145)\n",
      "137 0.0011699\n",
      "(0.98540145, 0.98550725)\n",
      "138 0.00115655\n",
      "(0.98550725, 0.9856115)\n",
      "139 0.00114373\n",
      "(0.9856115, 0.98571426)\n",
      "140 0.00113102\n",
      "(0.98571426, 0.98581558)\n",
      "141 0.00111882\n",
      "(0.98581558, 0.98591548)\n",
      "142 0.00110669\n",
      "(0.98591548, 0.98601401)\n",
      "143 0.00109454\n",
      "(0.98601401, 0.9861111)\n",
      "144 0.00108246\n",
      "(0.9861111, 0.98620689)\n",
      "145 0.00107043\n",
      "(0.98620689, 0.98630136)\n",
      "146 0.00105925\n",
      "(0.98630136, 0.98639458)\n",
      "147 0.0010481\n",
      "(0.98639458, 0.98648649)\n",
      "148 0.00103696\n",
      "(0.98648649, 0.98657715)\n",
      "149 0.00102573\n",
      "(0.98657715, 0.98666668)\n",
      "150 0.00101481\n",
      "(0.98666668, 0.98675495)\n",
      "151 0.00100412\n",
      "(0.98675495, 0.9868421)\n",
      "152 0.000993645\n",
      "(0.9868421, 0.98692811)\n",
      "153 0.00098365\n",
      "(0.98692811, 0.98701298)\n",
      "154 0.000973614\n",
      "(0.98701298, 0.98709679)\n",
      "155 0.000963341\n",
      "(0.98709679, 0.98717946)\n",
      "156 0.000953463\n",
      "(0.98717946, 0.98726118)\n",
      "157 0.000943943\n",
      "(0.98726118, 0.98734176)\n",
      "158 0.000934403\n",
      "(0.98734176, 0.98742139)\n",
      "159 0.000924824\n",
      "(0.98742139, 0.98750001)\n",
      "160 0.000915462\n",
      "(0.98750001, 0.98757762)\n",
      "161 0.000906537\n",
      "(0.98757762, 0.98765433)\n",
      "162 0.000897552\n",
      "(0.98765433, 0.98773009)\n",
      "163 0.000888368\n",
      "(0.98773009, 0.98780489)\n",
      "164 0.000879818\n",
      "(0.98780489, 0.9878788)\n",
      "165 0.000871329\n",
      "(0.9878788, 0.98795182)\n",
      "166 0.000862839\n",
      "(0.98795182, 0.98802394)\n",
      "167 0.000854428\n",
      "(0.98802394, 0.98809522)\n",
      "168 0.000846156\n",
      "(0.98809522, 0.98816568)\n",
      "169 0.000837923\n",
      "(0.98816568, 0.98823529)\n",
      "170 0.000829948\n",
      "(0.98823529, 0.98830408)\n",
      "171 0.000821973\n",
      "(0.98830408, 0.98837209)\n",
      "172 0.000814098\n",
      "(0.98837209, 0.98843932)\n",
      "173 0.000806677\n",
      "(0.98843932, 0.98850572)\n",
      "174 0.000799019\n",
      "(0.98850572, 0.98857141)\n",
      "175 0.000791619\n",
      "(0.98857141, 0.98863637)\n",
      "176 0.00078414\n",
      "(0.98863637, 0.98870057)\n",
      "177 0.000776819\n",
      "(0.98870057, 0.98876405)\n",
      "178 0.000769598\n",
      "(0.98876405, 0.98882681)\n",
      "179 0.000762555\n",
      "(0.98882681, 0.98888886)\n",
      "180 0.000755531\n",
      "(0.98888886, 0.98895025)\n",
      "181 0.000748627\n",
      "(0.98895025, 0.98901099)\n",
      "182 0.000741961\n",
      "(0.98901099, 0.98907101)\n",
      "183 0.000735195\n",
      "(0.98907101, 0.98913044)\n",
      "184 0.000728687\n",
      "(0.98913044, 0.98918921)\n",
      "185 0.000722139\n",
      "(0.98918921, 0.98924732)\n",
      "186 0.000715571\n",
      "(0.98924732, 0.98930484)\n",
      "187 0.000709182\n",
      "(0.98930484, 0.9893617)\n",
      "188 0.000702952\n",
      "(0.9893617, 0.98941797)\n",
      "189 0.000696781\n",
      "(0.98941797, 0.9894737)\n",
      "190 0.00069063\n",
      "(0.9894737, 0.98952878)\n",
      "191 0.000684518\n",
      "(0.98952878, 0.98958331)\n",
      "192 0.000678684\n",
      "(0.98958331, 0.98963732)\n",
      "193 0.000672751\n",
      "(0.98963732, 0.98969072)\n",
      "194 0.000666996\n",
      "(0.98969072, 0.98974359)\n",
      "195 0.000661281\n",
      "(0.98974359, 0.98979592)\n",
      "196 0.000655646\n",
      "(0.98979592, 0.98984772)\n",
      "197 0.00065001\n",
      "(0.98984772, 0.98989898)\n",
      "198 0.000644513\n",
      "(0.98989898, 0.98994976)\n",
      "199 0.000639175\n",
      "(0.98994976, 0.99000001)\n",
      "200 0.000633777\n",
      "(0.99000001, 0.99004978)\n",
      "201 0.0006283\n",
      "(0.99004978, 0.99009901)\n",
      "202 0.00062314\n",
      "(0.99009901, 0.99014777)\n",
      "203 0.00061804\n",
      "(0.99014777, 0.99019605)\n",
      "204 0.000613019\n",
      "(0.99019605, 0.99024391)\n",
      "205 0.000607899\n",
      "(0.99024391, 0.99029124)\n",
      "206 0.000602778\n",
      "(0.99029124, 0.99033815)\n",
      "207 0.000597738\n",
      "(0.99033815, 0.99038464)\n",
      "208 0.000593014\n",
      "(0.99038464, 0.99043059)\n",
      "209 0.000588351\n",
      "(0.99043059, 0.99047619)\n",
      "210 0.000583568\n",
      "(0.99047619, 0.99052131)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211 0.000578705\n",
      "(0.99052131, 0.99056602)\n",
      "212 0.000573962\n",
      "(0.99056602, 0.9906103)\n",
      "213 0.000569456\n",
      "(0.9906103, 0.99065423)\n",
      "214 0.000564951\n",
      "(0.99065423, 0.99069768)\n",
      "215 0.000560366\n",
      "(0.99069768, 0.99074072)\n",
      "216 0.00055598\n",
      "(0.99074072, 0.99078339)\n",
      "217 0.000551653\n",
      "(0.99078339, 0.99082571)\n",
      "218 0.000547307\n",
      "(0.99082571, 0.99086756)\n",
      "219 0.00054296\n",
      "(0.99086756, 0.9909091)\n",
      "220 0.000538733\n",
      "(0.9909091, 0.99095023)\n",
      "221 0.000534584\n",
      "(0.99095023, 0.990991)\n",
      "222 0.000530376\n",
      "(0.990991, 0.99103141)\n",
      "223 0.000526367\n",
      "(0.99103141, 0.9910714)\n",
      "224 0.000522218\n",
      "(0.9910714, 0.9911111)\n",
      "225 0.000518268\n",
      "(0.9911111, 0.99115044)\n",
      "226 0.000514239\n",
      "(0.99115044, 0.99118942)\n",
      "227 0.000510388\n",
      "(0.99118942, 0.99122804)\n",
      "228 0.000506418\n",
      "(0.99122804, 0.99126637)\n",
      "229 0.000502627\n",
      "(0.99126637, 0.99130434)\n",
      "230 0.000498776\n",
      "(0.99130434, 0.99134201)\n",
      "231 0.000494945\n",
      "(0.99134201, 0.99137932)\n",
      "232 0.000491293\n",
      "(0.99137932, 0.99141634)\n",
      "233 0.00048766\n",
      "(0.99141634, 0.99145299)\n",
      "234 0.000484008\n",
      "(0.99145299, 0.99148935)\n",
      "235 0.000480514\n",
      "(0.99148935, 0.99152541)\n",
      "236 0.00047704\n",
      "(0.99152541, 0.99156117)\n",
      "237 0.000473507\n",
      "(0.99156117, 0.99159664)\n",
      "238 0.000469934\n",
      "(0.99159664, 0.99163181)\n",
      "239 0.00046648\n",
      "(0.99163181, 0.99166667)\n",
      "240 0.000463125\n",
      "(0.99166667, 0.99170125)\n",
      "241 0.00045979\n",
      "(0.99170125, 0.99173552)\n",
      "242 0.000456495\n",
      "(0.99173552, 0.99176955)\n",
      "243 0.000453279\n",
      "(0.99176955, 0.99180329)\n",
      "244 0.000449984\n",
      "(0.99180329, 0.99183673)\n",
      "245 0.000446768\n",
      "(0.99183673, 0.99186993)\n",
      "246 0.000443532\n",
      "(0.99186993, 0.99190283)\n",
      "247 0.000440395\n",
      "(0.99190283, 0.99193549)\n",
      "248 0.000437298\n",
      "(0.99193549, 0.99196786)\n",
      "249 0.000434162\n",
      "(0.99196786, 0.99199998)\n",
      "250 0.000431204\n",
      "(0.99199998, 0.99203187)\n",
      "251 0.000428206\n",
      "(0.99203187, 0.99206346)\n",
      "252 0.000425248\n",
      "(0.99206346, 0.99209487)\n",
      "253 0.000422191\n",
      "(0.99209487, 0.99212599)\n",
      "254 0.000419352\n",
      "(0.99212599, 0.99215686)\n",
      "255 0.000416433\n",
      "(0.99215686, 0.9921875)\n",
      "256 0.000413575\n",
      "(0.9921875, 0.9922179)\n",
      "257 0.000410696\n",
      "(0.9922179, 0.99224806)\n",
      "258 0.000407877\n",
      "(0.99224806, 0.99227798)\n",
      "259 0.000405098\n",
      "(0.99227798, 0.99230766)\n",
      "260 0.000402417\n",
      "(0.99230766, 0.99233717)\n",
      "261 0.000399658\n",
      "(0.99233717, 0.99236643)\n",
      "262 0.000396918\n",
      "(0.99236643, 0.99239546)\n",
      "263 0.000394297\n",
      "(0.99239546, 0.99242425)\n",
      "264 0.000391558\n",
      "(0.99242425, 0.99245286)\n",
      "265 0.000388977\n",
      "(0.99245286, 0.99248123)\n",
      "266 0.000386336\n",
      "(0.99248123, 0.99250937)\n",
      "267 0.000383775\n",
      "(0.99250937, 0.99253732)\n",
      "268 0.000381313\n",
      "(0.99253732, 0.99256504)\n",
      "269 0.000378772\n",
      "(0.99256504, 0.99259257)\n",
      "270 0.00037629\n",
      "(0.99259257, 0.99261993)\n",
      "271 0.000373748\n",
      "(0.99261993, 0.99264705)\n",
      "272 0.000371247\n",
      "(0.99264705, 0.99267399)\n",
      "273 0.000368884\n",
      "(0.99267399, 0.99270076)\n",
      "274 0.000366442\n",
      "(0.99270076, 0.99272728)\n",
      "275 0.000364099\n",
      "(0.99272728, 0.99275362)\n",
      "276 0.000361816\n",
      "(0.99275362, 0.99277979)\n",
      "277 0.000359414\n",
      "(0.99277979, 0.99280578)\n",
      "278 0.00035711\n",
      "(0.99280578, 0.99283153)\n",
      "279 0.000354887\n",
      "(0.99283153, 0.99285716)\n",
      "280 0.000352643\n",
      "(0.99285716, 0.99288255)\n",
      "281 0.000350439\n",
      "(0.99288255, 0.99290782)\n",
      "282 0.000348176\n",
      "(0.99290782, 0.99293286)\n",
      "283 0.000345932\n",
      "(0.99293286, 0.99295777)\n",
      "284 0.000343688\n",
      "(0.99295777, 0.99298245)\n",
      "285 0.000341584\n",
      "(0.99298245, 0.993007)\n",
      "286 0.000339439\n",
      "(0.993007, 0.99303138)\n",
      "287 0.000337295\n",
      "(0.99303138, 0.99305558)\n",
      "288 0.00033519\n",
      "(0.99305558, 0.9930796)\n",
      "289 0.000333145\n",
      "(0.9930796, 0.99310344)\n",
      "290 0.00033108\n",
      "(0.99310344, 0.99312717)\n",
      "291 0.000329055\n",
      "(0.99312717, 0.99315071)\n",
      "292 0.00032701\n",
      "(0.99315071, 0.99317408)\n",
      "293 0.000325024\n",
      "(0.99317408, 0.99319726)\n",
      "294 0.000323018\n",
      "(0.99319726, 0.99322033)\n",
      "295 0.000321152\n",
      "(0.99322033, 0.99324322)\n",
      "296 0.000319127\n",
      "(0.99324322, 0.99326599)\n",
      "297 0.000317121\n",
      "(0.99326599, 0.99328858)\n",
      "298 0.000315235\n",
      "(0.99328858, 0.99331105)\n",
      "299 0.000313388\n",
      "(0.99331105, 0.99333334)\n",
      "300 0.000311502\n",
      "(0.99333334, 0.99335545)\n",
      "301 0.000309655\n",
      "(0.99335545, 0.99337751)\n",
      "302 0.000307729\n",
      "(0.99337751, 0.99339932)\n",
      "303 0.000305882\n",
      "(0.99339932, 0.99342108)\n",
      "304 0.000304115\n",
      "(0.99342108, 0.9934426)\n",
      "305 0.000302248\n",
      "(0.9934426, 0.99346405)\n",
      "306 0.000300461\n",
      "(0.99346405, 0.99348533)\n",
      "307 0.000298734\n",
      "(0.99348533, 0.99350649)\n",
      "308 0.000296967\n",
      "(0.99350649, 0.99352753)\n",
      "309 0.000295219\n",
      "(0.99352753, 0.99354839)\n",
      "310 0.000293472\n",
      "(0.99354839, 0.99356914)\n",
      "311 0.000291804\n",
      "(0.99356914, 0.99358976)\n",
      "312 0.000290076\n",
      "(0.99358976, 0.9936102)\n",
      "313 0.000288428\n",
      "(0.9936102, 0.99363059)\n",
      "314 0.00028676\n",
      "(0.99363059, 0.99365079)\n",
      "315 0.000285072\n",
      "(0.99365079, 0.99367088)\n",
      "316 0.000283444\n",
      "(0.99367088, 0.99369085)\n",
      "317 0.000281815\n",
      "(0.99369085, 0.9937107)\n",
      "318 0.000280167\n",
      "(0.9937107, 0.99373043)\n",
      "319 0.000278479\n",
      "(0.99373043, 0.99374998)\n",
      "320 0.000276871\n",
      "(0.99374998, 0.99376947)\n",
      "321 0.000275242\n",
      "(0.99376947, 0.99378884)\n",
      "322 0.000273713\n",
      "(0.99378884, 0.99380803)\n",
      "323 0.000272085\n",
      "(0.99380803, 0.99382716)\n",
      "324 0.000270516\n",
      "(0.99382716, 0.99384618)\n",
      "325 0.000269007\n",
      "(0.99384618, 0.99386501)\n",
      "326 0.000267438\n",
      "(0.99386501, 0.99388379)\n",
      "327 0.000265909\n",
      "(0.99388379, 0.99390244)\n",
      "328 0.00026442\n",
      "(0.99390244, 0.99392098)\n",
      "329 0.00026291\n",
      "(0.99392098, 0.9939394)\n",
      "330 0.000261421\n",
      "(0.9939394, 0.9939577)\n",
      "331 0.000259912\n",
      "(0.9939577, 0.99397588)\n",
      "332 0.000258462\n",
      "(0.99397588, 0.993994)\n",
      "333 0.000257052\n",
      "(0.993994, 0.994012)\n",
      "334 0.000255543\n",
      "(0.994012, 0.99402988)\n",
      "335 0.000254113\n",
      "(0.99402988, 0.99404764)\n",
      "336 0.000252703\n",
      "(0.99404764, 0.99406528)\n",
      "337 0.000251372\n",
      "(0.99406528, 0.99408287)\n",
      "338 0.000249943\n",
      "(0.99408287, 0.99410027)\n",
      "339 0.000248533\n",
      "(0.99410027, 0.99411762)\n",
      "340 0.000247103\n",
      "(0.99411762, 0.9941349)\n",
      "341 0.000245812\n",
      "(0.9941349, 0.99415207)\n",
      "342 0.000244442\n",
      "(0.99415207, 0.99416912)\n",
      "343 0.000243111\n",
      "(0.99416912, 0.99418604)\n",
      "344 0.000241781\n",
      "(0.99418604, 0.99420291)\n",
      "345 0.00024051\n",
      "(0.99420291, 0.99421966)\n",
      "346 0.000239159\n",
      "(0.99421966, 0.99423629)\n",
      "347 0.000237888\n",
      "(0.99423629, 0.99425286)\n",
      "348 0.000236637\n",
      "(0.99425286, 0.99426931)\n",
      "349 0.000235326\n",
      "(0.99426931, 0.9942857)\n",
      "350 0.000234095\n",
      "(0.9942857, 0.99430197)\n",
      "351 0.000232804\n",
      "(0.99430197, 0.99431819)\n",
      "352 0.000231573\n",
      "(0.99431819, 0.99433428)\n",
      "353 0.000230361\n",
      "(0.99433428, 0.99435025)\n",
      "354 0.00022911\n",
      "(0.99435025, 0.99436617)\n",
      "355 0.000227859\n",
      "(0.99436617, 0.99438202)\n",
      "356 0.000226628\n",
      "(0.99438202, 0.99439776)\n",
      "357 0.000225436\n",
      "(0.99439776, 0.99441344)\n",
      "358 0.000224304\n",
      "(0.99441344, 0.99442899)\n",
      "359 0.000223132\n",
      "(0.99442899, 0.99444443)\n",
      "360 0.000221981\n",
      "(0.99444443, 0.99445981)\n",
      "361 0.000220769\n",
      "(0.99445981, 0.99447513)\n",
      "362 0.000219677\n",
      "(0.99447513, 0.99449039)\n",
      "363 0.000218565\n",
      "(0.99449039, 0.99450547)\n",
      "364 0.000217433\n",
      "(0.99450547, 0.99452055)\n",
      "365 0.000216281\n",
      "(0.99452055, 0.99453551)\n",
      "366 0.000215208\n",
      "(0.99453551, 0.99455041)\n",
      "367 0.000214116\n",
      "(0.99455041, 0.99456519)\n",
      "368 0.000213044\n",
      "(0.99456519, 0.99457997)\n",
      "369 0.000211931\n",
      "(0.99457997, 0.99459457)\n",
      "370 0.000210839\n",
      "(0.99459457, 0.99460918)\n",
      "371 0.000209767\n",
      "(0.99460918, 0.99462366)\n",
      "372 0.000208694\n",
      "(0.99462366, 0.99463809)\n",
      "373 0.000207661\n",
      "(0.99463809, 0.99465239)\n",
      "374 0.000206629\n",
      "(0.99465239, 0.9946667)\n",
      "375 0.000205576\n",
      "(0.9946667, 0.99468082)\n",
      "376 0.000204563\n",
      "(0.99468082, 0.99469495)\n",
      "377 0.000203511\n",
      "(0.99469495, 0.99470901)\n",
      "378 0.000202498\n",
      "(0.99470901, 0.99472296)\n",
      "379 0.000201544\n",
      "(0.99472296, 0.99473685)\n",
      "380 0.000200591\n",
      "(0.99473685, 0.99475068)\n",
      "381 0.000199538\n",
      "(0.99475068, 0.99476439)\n",
      "382 0.000198545\n",
      "(0.99476439, 0.9947781)\n",
      "383 0.000197572\n",
      "(0.9947781, 0.99479169)\n",
      "384 0.000196619\n",
      "(0.99479169, 0.99480522)\n",
      "385 0.000195666\n",
      "(0.99480522, 0.99481863)\n",
      "386 0.000194752\n",
      "(0.99481863, 0.99483204)\n",
      "387 0.000193779\n",
      "(0.99483204, 0.99484539)\n",
      "388 0.000192786\n",
      "(0.99484539, 0.99485862)\n",
      "389 0.000191892\n",
      "(0.99485862, 0.9948718)\n",
      "390 0.000190978\n",
      "(0.9948718, 0.99488491)\n",
      "391 0.000190025\n",
      "(0.99488491, 0.99489796)\n",
      "392 0.000189131\n",
      "(0.99489796, 0.99491096)\n",
      "393 0.000188158\n",
      "(0.99491096, 0.99492383)\n",
      "394 0.000187264\n",
      "(0.99492383, 0.9949367)\n",
      "395 0.000186391\n",
      "(0.9949367, 0.99494952)\n",
      "396 0.000185536\n",
      "(0.99494952, 0.99496222)\n",
      "397 0.000184623\n",
      "(0.99496222, 0.99497485)\n",
      "398 0.000183769\n",
      "(0.99497485, 0.99498749)\n",
      "399 0.000182935\n",
      "(0.99498749, 0.995)\n",
      "400 0.000182021\n",
      "(0.995, 0.99501246)\n",
      "401 0.000181187\n",
      "(0.99501246, 0.99502486)\n",
      "402 0.000180333\n",
      "(0.99502486, 0.9950372)\n",
      "403 0.000179479\n",
      "(0.9950372, 0.99504948)\n",
      "404 0.000178645\n",
      "(0.99504948, 0.99506176)\n",
      "405 0.00017783\n",
      "(0.99506176, 0.99507391)\n",
      "406 0.000177036\n",
      "(0.99507391, 0.99508601)\n",
      "407 0.000176202\n",
      "(0.99508601, 0.99509805)\n",
      "408 0.000175387\n",
      "(0.99509805, 0.99511003)\n",
      "409 0.000174573\n",
      "(0.99511003, 0.99512196)\n",
      "410 0.000173759\n",
      "(0.99512196, 0.99513382)\n",
      "411 0.000172964\n",
      "(0.99513382, 0.99514562)\n",
      "412 0.000172209\n",
      "(0.99514562, 0.99515736)\n",
      "413 0.000171375\n",
      "(0.99515736, 0.9951691)\n",
      "414 0.000170621\n",
      "(0.9951691, 0.99518073)\n",
      "415 0.000169866\n",
      "(0.99518073, 0.99519229)\n",
      "416 0.000169051\n",
      "(0.99519229, 0.99520385)\n",
      "417 0.000168317\n",
      "(0.99520385, 0.9952153)\n",
      "418 0.000167542\n",
      "(0.9952153, 0.99522674)\n",
      "419 0.000166787\n",
      "(0.99522674, 0.99523807)\n",
      "420 0.000166072\n",
      "(0.99523807, 0.99524939)\n",
      "421 0.000165298\n",
      "(0.99524939, 0.99526066)\n",
      "422 0.000164602\n",
      "(0.99526066, 0.99527186)\n",
      "423 0.000163848\n",
      "(0.99527186, 0.99528301)\n",
      "424 0.000163073\n",
      "(0.99528301, 0.99529409)\n",
      "425 0.000162378\n",
      "(0.99529409, 0.99530518)\n",
      "426 0.000161643\n",
      "(0.99530518, 0.99531615)\n",
      "427 0.000161007\n",
      "(0.99531615, 0.99532712)\n",
      "428 0.000160292\n",
      "(0.99532712, 0.99533802)\n",
      "429 0.000159538\n",
      "(0.99533802, 0.99534881)\n",
      "430 0.000158862\n",
      "(0.99534881, 0.9953596)\n",
      "431 0.000158187\n",
      "(0.9953596, 0.99537039)\n",
      "432 0.000157492\n",
      "(0.99537039, 0.99538106)\n",
      "433 0.000156836\n",
      "(0.99538106, 0.99539173)\n",
      "434 0.000156062\n",
      "(0.99539173, 0.99540228)\n",
      "435 0.000155386\n",
      "(0.99540228, 0.99541283)\n",
      "436 0.000154731\n",
      "(0.99541283, 0.99542332)\n",
      "437 0.000154016\n",
      "(0.99542332, 0.99543381)\n",
      "438 0.00015338\n",
      "(0.99543381, 0.99544418)\n",
      "439 0.000152725\n",
      "(0.99544418, 0.99545455)\n",
      "440 0.000152069\n",
      "(0.99545455, 0.99546486)\n",
      "441 0.000151434\n",
      "(0.99546486, 0.99547511)\n",
      "442 0.000150758\n",
      "(0.99547511, 0.99548531)\n",
      "443 0.000150143\n",
      "(0.99548531, 0.9954955)\n",
      "444 0.000149507\n",
      "(0.9954955, 0.99550563)\n",
      "445 0.000148832\n",
      "(0.99550563, 0.9955157)\n",
      "446 0.000148236\n",
      "(0.9955157, 0.99552572)\n",
      "447 0.0001476\n",
      "(0.99552572, 0.99553573)\n",
      "448 0.000146984\n",
      "(0.99553573, 0.99554569)\n",
      "449 0.000146349\n",
      "(0.99554569, 0.99555558)\n",
      "450 0.000145753\n",
      "(0.99555558, 0.99556541)\n",
      "451 0.000145177\n",
      "(0.99556541, 0.99557525)\n",
      "452 0.000144581\n",
      "(0.99557525, 0.99558496)\n",
      "453 0.000143926\n",
      "(0.99558496, 0.99559474)\n",
      "454 0.00014331\n",
      "(0.99559474, 0.9956044)\n",
      "455 0.000142734\n",
      "(0.9956044, 0.99561405)\n",
      "456 0.000142178\n",
      "(0.99561405, 0.99562365)\n",
      "457 0.000141582\n",
      "(0.99562365, 0.99563318)\n",
      "458 0.000141026\n",
      "(0.99563318, 0.99564272)\n",
      "459 0.00014043\n",
      "(0.99564272, 0.9956522)\n",
      "460 0.000139854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9956522, 0.99566162)\n",
      "461 0.000139258\n",
      "(0.99566162, 0.99567097)\n",
      "462 0.000138722\n",
      "(0.99567097, 0.99568033)\n",
      "463 0.000138165\n",
      "(0.99568033, 0.99568963)\n",
      "464 0.000137589\n",
      "(0.99568963, 0.99569893)\n",
      "465 0.000137033\n",
      "(0.99569893, 0.99570817)\n",
      "466 0.000136477\n",
      "(0.99570817, 0.99571735)\n",
      "467 0.000135921\n",
      "(0.99571735, 0.99572647)\n",
      "468 0.000135365\n",
      "(0.99572647, 0.99573559)\n",
      "469 0.000134848\n",
      "(0.99573559, 0.99574471)\n",
      "470 0.000134292\n",
      "(0.99574471, 0.99575371)\n",
      "471 0.000133716\n",
      "(0.99575371, 0.99576271)\n",
      "472 0.00013318\n",
      "(0.99576271, 0.99577165)\n",
      "473 0.000132703\n",
      "(0.99577165, 0.99578059)\n",
      "474 0.000132127\n",
      "(0.99578059, 0.99578947)\n",
      "475 0.00013165\n",
      "(0.99578947, 0.99579829)\n",
      "476 0.000131114\n",
      "(0.99579829, 0.99580711)\n",
      "477 0.000130558\n",
      "(0.99580711, 0.99581587)\n",
      "478 0.000130081\n",
      "(0.99581587, 0.99582464)\n",
      "479 0.000129505\n",
      "(0.99582464, 0.99583334)\n",
      "480 0.000128949\n",
      "(0.99583334, 0.99584198)\n",
      "481 0.000128452\n",
      "(0.99584198, 0.99585062)\n",
      "482 0.000127936\n",
      "(0.99585062, 0.99585921)\n",
      "483 0.000127479\n",
      "(0.99585921, 0.99586779)\n",
      "484 0.000126963\n",
      "(0.99586779, 0.99587631)\n",
      "485 0.000126486\n",
      "(0.99587631, 0.99588478)\n",
      "486 0.000125989\n",
      "(0.99588478, 0.99589324)\n",
      "487 0.000125532\n",
      "(0.99589324, 0.99590164)\n",
      "488 0.000125056\n",
      "(0.99590164, 0.99591005)\n",
      "489 0.000124539\n",
      "(0.99591005, 0.99591839)\n",
      "490 0.000124062\n",
      "(0.99591839, 0.99592668)\n",
      "491 0.000123566\n",
      "(0.99592668, 0.99593496)\n",
      "492 0.000123129\n",
      "(0.99593496, 0.99594319)\n",
      "493 0.000122632\n",
      "(0.99594319, 0.99595141)\n",
      "494 0.000122156\n",
      "(0.99595141, 0.99595958)\n",
      "495 0.000121699\n",
      "(0.99595958, 0.99596775)\n",
      "496 0.000121262\n",
      "(0.99596775, 0.99597585)\n",
      "497 0.000120825\n",
      "(0.99597585, 0.99598396)\n",
      "498 0.000120328\n",
      "(0.99598396, 0.995992)\n",
      "499 0.000119871\n",
      "(0.995992, 0.99599999)\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([2, 10], -1, 1))\n",
    "b = tf.Variable(tf.random_uniform([10]))\n",
    "L1 = tf.add(tf.matmul(X, W), b)\n",
    "L1 = tf.nn.relu(L1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([10, 20], -1, 1))\n",
    "b2 = tf.Variable(tf.random_uniform([20]))\n",
    "L2 = tf.add(tf.matmul(L1, W2), b2)\n",
    "L2 = tf.nn.relu(L2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_uniform([20, 3], -1, 1))\n",
    "b3 = tf.Variable(tf.random_uniform([3]))\n",
    "L3 = tf.add(tf.matmul(L2, W3), b3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=L3))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "prediction = tf.argmax(tf.nn.softmax(L3), axis = 1)\n",
    "target = tf.argmax(Y, axis = 1)\n",
    "accuracy = tf.metrics.accuracy(target, prediction)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    for step in range(500):\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict = {X: x_data, Y: y_data})\n",
    "        print(step, c)\n",
    "        print(sess.run(accuracy, feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "    \n",
    "\n",
    "#L1 = tf.layers.dense(X, 3, activation = tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\\dnn2.ckpt-500\n",
      "Step : 501, cost : 0.00033704936504364014\n",
      "Step : 502, cost : 0.0003359177790116519\n",
      "Step : 503, cost : 0.00033482591970823705\n",
      "Step : 504, cost : 0.00033375388011336327\n",
      "Step : 505, cost : 0.00033266202080994844\n",
      "Step : 506, cost : 0.00033158998121507466\n",
      "Step : 507, cost : 0.00033051797072403133\n",
      "Step : 508, cost : 0.00032944593112915754\n",
      "Step : 509, cost : 0.00032839374034665525\n",
      "Step : 510, cost : 0.00032732170075178146\n",
      "Step : 511, cost : 0.00032626950996927917\n",
      "Step : 512, cost : 0.0003252172900829464\n",
      "Step : 513, cost : 0.00032420482602901757\n",
      "Step : 514, cost : 0.0003231526352465153\n",
      "Step : 515, cost : 0.0003220606595277786\n",
      "Step : 516, cost : 0.0003210481663700193\n",
      "Step : 517, cost : 0.00032001579529605806\n",
      "Step : 518, cost : 0.0003190032730344683\n",
      "Step : 519, cost : 0.00031797096016816795\n",
      "Step : 520, cost : 0.0003169584379065782\n",
      "Step : 521, cost : 0.00031592603772878647\n",
      "Step : 522, cost : 0.0003149135154671967\n",
      "Step : 523, cost : 0.00031392084201797843\n",
      "Step : 524, cost : 0.00031290831975638866\n",
      "Step : 525, cost : 0.00031187591957859695\n",
      "Step : 526, cost : 0.00031090309494175017\n",
      "Step : 527, cost : 0.000309870665660128\n",
      "Step : 528, cost : 0.0003088978410232812\n",
      "Step : 529, cost : 0.00030792501638643444\n",
      "Step : 530, cost : 0.00030695213354192674\n",
      "Step : 531, cost : 0.00030595946009270847\n",
      "Step : 532, cost : 0.0003050064842682332\n",
      "Step : 533, cost : 0.0003040535084437579\n",
      "Step : 534, cost : 0.0003031402302440256\n",
      "Step : 535, cost : 0.00030210777185857296\n",
      "Step : 536, cost : 0.00030119449365884066\n",
      "Step : 537, cost : 0.0003002613957505673\n",
      "Step : 538, cost : 0.0002993083617184311\n",
      "Step : 539, cost : 0.0002984149323310703\n",
      "Step : 540, cost : 0.0002974420494865626\n",
      "Step : 541, cost : 0.00029650889337062836\n",
      "Step : 542, cost : 0.0002956353418994695\n",
      "Step : 543, cost : 0.00029472203459590673\n",
      "Step : 544, cost : 0.000293808727292344\n",
      "Step : 545, cost : 0.00029287554207257926\n",
      "Step : 546, cost : 0.00029196226387284696\n",
      "Step : 547, cost : 0.0002910290495492518\n",
      "Step : 548, cost : 0.000290155439870432\n",
      "Step : 549, cost : 0.00028924213256686926\n",
      "Step : 550, cost : 0.0002884082496166229\n",
      "Step : 551, cost : 0.00028745518648065627\n",
      "Step : 552, cost : 0.00028660145471803844\n",
      "Step : 553, cost : 0.0002856881183106452\n",
      "Step : 554, cost : 0.0002848343865480274\n",
      "Step : 555, cost : 0.00028400050359778106\n",
      "Step : 556, cost : 0.0002831467427313328\n",
      "Step : 557, cost : 0.00028227310394868255\n",
      "Step : 558, cost : 0.0002813994651660323\n",
      "Step : 559, cost : 0.0002805456751957536\n",
      "Step : 560, cost : 0.0002796919143293053\n",
      "Step : 561, cost : 0.00027889772900380194\n",
      "Step : 562, cost : 0.0002780439390335232\n",
      "Step : 563, cost : 0.00027721005608327687\n",
      "Step : 564, cost : 0.00027639599284157157\n",
      "Step : 565, cost : 0.0002755223249550909\n",
      "Step : 566, cost : 0.00027468838379718363\n",
      "Step : 567, cost : 0.0002738743496593088\n",
      "Step : 568, cost : 0.000273080135229975\n",
      "Step : 569, cost : 0.0002722859208006412\n",
      "Step : 570, cost : 0.0002714718575589359\n",
      "Step : 571, cost : 0.0002706776431296021\n",
      "Step : 572, cost : 0.00026990327751263976\n",
      "Step : 573, cost : 0.00026904945843853056\n",
      "Step : 574, cost : 0.00026825524400919676\n",
      "Step : 575, cost : 0.00026746102957986295\n",
      "Step : 576, cost : 0.0002667064545676112\n",
      "Step : 577, cost : 0.0002658725425135344\n",
      "Step : 578, cost : 0.00026513790362514555\n",
      "Step : 579, cost : 0.00026436353800818324\n",
      "Step : 580, cost : 0.0002636090212035924\n",
      "Step : 581, cost : 0.00026283462648279965\n",
      "Step : 582, cost : 0.0002620801387820393\n",
      "Step : 583, cost : 0.000261325592873618\n",
      "Step : 584, cost : 0.0002605512272566557\n",
      "Step : 585, cost : 0.00025979671045206487\n",
      "Step : 586, cost : 0.0002590421645436436\n",
      "Step : 587, cost : 0.00025832734536379576\n",
      "Step : 588, cost : 0.00025757282855920494\n",
      "Step : 589, cost : 0.00025677852681837976\n",
      "Step : 590, cost : 0.0002560438879299909\n",
      "Step : 591, cost : 0.0002553091908339411\n",
      "Step : 592, cost : 0.00025459437165409327\n",
      "Step : 593, cost : 0.00025387955247424543\n",
      "Step : 594, cost : 0.00025314485537819564\n",
      "Step : 595, cost : 0.0002524101873859763\n",
      "Step : 596, cost : 0.00025171521701849997\n",
      "Step : 597, cost : 0.00025100039783865213\n",
      "Step : 598, cost : 0.00025030539836734533\n",
      "Step : 599, cost : 0.0002495111257303506\n",
      "Step : 600, cost : 0.0002488161262590438\n",
      "Step : 601, cost : 0.000248101307079196\n",
      "Step : 602, cost : 0.0002474261855240911\n",
      "Step : 603, cost : 0.0002467312151566148\n",
      "Step : 604, cost : 0.00024603624478913844\n",
      "Step : 605, cost : 0.00024534124531783164\n",
      "Step : 606, cost : 0.0002446661237627268\n",
      "Step : 607, cost : 0.0002439909876557067\n",
      "Step : 608, cost : 0.0002432959881843999\n",
      "Step : 609, cost : 0.00024262086662929505\n",
      "Step : 610, cost : 0.00024194573052227497\n",
      "Step : 611, cost : 0.00024123086768668145\n",
      "Step : 612, cost : 0.00024053586821537465\n",
      "Step : 613, cost : 0.00023990047338884324\n",
      "Step : 614, cost : 0.00023922533728182316\n",
      "Step : 615, cost : 0.00023864944523666054\n",
      "Step : 616, cost : 0.00023795450397301465\n",
      "Step : 617, cost : 0.00023727935331407934\n",
      "Step : 618, cost : 0.00023666380729991943\n",
      "Step : 619, cost : 0.000236068110098131\n",
      "Step : 620, cost : 0.00023541285190731287\n",
      "Step : 621, cost : 0.00023475755006074905\n",
      "Step : 622, cost : 0.00023424132086802274\n",
      "Step : 623, cost : 0.0002336257603019476\n",
      "Step : 624, cost : 0.000232970473007299\n",
      "Step : 625, cost : 0.0002323151711607352\n",
      "Step : 626, cost : 0.00023171945940703154\n",
      "Step : 627, cost : 0.0002311038988409564\n",
      "Step : 628, cost : 0.00023044859699439257\n",
      "Step : 629, cost : 0.0002298330218764022\n",
      "Step : 630, cost : 0.00022921744675841182\n",
      "Step : 631, cost : 0.00022860185708850622\n",
      "Step : 632, cost : 0.00022800614533480257\n",
      "Step : 633, cost : 0.00022737069230061024\n",
      "Step : 634, cost : 0.00022673525381833315\n",
      "Step : 635, cost : 0.00022613951296079904\n",
      "Step : 636, cost : 0.00022554380120709538\n",
      "Step : 637, cost : 0.00022494806034956127\n",
      "Step : 638, cost : 0.00022435234859585762\n",
      "Step : 639, cost : 0.0002237566077383235\n",
      "Step : 640, cost : 0.00022314100351650268\n",
      "Step : 641, cost : 0.00022256515512708575\n",
      "Step : 642, cost : 0.00022194958000909537\n",
      "Step : 643, cost : 0.00022137367341201752\n",
      "Step : 644, cost : 0.00022077794710639864\n",
      "Step : 645, cost : 0.00022022193297743797\n",
      "Step : 646, cost : 0.00021960632875561714\n",
      "Step : 647, cost : 0.00021893111988902092\n",
      "Step : 648, cost : 0.00021835521329194307\n",
      "Step : 649, cost : 0.0002177793503506109\n",
      "Step : 650, cost : 0.00021718359494116157\n",
      "Step : 651, cost : 0.00021662759536411613\n",
      "Step : 652, cost : 0.000216071552131325\n",
      "Step : 653, cost : 0.00021547579672187567\n",
      "Step : 654, cost : 0.00021491979714483023\n",
      "Step : 655, cost : 0.00021436378301586956\n",
      "Step : 656, cost : 0.00021376802760642022\n",
      "Step : 657, cost : 0.00021317224309314042\n",
      "Step : 658, cost : 0.00021263607777655125\n",
      "Step : 659, cost : 0.0002120601711794734\n",
      "Step : 660, cost : 0.00021150415705051273\n",
      "Step : 661, cost : 0.00021096797718200833\n",
      "Step : 662, cost : 0.00021043181186541915\n",
      "Step : 663, cost : 0.0002098757540807128\n",
      "Step : 664, cost : 0.00020933958876412362\n",
      "Step : 665, cost : 0.00020880340889561921\n",
      "Step : 666, cost : 0.00020824738021474332\n",
      "Step : 667, cost : 0.00020767147361766547\n",
      "Step : 668, cost : 0.00020713527919724584\n",
      "Step : 669, cost : 0.0002065792359644547\n",
      "Step : 670, cost : 0.00020604307064786553\n",
      "Step : 671, cost : 0.0002055267250398174\n",
      "Step : 672, cost : 0.0002050104085355997\n",
      "Step : 673, cost : 0.00020447424321901053\n",
      "Step : 674, cost : 0.0002039380487985909\n",
      "Step : 675, cost : 0.00020342173229437321\n",
      "Step : 676, cost : 0.0002029054012382403\n",
      "Step : 677, cost : 0.0002023890701821074\n",
      "Step : 678, cost : 0.00020183301239740103\n",
      "Step : 679, cost : 0.0002012968179769814\n",
      "Step : 680, cost : 0.00020078050147276372\n",
      "Step : 681, cost : 0.0002002840192290023\n",
      "Step : 682, cost : 0.00019976768817286938\n",
      "Step : 683, cost : 0.0001992910838453099\n",
      "Step : 684, cost : 0.000198774752789177\n",
      "Step : 685, cost : 0.0001982782850973308\n",
      "Step : 686, cost : 0.00019778181740548462\n",
      "Step : 687, cost : 0.0001972654863493517\n",
      "Step : 688, cost : 0.00019676900410559028\n",
      "Step : 689, cost : 0.0001963122485904023\n",
      "Step : 690, cost : 0.0001957959175342694\n",
      "Step : 691, cost : 0.0001952596940100193\n",
      "Step : 692, cost : 0.00019470362167339772\n",
      "Step : 693, cost : 0.00019420712487772107\n",
      "Step : 694, cost : 0.0001937503693625331\n",
      "Step : 695, cost : 0.0001932539016706869\n",
      "Step : 696, cost : 0.00019277726823929697\n",
      "Step : 697, cost : 0.00019228080054745078\n",
      "Step : 698, cost : 0.0001918240450322628\n",
      "Step : 699, cost : 0.00019132754823658615\n",
      "Step : 700, cost : 0.00019083108054473996\n",
      "Step : 701, cost : 0.00019039417384192348\n",
      "Step : 702, cost : 0.00018991755496244878\n",
      "Step : 703, cost : 0.00018944092153105885\n",
      "Step : 704, cost : 0.00018900401482824236\n",
      "Step : 705, cost : 0.00018850754713639617\n",
      "Step : 706, cost : 0.0001880110357888043\n",
      "Step : 707, cost : 0.00018751453899312764\n",
      "Step : 708, cost : 0.00018707766139414161\n",
      "Step : 709, cost : 0.00018662087677512318\n",
      "Step : 710, cost : 0.00018614425789564848\n",
      "Step : 711, cost : 0.00018568748782854527\n",
      "Step : 712, cost : 0.00018523070320952684\n",
      "Step : 713, cost : 0.00018479379650671035\n",
      "Step : 714, cost : 0.00018435688980389386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 715, cost : 0.00018390011973679066\n",
      "Step : 716, cost : 0.00018346321303397417\n",
      "Step : 717, cost : 0.00018298656505066901\n",
      "Step : 718, cost : 0.00018256953626405448\n",
      "Step : 719, cost : 0.00018211275164503604\n",
      "Step : 720, cost : 0.00018167584494221956\n",
      "Step : 721, cost : 0.00018123892368748784\n",
      "Step : 722, cost : 0.00018080201698467135\n",
      "Step : 723, cost : 0.00018036511028185487\n",
      "Step : 724, cost : 0.0001799083111109212\n",
      "Step : 725, cost : 0.00017951113113667816\n",
      "Step : 726, cost : 0.0001790940877981484\n",
      "Step : 727, cost : 0.00017861743981484324\n",
      "Step : 728, cost : 0.00017820038192439824\n",
      "Step : 729, cost : 0.0001777833531377837\n",
      "Step : 730, cost : 0.00017728681268636137\n",
      "Step : 731, cost : 0.00017688963271211833\n",
      "Step : 732, cost : 0.00017647254571784288\n",
      "Step : 733, cost : 0.00017601577565073967\n",
      "Step : 734, cost : 0.0001755987323122099\n",
      "Step : 735, cost : 0.00017518165986984968\n",
      "Step : 736, cost : 0.0001747844653436914\n",
      "Step : 737, cost : 0.0001743872562656179\n",
      "Step : 738, cost : 0.0001739304861985147\n",
      "Step : 739, cost : 0.0001735332771204412\n",
      "Step : 740, cost : 0.0001731162192299962\n",
      "Step : 741, cost : 0.00017271902470383793\n",
      "Step : 742, cost : 0.00017232181562576443\n",
      "Step : 743, cost : 0.00017192463565152138\n",
      "Step : 744, cost : 0.0001714876852929592\n",
      "Step : 745, cost : 0.0001710904762148857\n",
      "Step : 746, cost : 0.0001707131596049294\n",
      "Step : 747, cost : 0.00017029607261065394\n",
      "Step : 748, cost : 0.0001698988926364109\n",
      "Step : 749, cost : 0.00016950165445450693\n",
      "Step : 750, cost : 0.0001691044744802639\n",
      "Step : 751, cost : 0.0001687072654021904\n",
      "Step : 752, cost : 0.00016832990513648838\n",
      "Step : 753, cost : 0.0001679327106103301\n",
      "Step : 754, cost : 0.00016755536489654332\n",
      "Step : 755, cost : 0.0001671382924541831\n",
      "Step : 756, cost : 0.00016676094674039632\n",
      "Step : 757, cost : 0.00016636373766232282\n",
      "Step : 758, cost : 0.00016600625531282276\n",
      "Step : 759, cost : 0.00016562890959903598\n",
      "Step : 760, cost : 0.00016523170052096248\n",
      "Step : 761, cost : 0.00016483449144288898\n",
      "Step : 762, cost : 0.0001644769945414737\n",
      "Step : 763, cost : 0.00016407978546340019\n",
      "Step : 764, cost : 0.00016370245430152863\n",
      "Step : 765, cost : 0.00016334495740011334\n",
      "Step : 766, cost : 0.00016294773377012461\n",
      "Step : 767, cost : 0.0001625703735044226\n",
      "Step : 768, cost : 0.00016221289115492254\n",
      "Step : 769, cost : 0.00016183553088922054\n",
      "Step : 770, cost : 0.00016145819972734898\n",
      "Step : 771, cost : 0.0001611007028259337\n",
      "Step : 772, cost : 0.0001607432059245184\n",
      "Step : 773, cost : 0.00016040557238738984\n",
      "Step : 774, cost : 0.00015998849994502962\n",
      "Step : 775, cost : 0.0001596111396793276\n",
      "Step : 776, cost : 0.00015927352069411427\n",
      "Step : 777, cost : 0.00015891602379269898\n",
      "Step : 778, cost : 0.0001585585268912837\n",
      "Step : 779, cost : 0.0001582010299898684\n",
      "Step : 780, cost : 0.00015788327436894178\n",
      "Step : 781, cost : 0.0001575257774675265\n",
      "Step : 782, cost : 0.00015718815848231316\n",
      "Step : 783, cost : 0.00015683064702898264\n",
      "Step : 784, cost : 0.0001564930280437693\n",
      "Step : 785, cost : 0.0001561156677780673\n",
      "Step : 786, cost : 0.00015579789760522544\n",
      "Step : 787, cost : 0.00015542053733952343\n",
      "Step : 788, cost : 0.00015508288925047964\n",
      "Step : 789, cost : 0.0001547452702652663\n",
      "Step : 790, cost : 0.000154387773363851\n",
      "Step : 791, cost : 0.0001540302619105205\n",
      "Step : 792, cost : 0.00015369262837339193\n",
      "Step : 793, cost : 0.00015335499483626336\n",
      "Step : 794, cost : 0.0001530173612991348\n",
      "Step : 795, cost : 0.00015267972776200622\n",
      "Step : 796, cost : 0.00015234207967296243\n",
      "Step : 797, cost : 0.00015198458277154714\n",
      "Step : 798, cost : 0.00015168666141107678\n",
      "Step : 799, cost : 0.00015130930114537477\n",
      "Step : 800, cost : 0.00015099153097253293\n",
      "Step : 801, cost : 0.00015067374624777585\n",
      "Step : 802, cost : 0.00015031623479444534\n",
      "Step : 803, cost : 0.0001499984646216035\n",
      "Step : 804, cost : 0.0001496608165325597\n",
      "Step : 805, cost : 0.00014934304635971785\n",
      "Step : 806, cost : 0.00014900539827067405\n",
      "Step : 807, cost : 0.0001486280234530568\n",
      "Step : 808, cost : 0.00014829037536401302\n",
      "Step : 809, cost : 0.00014797260519117117\n",
      "Step : 810, cost : 0.00014765483501832932\n",
      "Step : 811, cost : 0.00014733705029357225\n",
      "Step : 812, cost : 0.00014697953884024173\n",
      "Step : 813, cost : 0.00014668161747977138\n",
      "Step : 814, cost : 0.00014634396939072758\n",
      "Step : 815, cost : 0.00014604604803025723\n",
      "Step : 816, cost : 0.00014572827785741538\n",
      "Step : 817, cost : 0.0001454104931326583\n",
      "Step : 818, cost : 0.00014509270840790123\n",
      "Step : 819, cost : 0.0001447948015993461\n",
      "Step : 820, cost : 0.00014449686568696052\n",
      "Step : 821, cost : 0.00014415923214983195\n",
      "Step : 822, cost : 0.00014384144742507488\n",
      "Step : 823, cost : 0.00014350378478411585\n",
      "Step : 824, cost : 0.00014320587797556072\n",
      "Step : 825, cost : 0.00014288809325080365\n",
      "Step : 826, cost : 0.00014261003525462002\n",
      "Step : 827, cost : 0.0001422922359779477\n",
      "Step : 828, cost : 0.00014197445125319064\n",
      "Step : 829, cost : 0.0001416169252479449\n",
      "Step : 830, cost : 0.00014131901843938977\n",
      "Step : 831, cost : 0.00014102108252700418\n",
      "Step : 832, cost : 0.00014072316116653383\n",
      "Step : 833, cost : 0.00014044508861843497\n",
      "Step : 834, cost : 0.0001401074550813064\n",
      "Step : 835, cost : 0.00013980951916892081\n",
      "Step : 836, cost : 0.00013953146117273718\n",
      "Step : 837, cost : 0.0001392136764479801\n",
      "Step : 838, cost : 0.00013891574053559452\n",
      "Step : 839, cost : 0.0001386376825394109\n",
      "Step : 840, cost : 0.00013833976117894053\n",
      "Step : 841, cost : 0.00013802196190226823\n",
      "Step : 842, cost : 0.0001377439039060846\n",
      "Step : 843, cost : 0.00013746584590990096\n",
      "Step : 844, cost : 0.00013716790999751538\n",
      "Step : 845, cost : 0.00013686998863704503\n",
      "Step : 846, cost : 0.0001365919306408614\n",
      "Step : 847, cost : 0.0001362939947284758\n",
      "Step : 848, cost : 0.00013601593673229218\n",
      "Step : 849, cost : 0.0001357378641841933\n",
      "Step : 850, cost : 0.00013543994282372296\n",
      "Step : 851, cost : 0.0001351618702756241\n",
      "Step : 852, cost : 0.00013486394891515374\n",
      "Step : 853, cost : 0.00013462560309562832\n",
      "Step : 854, cost : 0.00013430781837087125\n",
      "Step : 855, cost : 0.00013397012662608176\n",
      "Step : 856, cost : 0.00013369206862989813\n",
      "Step : 857, cost : 0.00013339414726942778\n",
      "Step : 858, cost : 0.00013307633344084024\n",
      "Step : 859, cost : 0.0001328181242570281\n",
      "Step : 860, cost : 0.0001325003249803558\n",
      "Step : 861, cost : 0.00013224213034845889\n",
      "Step : 862, cost : 0.00013196405780036002\n",
      "Step : 863, cost : 0.0001316859998041764\n",
      "Step : 864, cost : 0.00013144763943273574\n",
      "Step : 865, cost : 0.0001311497180722654\n",
      "Step : 866, cost : 0.00013087164552416652\n",
      "Step : 867, cost : 0.0001306332997046411\n",
      "Step : 868, cost : 0.00013035524170845747\n",
      "Step : 869, cost : 0.0001300573057960719\n",
      "Step : 870, cost : 0.00012979909661225975\n",
      "Step : 871, cost : 0.00012952102406416088\n",
      "Step : 872, cost : 0.00012928267824463546\n",
      "Step : 873, cost : 0.0001289847568841651\n",
      "Step : 874, cost : 0.00012872654770035297\n",
      "Step : 875, cost : 0.00012846833851654083\n",
      "Step : 876, cost : 0.00012821012933272868\n",
      "Step : 877, cost : 0.00012795190559700131\n",
      "Step : 878, cost : 0.0001276937109651044\n",
      "Step : 879, cost : 0.00012741563841700554\n",
      "Step : 880, cost : 0.00012717729259748012\n",
      "Step : 881, cost : 0.00012689922004938126\n",
      "Step : 882, cost : 0.00012664101086556911\n",
      "Step : 883, cost : 0.00012638280168175697\n",
      "Step : 884, cost : 0.00012612459249794483\n",
      "Step : 885, cost : 0.0001258663833141327\n",
      "Step : 886, cost : 0.00012560817413032055\n",
      "Step : 887, cost : 0.0001253499649465084\n",
      "Step : 888, cost : 0.00012511160457506776\n",
      "Step : 889, cost : 0.00012485340994317085\n",
      "Step : 890, cost : 0.00012459518620744348\n",
      "Step : 891, cost : 0.00012433697702363133\n",
      "Step : 892, cost : 0.00012409863120410591\n",
      "Step : 893, cost : 0.00012386027083266526\n",
      "Step : 894, cost : 0.00012360206164885312\n",
      "Step : 895, cost : 0.0001233637158293277\n",
      "Step : 896, cost : 0.00012310550664551556\n",
      "Step : 897, cost : 0.00012286716082599014\n",
      "Step : 898, cost : 0.00012262881500646472\n",
      "Step : 899, cost : 0.00012237059127073735\n",
      "Step : 900, cost : 0.00012213224545121193\n",
      "Step : 901, cost : 0.00012187403626739979\n",
      "Step : 902, cost : 0.00012161582708358765\n",
      "Step : 903, cost : 0.00012139733735239133\n",
      "Step : 904, cost : 0.00012113912816857919\n",
      "Step : 905, cost : 0.00012084116315236315\n",
      "Step : 906, cost : 0.00012060281733283773\n",
      "Step : 907, cost : 0.00012038432760164142\n",
      "Step : 908, cost : 0.00012014597450615838\n",
      "Step : 909, cost : 0.00011988775804638863\n",
      "Step : 910, cost : 0.00011962954886257648\n",
      "Step : 911, cost : 0.00011939121031900868\n",
      "Step : 912, cost : 0.00011917271331185475\n",
      "Step : 913, cost : 0.00011895422358065844\n",
      "Step : 914, cost : 0.0001186960143968463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 915, cost : 0.00011845765402540565\n",
      "Step : 916, cost : 0.00011821931548183784\n",
      "Step : 917, cost : 0.00011800081847468391\n",
      "Step : 918, cost : 0.0001177823287434876\n",
      "Step : 919, cost : 0.00011752409773180261\n",
      "Step : 920, cost : 0.0001172857591882348\n",
      "Step : 921, cost : 0.00011706725490512326\n",
      "Step : 922, cost : 0.00011682891636155546\n",
      "Step : 923, cost : 0.00011663028271868825\n",
      "Step : 924, cost : 0.00011639192962320521\n",
      "Step : 925, cost : 0.0001161535838036798\n",
      "Step : 926, cost : 0.00011593508679652587\n",
      "Step : 927, cost : 0.00011569674097700045\n",
      "Step : 928, cost : 0.00011547824396984652\n",
      "Step : 929, cost : 0.00011523988359840587\n",
      "Step : 930, cost : 0.00011510084732435644\n",
      "Step : 931, cost : 0.00011482276750029996\n",
      "Step : 932, cost : 0.00011458442168077454\n",
      "Step : 933, cost : 0.00011442552204243839\n",
      "Step : 934, cost : 0.00011418716894695535\n",
      "Step : 935, cost : 0.00011398854985600337\n",
      "Step : 936, cost : 0.00011375018948456272\n",
      "Step : 937, cost : 0.0001135316924774088\n",
      "Step : 938, cost : 0.0001133132100221701\n",
      "Step : 939, cost : 0.00011309471301501617\n",
      "Step : 940, cost : 0.00011285635991953313\n",
      "Step : 941, cost : 0.00011267759691691026\n",
      "Step : 942, cost : 0.00011245909990975633\n",
      "Step : 943, cost : 0.00011222075409023091\n",
      "Step : 944, cost : 0.0001120221204473637\n",
      "Step : 945, cost : 0.00011178376735188067\n",
      "Step : 946, cost : 0.00011156526306876913\n",
      "Step : 947, cost : 0.00011136664397781715\n",
      "Step : 948, cost : 0.00011114814697066322\n",
      "Step : 949, cost : 0.00011092964996350929\n",
      "Step : 950, cost : 0.00011075089423684403\n",
      "Step : 951, cost : 0.00011051253386540338\n",
      "Step : 952, cost : 0.00011029402958229184\n",
      "Step : 953, cost : 0.00011011527385562658\n",
      "Step : 954, cost : 0.00010989676957251504\n",
      "Step : 955, cost : 0.00010965842375298962\n",
      "Step : 956, cost : 0.00010947965347440913\n",
      "Step : 957, cost : 0.0001092611564672552\n",
      "Step : 958, cost : 0.00010906253010034561\n",
      "Step : 959, cost : 0.00010884402581723407\n",
      "Step : 960, cost : 0.00010864540672628209\n",
      "Step : 961, cost : 0.00010842690244317055\n",
      "Step : 962, cost : 0.00010822827607626095\n",
      "Step : 963, cost : 0.00010800978634506464\n",
      "Step : 964, cost : 0.00010781115270219743\n",
      "Step : 965, cost : 0.00010759264841908589\n",
      "Step : 966, cost : 0.00010743374150479212\n",
      "Step : 967, cost : 0.0001071953956852667\n",
      "Step : 968, cost : 0.00010703647421905771\n",
      "Step : 969, cost : 0.0001067981356754899\n",
      "Step : 970, cost : 0.0001066193581209518\n",
      "Step : 971, cost : 0.00010640086838975549\n",
      "Step : 972, cost : 0.00010622209083521739\n",
      "Step : 973, cost : 0.00010600360110402107\n",
      "Step : 974, cost : 0.00010582482354948297\n",
      "Step : 975, cost : 0.00010562620445853099\n",
      "Step : 976, cost : 0.00010540770017541945\n",
      "Step : 977, cost : 0.00010520906653255224\n",
      "Step : 978, cost : 0.00010495082824490964\n",
      "Step : 979, cost : 0.00010475219460204244\n",
      "Step : 980, cost : 0.00010455356095917523\n",
      "Step : 981, cost : 0.00010435492731630802\n",
      "Step : 982, cost : 0.00010415629367344081\n",
      "Step : 983, cost : 0.00010397753067081794\n",
      "Step : 984, cost : 0.0001037788824760355\n",
      "Step : 985, cost : 0.00010360011947341263\n",
      "Step : 986, cost : 0.00010340148583054543\n",
      "Step : 987, cost : 0.00010322272282792255\n",
      "Step : 988, cost : 0.00010302408918505535\n",
      "Step : 989, cost : 0.00010282545554218814\n",
      "Step : 990, cost : 0.00010264668526360765\n",
      "Step : 991, cost : 0.00010246791498502716\n",
      "Step : 992, cost : 0.00010226928134215996\n",
      "Step : 993, cost : 0.00010207063314737752\n",
      "Step : 994, cost : 0.00010189187014475465\n",
      "Step : 995, cost : 0.00010169323650188744\n",
      "Step : 996, cost : 0.00010149460285902023\n",
      "Step : 997, cost : 0.00010131582530448213\n",
      "Step : 998, cost : 0.00010115691839018837\n",
      "Step : 999, cost : 0.00010097814811160788\n",
      "Step : 1000, cost : 0.00010077952174469829\n"
     ]
    }
   ],
   "source": [
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    X = tf.placeholder(tf.float32)\n",
    "    Y = tf.placeholder(tf.float32)\n",
    "    with tf.name_scope('Layer1'):\n",
    "        W = tf.Variable(tf.random_uniform([2, 10], -1, 1))\n",
    "        b = tf.Variable(tf.random_uniform([10]))\n",
    "        L1 = tf.add(tf.matmul(X, W), b)\n",
    "        L1 = tf.nn.relu(L1)\n",
    "    with tf.name_scope('Layer2'):\n",
    "        W2 = tf.Variable(tf.random_uniform([10, 20], -1, 1))\n",
    "        b2 = tf.Variable(tf.random_uniform([20]))\n",
    "        L2 = tf.add(tf.matmul(L1, W2), b2)\n",
    "        L2 = tf.nn.relu(L2)\n",
    "    with tf.name_scope('output'):\n",
    "        W3 = tf.Variable(tf.random_uniform([20, 3], -1, 1))\n",
    "        b3 = tf.Variable(tf.random_uniform([3]))\n",
    "        L3 = tf.add(tf.matmul(L2, W3), b3)\n",
    "    with tf.name_scope('optimizer'):\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=L3))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.01).minimize(cost, global_step = global_step)\n",
    "tf.summary.scalar('cost', cost)\n",
    "tf.summary.histogram('weight1', W)\n",
    "tf.summary.histogram('weight2', W2)\n",
    "tf.summary.histogram('weight3', W3)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "prediction = tf.argmax(tf.nn.softmax(L3), axis = 1)\n",
    "target = tf.argmax(Y, axis = 1)\n",
    "accuracy = tf.metrics.accuracy(target, prediction)\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter('./logs', sess.graph)\n",
    "    ckpt = tf.train.get_checkpoint_state('./model')\n",
    "    \n",
    "    if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "    for step in range(500):\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict = {X: x_data, Y: y_data})\n",
    "        summ = sess.run(merged, feed_dict = {X: x_data, Y: y_data})\n",
    "        print('Step : {}, cost : {}'.format(sess.run(global_step), c))\n",
    "        writer.add_summary(summ, global_step= sess.run(global_step))\n",
    "    saver.save(sess, './model/dnn2.ckpt', global_step=global_step)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!tensorboard --logdir=./logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\\dnn.ckpt-2\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Key Variable_3/Adam not found in checkpoint\n\t [[Node: save_1/RestoreV2_10 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_10/tensor_names, save_1/RestoreV2_10/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_10/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_114_save_1/RestoreV2_10\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'save_1/RestoreV2_10', defined at:\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-52-5f07597da086>\", line 38, in <module>\n    saver = tf.train.Saver(tf.global_variables())\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1056, in __init__\n    self.build()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 669, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Key Variable_3/Adam not found in checkpoint\n\t [[Node: save_1/RestoreV2_10 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_10/tensor_names, save_1/RestoreV2_10/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_10/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_114_save_1/RestoreV2_10\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key Variable_3/Adam not found in checkpoint\n\t [[Node: save_1/RestoreV2_10 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_10/tensor_names, save_1/RestoreV2_10/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_10/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_114_save_1/RestoreV2_10\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-5f07597da086>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mckpt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_checkpoint_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mckpt\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Restoring parameters from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1457\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key Variable_3/Adam not found in checkpoint\n\t [[Node: save_1/RestoreV2_10 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_10/tensor_names, save_1/RestoreV2_10/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_10/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_114_save_1/RestoreV2_10\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'save_1/RestoreV2_10', defined at:\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-52-5f07597da086>\", line 38, in <module>\n    saver = tf.train.Saver(tf.global_variables())\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1056, in __init__\n    self.build()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 669, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Key Variable_3/Adam not found in checkpoint\n\t [[Node: save_1/RestoreV2_10 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_10/tensor_names, save_1/RestoreV2_10/shape_and_slices)]]\n\t [[Node: save_1/RestoreV2_10/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_114_save_1/RestoreV2_10\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "# 학습에 직접적으로 사용하지 않고 학습 횟수에 따라 단순히 증가시킬 변수를 만듭니다.\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([2, 10], -1., 1.))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([10, 20], -1., 1.))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "\n",
    "W3 = tf.Variable(tf.random_uniform([20, 3], -1., 1.))\n",
    "model = tf.matmul(L2, W3)\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=model))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "# global_step로 넘겨준 변수를, 학습용 변수들을 최적화 할 때 마다 학습 횟수를 하나씩 증가시킵니다.\n",
    "train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "\n",
    "\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "sess = tf.Session()\n",
    "# 모델을 저장하고 불러오는 API를 초기화합니다.\n",
    "# global_variables 함수를 통해 앞서 정의하였던 변수들을 저장하거나 불러올 변수들로 설정합니다.\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state('./model')\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 최적화 진행\n",
    "for step in range(2):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    print('Step: %d, ' % sess.run(global_step),\n",
    "          'Cost: %.3f' % sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "# 최적화가 끝난 뒤, 변수를 저장합니다.\n",
    "saver.save(sess, './model/dnn.ckpt', global_step=global_step)\n",
    "\n",
    "#########\n",
    "# 결과 확인\n",
    "# 0: 기타 1: 포유류, 2: 조류\n",
    "######\n",
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "print('예측값:', sess.run(prediction, feed_dict={X: x_data}))\n",
    "print('실제값:', sess.run(target, feed_dict={Y: y_data}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1,  Cost: 0.952\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_8' with dtype float\n\t [[Node: Placeholder_8 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: optimizer_3/Mean/_63 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_254_optimizer_3/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Placeholder_8', defined at:\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-61-bcd5bf177eb5>\", line 2, in <module>\n    X = tf.placeholder(tf.float32)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1507, in placeholder\n    name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 1997, in _placeholder\n    name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_8' with dtype float\n\t [[Node: Placeholder_8 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: optimizer_3/Mean/_63 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_254_optimizer_3/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_8' with dtype float\n\t [[Node: Placeholder_8 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: optimizer_3/Mean/_63 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_254_optimizer_3/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-b022236bfe19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[1;31m# 적절한 시점에 저장할 값들을 수집하고 저장합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0msummary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_8' with dtype float\n\t [[Node: Placeholder_8 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: optimizer_3/Mean/_63 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_254_optimizer_3/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Placeholder_8', defined at:\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-61-bcd5bf177eb5>\", line 2, in <module>\n    X = tf.placeholder(tf.float32)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1507, in placeholder\n    name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 1997, in _placeholder\n    name=name)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\POWER USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_8' with dtype float\n\t [[Node: Placeholder_8 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: optimizer_3/Mean/_63 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_254_optimizer_3/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# with tf.name_scope 으로 묶은 블럭은 텐서보드에서 한 레이어안에 표현해줍니다\n",
    "with tf.name_scope('layer1'):\n",
    "    W1 = tf.Variable(tf.random_uniform([2, 10], -1., 1.), name='W1')\n",
    "    L1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "\n",
    "with tf.name_scope('layer2'):\n",
    "    W2 = tf.Variable(tf.random_uniform([10, 20], -1., 1.), name='W2')\n",
    "    L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "\n",
    "with tf.name_scope('output'):\n",
    "    W3 = tf.Variable(tf.random_uniform([20, 3], -1., 1.), name='W3')\n",
    "    model = tf.matmul(L2, W3)\n",
    "\n",
    "with tf.name_scope('optimizer'):\n",
    "    cost = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=model))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "\n",
    "    # tf.summary.scalar 를 이용해 수집하고 싶은 값들을 지정할 수 있습니다.\n",
    "    tf.summary.scalar('cost', cost)\n",
    "\n",
    "\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state('./model')\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 텐서보드에서 표시해주기 위한 텐서들을 수집합니다.\n",
    "merged = tf.summary.merge_all()\n",
    "# 저장할 그래프와 텐서값들을 저장할 디렉토리를 설정합니다.\n",
    "writer = tf.summary.FileWriter('./logs', sess.graph)\n",
    "# 이렇게 저장한 로그는, 학습 후 다음의 명령어를 이용해 웹서버를 실행시킨 뒤\n",
    "# tensorboard --logdir=./logs\n",
    "# 다음 주소와 웹브라우저를 이용해 텐서보드에서 확인할 수 있습니다.\n",
    "# http://localhost:6006\n",
    "\n",
    "# 최적화 진행\n",
    "for step in range(100):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    print('Step: %d, ' % sess.run(global_step),\n",
    "          'Cost: %.3f' % sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "    # 적절한 시점에 저장할 값들을 수집하고 저장합니다.\n",
    "    summary = sess.run(merged, feed_dict={X: x_data, Y: y_data})\n",
    "    writer.add_summary(summary, global_step=sess.run(global_step))\n",
    "\n",
    "saver.save(sess, './model/dnn.ckpt', global_step=global_step)\n",
    "\n",
    "#########\n",
    "# 결과 확인\n",
    "# 0: 기타 1: 포유류, 2: 조류\n",
    "######\n",
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "print('예측값:', sess.run(prediction, feed_dict={X: x_data}))\n",
    "print('실제값:', sess.run(target, feed_dict={Y: y_data}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
